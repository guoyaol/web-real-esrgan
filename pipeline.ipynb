{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/guoyaoli/tvm_work/web-real-esrgan', '/Users/guoyaoli/tvm_work/tvm/python', '/Users/guoyaoli/tvm_work/web-real-esrgan', '/Users/guoyaoli/ENTER/envs/esr/lib/python38.zip', '/Users/guoyaoli/ENTER/envs/esr/lib/python3.8', '/Users/guoyaoli/ENTER/envs/esr/lib/python3.8/lib-dynload', '', '/Users/guoyaoli/ENTER/envs/esr/lib/python3.8/site-packages', '/Users/guoyaoli/tvm_work/tvm/python/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/guoyaoli/tvm_work/tvm/python/\")\n",
    "print(sys.path)\n",
    "\n",
    "# import os\n",
    "\n",
    "# # Replace this with the path to the 'nvcc' executable on your system\n",
    "# nvcc_path = \"/usr/local/cuda-11.8/bin\"\n",
    "\n",
    "# if nvcc_path not in os.environ[\"PATH\"]:\n",
    "#     os.environ[\"PATH\"] += f\":{nvcc_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "from network import RRDBNet\n",
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.script import relax as R\n",
    "from tvm.relax.frontend.torch import dynamo_capture_subgraphs\n",
    "import torch\n",
    "from typing import Dict, List, Tuple\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "netscale = 4\n",
    "model_path = \"./weights/RealESRGAN_x4plus.pth\"\n",
    "model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
    "outscale = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrdb_net(model) -> tvm.IRModule:\n",
    "\n",
    "    class RRDBNetWrapper(torch.nn.Module):\n",
    "        def __init__(self, rrdb):\n",
    "            super().__init__()\n",
    "            self.rrdb = rrdb\n",
    "\n",
    "        def forward(self, input):\n",
    "            output = self.rrdb(input)\n",
    "            return output\n",
    "\n",
    "    rrdb = RRDBNetWrapper(model)\n",
    "\n",
    "    #todo: change size\n",
    "    z = torch.rand((1, 3, 640, 448), dtype=torch.float32)\n",
    "\n",
    "    mod = dynamo_capture_subgraphs(\n",
    "        rrdb.forward,\n",
    "        z,\n",
    "        keep_params_as_input=True,\n",
    "    )\n",
    "    assert len(mod.functions) == 1\n",
    "\n",
    "    return tvm.IRModule({\"rrdb\": mod[\"subgraph_0\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image() -> tvm.IRModule:\n",
    "    from tvm import te\n",
    "    #divide each element by 255\n",
    "    #todo: different sizes of images\n",
    "    def f_scale_image(A):\n",
    "        def fcompute(x, y, c):\n",
    "            return A[x, y, c] / te.const(255, \"float32\")\n",
    "\n",
    "        return te.compute((640, 448, 3), fcompute, name=\"scale_image\")\n",
    "\n",
    "    bb = relax.BlockBuilder()\n",
    "    x = relax.Var(\"x\", R.Tensor([640, 448, 3], \"float32\"))\n",
    "    with bb.function(\"scale_image\", [x]):\n",
    "        image = bb.emit(\n",
    "            bb.call_te(f_scale_image, x, primfunc_name_hint=\"tir_scale_image\")\n",
    "        )\n",
    "        bb.emit_func_output(image)\n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess() -> tvm.IRModule:\n",
    "    from tvm import te\n",
    "    #np.transpose(img, (2, 0, 1)) and unqueeze(0)\n",
    "    #todo: different sizes of images\n",
    "    def f_preprocess(A):\n",
    "        def fcompute(i, c, x, y):\n",
    "            return A[x, y, c]\n",
    "        return te.compute((1, 3, 640, 448), fcompute, name=\"preprocess\")\n",
    "\n",
    "\n",
    "    bb = relax.BlockBuilder()\n",
    "    x = relax.Var(\"x\", R.Tensor([640, 448, 3], \"float32\"))\n",
    "    with bb.function(\"preprocess\", [x]):\n",
    "        image = bb.emit(\n",
    "            bb.call_te(f_preprocess, x, primfunc_name_hint=\"tir_preprocess\")\n",
    "        )\n",
    "        bb.emit_func_output(image)\n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess() -> tvm.IRModule:\n",
    "    from tvm import te\n",
    "    # output_img = output_img.data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "    # output_img = np.transpose(output_img[[2, 1, 0], :, :], (1, 2, 0))\n",
    "    def f_squeeze(A):\n",
    "        def fcompute(c, x, y):\n",
    "            return A[0, c, x, y]\n",
    "        return te.compute((3, 2560, 1792), fcompute, name=\"squeeze\")\n",
    "\n",
    "    def f_swapchannel(A):\n",
    "        def fcompute(c, x, y):\n",
    "            return A[2-c, x, y]\n",
    "        return te.compute((3, 2560, 1792), fcompute, name=\"swapnnel\")\n",
    "    \n",
    "    def f_transpose(A):\n",
    "        def fcompute(x, y, c):\n",
    "            return A[c, x, y]\n",
    "        return te.compute((2560, 1792, 3), fcompute, name=\"transpose\")\n",
    "    \n",
    "    def f_max_0(A):\n",
    "        def fcompute(c, x, y):\n",
    "            return te.if_then_else(A[c, x, y] > te.const(0, \"float32\"), A[c, x, y], te.const(0, \"float32\"))\n",
    "        return te.compute((3, 2560, 1792), fcompute, name=\"max0\")\n",
    "    \n",
    "    def f_min_1(A):\n",
    "        def fcompute(c, x, y):\n",
    "            return te.if_then_else(A[c, x, y] < te.const(1, \"float32\"), A[c, x, y], te.const(1, \"float32\"))\n",
    "        return te.compute((3, 2560, 1792), fcompute, name=\"min1\")\n",
    "\n",
    "\n",
    "    bb = relax.BlockBuilder()\n",
    "    x = relax.Var(\"x\", R.Tensor([1, 3, 2560, 1792], \"float32\"))\n",
    "    with bb.function(\"postprocess\", [x]):\n",
    "        #squeeze\n",
    "        squeezed = bb.emit(bb.call_te(f_squeeze, x, primfunc_name_hint=\"tir_squeeze\"))\n",
    "        #clamp\n",
    "        maxed = bb.emit(bb.call_te(f_max_0, squeezed, primfunc_name_hint=\"tir_max_0\"))\n",
    "        clamped = bb.emit(bb.call_te(f_min_1, maxed, primfunc_name_hint=\"tir_min_1\"))\n",
    "        #rgb swap\n",
    "        swapped = bb.emit(bb.call_te(f_swapchannel, clamped, primfunc_name_hint=\"tir_swapchannel\"))\n",
    "        #transpose\n",
    "        out_image = bb.emit(bb.call_te(f_transpose, swapped, primfunc_name_hint=\"tir_transpose\"))\n",
    "\n",
    "        bb.emit_func_output(out_image)\n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unscale_image() -> tvm.IRModule:\n",
    "    from tvm import te\n",
    "    #divide each element by 255\n",
    "    #todo: different sizes of images\n",
    "    def f_unscale_image(A):\n",
    "        def fcompute(y, x, c):\n",
    "            return te.round(A[y, x, c] * 255).astype(\"uint8\")\n",
    "\n",
    "        return te.compute((2560, 1792, 3), fcompute, name=\"unscale_image\")\n",
    "\n",
    "    bb = relax.BlockBuilder()\n",
    "    x = relax.Var(\"x\", R.Tensor([2560, 1792, 3], \"float32\"))\n",
    "    with bb.function(\"unscale_image\", [x]):\n",
    "        image = bb.emit(\n",
    "            bb.call_te(f_unscale_image, x, primfunc_name_hint=\"tir_unscale_image\")\n",
    "        )\n",
    "        bb.emit_func_output(image)\n",
    "    return bb.get()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put Module together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. scale image\n",
    "scale = scale_image()\n",
    "\n",
    "#2. preprocess image\n",
    "pre_pro = preprocess()\n",
    "\n",
    "# 3. model inference\n",
    "loadnet = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(loadnet['params_ema'], strict=True)\n",
    "rrdb = rrdb_net(model)\n",
    "\n",
    "#4. post process\n",
    "post_pro = postprocess()\n",
    "\n",
    "#5. un-scale image\n",
    "unscale = unscale_image()\n",
    "\n",
    "#---------------------merge together---------------------\n",
    "def merge_irmodules(*irmodules: tvm.IRModule) -> tvm.IRModule:\n",
    "    merged_mod = tvm.IRModule()\n",
    "\n",
    "    for mod in irmodules:\n",
    "        for gv, func in mod.functions.items():\n",
    "            merged_mod[gv] = func\n",
    "    return merged_mod\n",
    "\n",
    "mod: tvm.IRModule = merge_irmodules(\n",
    "    scale,\n",
    "    pre_pro,\n",
    "    rrdb,\n",
    "    post_pro,\n",
    "    unscale\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seperate model and params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod, params = relax.frontend.detach_params(mod)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_image\n",
      "rrdb_transform_params  # <=== This is the weight parameter computation function for \"rrdb\"\n",
      "preprocess\n",
      "rrdb\n",
      "postprocess\n",
      "unscale_image\n"
     ]
    }
   ],
   "source": [
    "mod = relax.pipeline.get_pipeline()(mod)\n",
    "\n",
    "entry_funcs = [\"scale_image\", \"preprocess\", \"rrdb\", \"postprocess\", \"unscale_image\"]\n",
    "mod = relax.transform.DeadCodeElimination(entry_funcs)(mod)\n",
    "\n",
    "mod = relax.transform.LiftTransformParams()(mod)\n",
    "\n",
    "for global_var, function in mod.functions.items():\n",
    "    if isinstance(function, relax.Function):\n",
    "        if global_var.name_hint.endswith(\"_transform_params\"):\n",
    "            print(\n",
    "                global_var.name_hint,\n",
    "                f' # <=== This is the weight parameter computation function for \"{global_var.name_hint[:-17]}\"',\n",
    "            )\n",
    "        else:\n",
    "            print(global_var.name_hint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split build and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In IRModule for build stage:\n",
      "rrdb_transform_params\n",
      "\n",
      "In IRModule for deployment stage:\n",
      "scale_image\n",
      "preprocess\n",
      "rrdb\n",
      "postprocess\n",
      "unscale_image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_relax_funcnames(mod: tvm.IRModule):\n",
    "    for global_var, func in mod.functions.items():\n",
    "        if isinstance(func, relax.Function):\n",
    "            print(global_var.name_hint)\n",
    "    print()\n",
    "\n",
    "def split_transform_deploy_mod(\n",
    "    mod: tvm.IRModule, model_names: List[str], mod_deploy_entry_func: List[str]\n",
    ") -> Tuple[tvm.IRModule, tvm.IRModule]:\n",
    "    mod_transform = tvm.IRModule()\n",
    "    mod_deploy = tvm.IRModule()\n",
    "\n",
    "    transform_func_names = [name + \"_transform_params\" for name in model_names]\n",
    "    for gv in mod.functions:\n",
    "        func = mod[gv]\n",
    "        if isinstance(func, tvm.tir.PrimFunc):\n",
    "            mod_transform[gv] = func\n",
    "            mod_deploy[gv] = func\n",
    "        elif gv.name_hint in transform_func_names:\n",
    "            mod_transform[gv] = func\n",
    "        else:\n",
    "            mod_deploy[gv] = func\n",
    "\n",
    "    mod_transform = relax.transform.DeadCodeElimination(transform_func_names)(\n",
    "        mod_transform\n",
    "    )\n",
    "    mod_deploy = relax.transform.DeadCodeElimination(mod_deploy_entry_func)(\n",
    "        mod_deploy\n",
    "    )\n",
    "\n",
    "    return mod_transform, mod_deploy\n",
    "\n",
    "model_names = [\"rrdb\"]\n",
    "\n",
    "mod_transform, mod_deploy = split_transform_deploy_mod(\n",
    "    mod, model_names, entry_funcs\n",
    ")\n",
    "\n",
    "print(\"In IRModule for build stage:\")\n",
    "print_relax_funcnames(mod_transform)\n",
    "\n",
    "print(\"In IRModule for deployment stage:\")\n",
    "print_relax_funcnames(mod_deploy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start storing to cache dist/params\n",
      "[0702/0702] saving rrdb_701\n",
      "All finished, 1 total shards committed, record saved to dist/params/ndarray-cache.json\n",
      "Also saved a bf16 record to dist/params/ndarray-cache-b16.json\n"
     ]
    }
   ],
   "source": [
    "def transform_params(\n",
    "    mod_transform: tvm.IRModule, model_params: Dict[str, List[tvm.nd.NDArray]]\n",
    ") -> Dict[str, List[tvm.nd.NDArray]]:\n",
    "    ex = relax.build(mod_transform, target=\"llvm\")\n",
    "    vm = relax.vm.VirtualMachine(ex, tvm.cpu())\n",
    "    new_params = dict()\n",
    "    for name, params in model_params.items():\n",
    "        new_params[name] = vm[name + \"_transform_params\"](params)\n",
    "    return new_params\n",
    "\n",
    "\n",
    "def save_params(params: Dict[str, List[tvm.nd.NDArray]], artifact_path: str) -> None:\n",
    "    from tvm.contrib import tvmjs\n",
    "\n",
    "    meta_data = {}\n",
    "    param_dict = {}\n",
    "    for model in [\"rrdb\"]:\n",
    "        meta_data[f\"{model}ParamSize\"] = len(params[model])\n",
    "        for i, nd in enumerate(params[model]):\n",
    "            param_dict[f\"{model}_{i}\"] = nd\n",
    "    tvmjs.dump_ndarray_cache(param_dict, f\"{artifact_path}/params\", meta_data=meta_data)\n",
    "\n",
    "new_params = transform_params(mod_transform, params)\n",
    "save_params(new_params, artifact_path=\"dist\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tvm.target.Target(\"apple/m2-gpu\")\n",
    "device = tvm.metal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm import meta_schedule as ms\n",
    "\n",
    "db = ms.database.create(work_dir=\"log_db\")\n",
    "with target, db, tvm.transform.PassContext(opt_level=3):\n",
    "    mod_deploy = relax.transform.MetaScheduleApplyDatabase()(mod_deploy)\n",
    "    mod_deploy = tvm.tir.transform.DefaultGPUSchedule()(mod_deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:18:03] /Users/guoyaoli/tvm_work/tvm/src/runtime/metal/metal_device_api.mm:165: Intializing Metal device 0, name=Apple M2 Max\n"
     ]
    }
   ],
   "source": [
    "ex = relax.build(mod=mod_deploy, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.export_library(\"dist/real_esrgan.so\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tvm.target.Target(\"apple/m2-gpu\")\n",
    "device = tvm.metal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(artifact_path: str, device) -> Dict[str, List[tvm.nd.NDArray]]:\n",
    "    from tvm.contrib import tvmjs\n",
    "\n",
    "    pdict = {}\n",
    "    params, meta = tvmjs.load_ndarray_cache(f\"{artifact_path}/params\", device)\n",
    "    for model in [\"rrdb\"]:\n",
    "        plist = []\n",
    "        size = meta[f\"{model}ParamSize\"]\n",
    "        for i in range(size):\n",
    "            plist.append(params[f\"{model}_{i}\"])\n",
    "        pdict[model] = plist\n",
    "    return pdict\n",
    "\n",
    "const_params_dict = load_params(artifact_path=\"dist\", device=device)\n",
    "ex = tvm.runtime.load_module(\"dist/real_esrgan.so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm = relax.VirtualMachine(rt_mod=ex, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Real-ESRGAN pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVMESRPipeline:\n",
    "    def __init__(\n",
    "        self,\n",
    "        vm: relax.VirtualMachine,\n",
    "        tvm_device,\n",
    "        param_dict,\n",
    "    ):\n",
    "        def wrapper(f, params):\n",
    "            def wrapped_f(*args):\n",
    "                return f(*args, params)\n",
    "\n",
    "            return wrapped_f\n",
    "\n",
    "        self.vm = vm\n",
    "        \n",
    "        self.rrdb = wrapper(vm[\"rrdb\"], param_dict[\"rrdb\"])\n",
    "        \n",
    "        self.scale_image = vm[\"scale_image\"]\n",
    "        self.preprocess = vm[\"preprocess\"]\n",
    "        self.unscale_image = vm[\"unscale_image\"]\n",
    "        self.postprocess = vm[\"postprocess\"]\n",
    "\n",
    "        self.tvm_device = tvm_device\n",
    "        self.param_dict = param_dict\n",
    "\n",
    "    def __call__(self, input_image: np.array):\n",
    "        image = tvm.nd.array(input_image, device=self.tvm_device)\n",
    "        image = self.scale_image(image)\n",
    "        image = self.preprocess(image)\n",
    "        image = self.rrdb(image)\n",
    "        image = self.postprocess(image)\n",
    "        image = self.unscale_image(image)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = TVMESRPipeline(vm, device, const_params_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"./input/OST_009.png\"\n",
    "output_path = \"./output\"\n",
    "\n",
    "imgname, extension = os.path.splitext(os.path.basename(input_path))\n",
    "img = cv2.imread(input_path, cv2.IMREAD_UNCHANGED)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img = img.astype(np.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "through the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  [bt] (8) 9   libtvm.dylib                        0x00000002a914a128 tvm::runtime::relax_vm::VirtualMachineImpl::InvokeClosurePacked(tvm::runtime::ObjectRef const&, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) + 96\n  [bt] (7) 8   real_esrgan.so                      0x00000002a69dc678 fused_conv2d7_add3_leaky_relu1_compute_ + 96\n  [bt] (6) 7   libtvm.dylib                        0x00000002a9189f94 tvm::runtime::WorkspacePool::AllocWorkspace(DLDevice, unsigned long) + 236\n  [bt] (5) 6   libtvm.dylib                        0x00000002a918a078 tvm::runtime::WorkspacePool::Pool::Alloc(DLDevice, tvm::runtime::DeviceAPI*, unsigned long) + 160\n  [bt] (4) 5   libtvm.dylib                        0x00000002a91de1e8 tvm::runtime::metal::MetalWorkspace::FreeDataSpace(DLDevice, void*) + 52\n  [bt] (3) 4   libtvm.dylib                        0x00000002a91deeb8 tvm::runtime::metal::MetalWorkspace::StreamSync(DLDevice, void*) + 264\n  [bt] (2) 3   libtvm.dylib                        0x00000002a723cc74 __clang_call_terminate + 0\n  [bt] (1) 2   libtvm.dylib                        0x00000002a723ed08 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0\n  [bt] (0) 1   libtvm.dylib                        0x00000002a723ed5c tvm::runtime::detail::LogFatal::Entry::Finalize() + 84\n  File \"/Users/guoyaoli/tvm_work/tvm/src/runtime/metal/metal_device_api.mm\", line 308\nTVMError: Error! Some problems on GPU happaned!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[39m=\u001b[39m pipe(img)\n",
      "Cell \u001b[0;32mIn[21], line 30\u001b[0m, in \u001b[0;36mTVMESRPipeline.__call__\u001b[0;34m(self, input_image)\u001b[0m\n\u001b[1;32m     28\u001b[0m image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_image(image)\n\u001b[1;32m     29\u001b[0m image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(image)\n\u001b[0;32m---> 30\u001b[0m image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrrdb(image)\n\u001b[1;32m     31\u001b[0m image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(image)\n\u001b[1;32m     32\u001b[0m image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munscale_image(image)\n",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m, in \u001b[0;36mTVMESRPipeline.__init__.<locals>.wrapper.<locals>.wrapped_f\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, params)\n",
      "File \u001b[0;32m~/tvm_work/tvm/python/tvm/_ffi/_ctypes/packed_func.py:238\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    226\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    228\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    229\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    237\u001b[0m ):\n\u001b[0;32m--> 238\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    240\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  [bt] (8) 9   libtvm.dylib                        0x00000002a914a128 tvm::runtime::relax_vm::VirtualMachineImpl::InvokeClosurePacked(tvm::runtime::ObjectRef const&, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) + 96\n  [bt] (7) 8   real_esrgan.so                      0x00000002a69dc678 fused_conv2d7_add3_leaky_relu1_compute_ + 96\n  [bt] (6) 7   libtvm.dylib                        0x00000002a9189f94 tvm::runtime::WorkspacePool::AllocWorkspace(DLDevice, unsigned long) + 236\n  [bt] (5) 6   libtvm.dylib                        0x00000002a918a078 tvm::runtime::WorkspacePool::Pool::Alloc(DLDevice, tvm::runtime::DeviceAPI*, unsigned long) + 160\n  [bt] (4) 5   libtvm.dylib                        0x00000002a91de1e8 tvm::runtime::metal::MetalWorkspace::FreeDataSpace(DLDevice, void*) + 52\n  [bt] (3) 4   libtvm.dylib                        0x00000002a91deeb8 tvm::runtime::metal::MetalWorkspace::StreamSync(DLDevice, void*) + 264\n  [bt] (2) 3   libtvm.dylib                        0x00000002a723cc74 __clang_call_terminate + 0\n  [bt] (1) 2   libtvm.dylib                        0x00000002a723ed08 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0\n  [bt] (0) 1   libtvm.dylib                        0x00000002a723ed5c tvm::runtime::detail::LogFatal::Entry::Finalize() + 84\n  File \"/Users/guoyaoli/tvm_work/tvm/src/runtime/metal/metal_device_api.mm\", line 308\nTVMError: Error! Some problems on GPU happaned!"
     ]
    }
   ],
   "source": [
    "output = pipe(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result = output.numpy().astype(np.uint8)\n",
    "cv2.imwrite(\"./output/TVM_output.png\", final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
