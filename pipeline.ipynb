{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/guoyaol/web-real-esrgan', '/home/guoyaol/.conda/envs/esr/lib/python38.zip', '/home/guoyaol/.conda/envs/esr/lib/python3.8', '/home/guoyaol/.conda/envs/esr/lib/python3.8/lib-dynload', '', '/home/guoyaol/.local/lib/python3.8/site-packages', '/home/guoyaol/.conda/envs/esr/lib/python3.8/site-packages', '/home/guoyaol/Real-ESRGAN', '/home/guoyaol/tvm/python/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/guoyaol/tvm/python/\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "from network import RRDBNet\n",
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.script import relax as R\n",
    "from tvm.relax.frontend.torch import dynamo_capture_subgraphs\n",
    "import torch\n",
    "from typing import Dict, List, Tuple\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"./input/OST_009.png\"\n",
    "output_path = \"./output\"\n",
    "\n",
    "imgname, extension = os.path.splitext(os.path.basename(input_path))\n",
    "img = cv2.imread(input_path, cv2.IMREAD_UNCHANGED)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "netscale = 4\n",
    "model_path = \"./weights/RealESRGAN_x4plus.pth\"\n",
    "model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
    "outscale = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrdb_net(model) -> tvm.IRModule:\n",
    "\n",
    "    class RRDBNetWrapper(torch.nn.Module):\n",
    "        def __init__(self, rrdb):\n",
    "            super().__init__()\n",
    "            self.rrdb = rrdb\n",
    "\n",
    "        def forward(self, input):\n",
    "            output = self.rrdb(input)\n",
    "            return output\n",
    "\n",
    "    rrdb = RRDBNetWrapper(model)\n",
    "\n",
    "    #todo: change size\n",
    "    z = torch.rand((1, 3, 640, 448), dtype=torch.float32)\n",
    "\n",
    "    mod = dynamo_capture_subgraphs(\n",
    "        rrdb.forward,\n",
    "        z,\n",
    "        keep_params_as_input=True,\n",
    "    )\n",
    "    assert len(mod.functions) == 1\n",
    "\n",
    "    return tvm.IRModule({\"rrdb\": mod[\"subgraph_0\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image() -> tvm.IRModule:\n",
    "    from tvm import te\n",
    "    #divide each element by 255\n",
    "    #todo: different sizes of images\n",
    "    def f_scale_image(A):\n",
    "        def fcompute(x, y, c):\n",
    "            return A[x, y, c] / te.const(255, \"float32\")\n",
    "\n",
    "        return te.compute((640, 448, 3), fcompute, name=\"scale_image\")\n",
    "\n",
    "    bb = relax.BlockBuilder()\n",
    "    x = relax.Var(\"x\", R.Tensor([640, 448, 3], \"float32\"))\n",
    "    with bb.function(\"scale_image\", [x]):\n",
    "        image = bb.emit(\n",
    "            bb.call_te(f_scale_image, x, primfunc_name_hint=\"tir_scale_image\")\n",
    "        )\n",
    "        bb.emit_func_output(image)\n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess() -> tvm.IRModule:\n",
    "    from tvm import te\n",
    "    #np.transpose(img, (2, 0, 1)) and unqueeze(0)\n",
    "    #todo: different sizes of images\n",
    "    def f_preprocess(A):\n",
    "        def fcompute(i, c, x, y):\n",
    "            return A[x, y, c]\n",
    "        return te.compute((1, 3, 640, 448), fcompute, name=\"preprocess\")\n",
    "\n",
    "\n",
    "    bb = relax.BlockBuilder()\n",
    "    x = relax.Var(\"x\", R.Tensor([640, 448, 3], \"float32\"))\n",
    "    with bb.function(\"preprocess\", [x]):\n",
    "        image = bb.emit(\n",
    "            bb.call_te(f_preprocess, x, primfunc_name_hint=\"tir_preprocess\")\n",
    "        )\n",
    "        bb.emit_func_output(image)\n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess() -> tvm.IRModule:\n",
    "    from tvm import te\n",
    "    # output_img = output_img.data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "    # output_img = np.transpose(output_img[[2, 1, 0], :, :], (1, 2, 0))\n",
    "    def f_squeeze(A):\n",
    "        def fcompute(c, x, y):\n",
    "            return A[0, c, x, y]\n",
    "        return te.compute((3, 2560, 1792), fcompute, name=\"squeeze\")\n",
    "\n",
    "    def f_swapchannel(A):\n",
    "        def fcompute(c, x, y):\n",
    "            return A[2-c, x, y]\n",
    "        return te.compute((3, 2560, 1792), fcompute, name=\"swapnnel\")\n",
    "    \n",
    "    def f_transpose(A):\n",
    "        def fcompute(x, y, c):\n",
    "            return A[c, x, y]\n",
    "        return te.compute((2560, 1792, 3), fcompute, name=\"transpose\")\n",
    "    \n",
    "    def f_max_0(A):\n",
    "        def fcompute(c, x, y):\n",
    "            return te.if_then_else(A[c, x, y] > te.const(0, \"float32\"), A[c, x, y], te.const(0, \"float32\"))\n",
    "        return te.compute((3, 2560, 1792), fcompute, name=\"max0\")\n",
    "    \n",
    "    def f_min_1(A):\n",
    "        def fcompute(c, x, y):\n",
    "            return te.if_then_else(A[c, x, y] < te.const(1, \"float32\"), A[c, x, y], te.const(1, \"float32\"))\n",
    "        return te.compute((3, 2560, 1792), fcompute, name=\"min1\")\n",
    "\n",
    "\n",
    "    bb = relax.BlockBuilder()\n",
    "    x = relax.Var(\"x\", R.Tensor([1, 3, 2560, 1792], \"float32\"))\n",
    "    with bb.function(\"postprocess\", [x]):\n",
    "        #squeeze\n",
    "        squeezed = bb.emit(bb.call_te(f_squeeze, x, primfunc_name_hint=\"tir_squeeze\"))\n",
    "        #clamp\n",
    "        maxed = bb.emit(bb.call_te(f_max_0, squeezed, primfunc_name_hint=\"tir_max_0\"))\n",
    "        clamped = bb.emit(bb.call_te(f_min_1, maxed, primfunc_name_hint=\"tir_min_1\"))\n",
    "        #rgb swap\n",
    "        swapped = bb.emit(bb.call_te(f_swapchannel, clamped, primfunc_name_hint=\"tir_swapchannel\"))\n",
    "        #transpose\n",
    "        out_image = bb.emit(bb.call_te(f_transpose, swapped, primfunc_name_hint=\"tir_transpose\"))\n",
    "\n",
    "        bb.emit_func_output(out_image)\n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unscale_image() -> tvm.IRModule:\n",
    "    from tvm import te\n",
    "    #divide each element by 255\n",
    "    #todo: different sizes of images\n",
    "    def f_unscale_image(A):\n",
    "        def fcompute(y, x, c):\n",
    "            return te.round(A[y, x, c] * 255).astype(\"uint8\")\n",
    "\n",
    "        return te.compute((640, 448, 3), fcompute, name=\"unscale_image\")\n",
    "\n",
    "    bb = relax.BlockBuilder()\n",
    "    x = relax.Var(\"x\", R.Tensor([640, 448, 3], \"float32\"))\n",
    "    with bb.function(\"unscale_image\", [x]):\n",
    "        image = bb.emit(\n",
    "            bb.call_te(f_unscale_image, x, primfunc_name_hint=\"tir_unscale_image\")\n",
    "        )\n",
    "        bb.emit_func_output(image)\n",
    "    return bb.get()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put Module together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. scale image\n",
    "scale = scale_image()\n",
    "\n",
    "#2. preprocess image\n",
    "pre_pro = preprocess()\n",
    "\n",
    "# 3. model inference\n",
    "loadnet = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(loadnet['params_ema'], strict=True)\n",
    "rrdb = rrdb_net(model)\n",
    "\n",
    "#4. post process\n",
    "post_pro = postprocess()\n",
    "\n",
    "#5. un-scale image\n",
    "unscale = unscale_image()\n",
    "\n",
    "#---------------------merge together---------------------\n",
    "def merge_irmodules(*irmodules: tvm.IRModule) -> tvm.IRModule:\n",
    "    merged_mod = tvm.IRModule()\n",
    "\n",
    "    for mod in irmodules:\n",
    "        for gv, func in mod.functions.items():\n",
    "            merged_mod[gv] = func\n",
    "    return merged_mod\n",
    "\n",
    "mod: tvm.IRModule = merge_irmodules(\n",
    "    scale,\n",
    "    pre_pro,\n",
    "    rrdb,\n",
    "    post_pro,\n",
    "    unscale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
