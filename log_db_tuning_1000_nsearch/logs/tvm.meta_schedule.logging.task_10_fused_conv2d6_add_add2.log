2023-05-18 11:57:30 [INFO] [task_scheduler.cc:160] Initializing Task #10: "fused_conv2d6_add_add2"
2023-05-18 11:57:30 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv1773: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), self_rrdb_conv_body_weight: T.Buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), "float32"), lv1775: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1)), "float32"), lv2: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(642), T.int64(450)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(64), T.int64(642), T.int64(450)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv1773[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(641) and T.int64(1) <= v_i3 and v_i3 < T.int64(449), lv1773[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(64), T.int64(640), T.int64(448), T.int64(64), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_conv_body_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_conv_body_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(64), T.int64(640), T.int64(448)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv1775[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv1775[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(64), T.int64(640), T.int64(448)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv2[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv2[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]
2023-05-18 11:57:30 [INFO] [task_scheduler.cc:164] Total 1 design space(s) generated
2023-05-18 11:57:30 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv1773: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), self_rrdb_conv_body_weight: T.Buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), "float32"), lv1775: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1)), "float32"), lv2: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 512})
            var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), scope="local")
            pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(642), T.int64(450)), scope="shared")
            self_rrdb_conv_body_weight_shared = T.alloc_buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), scope="shared")
            for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(28), thread="blockIdx.x"):
                for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(2560), thread="vthread.x"):
                    for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                        for rc_0, ry_0, rx_0 in T.grid(T.int64(4), T.int64(1), T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(171072)):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(64), rc_0 * T.int64(16) + ax0_ax1_ax2_ax3_fused // T.int64(10692))
                                    v2 = T.axis.spatial(T.int64(642), nn_0_ff_0_yy_0_xx_0_fused // T.int64(7) * T.int64(160) + ax0_ax1_ax2_ax3_fused % T.int64(10692) // T.int64(66))
                                    v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(7) * T.int64(64) + ax0_ax1_ax2_ax3_fused % T.int64(66))
                                    T.reads(lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(9216)):
                                with T.block("self_rrdb_conv_body.weight_shared"):
                                    v0 = T.axis.spatial(T.int64(64), ax0_ax1_ax2_ax3_fused // T.int64(144))
                                    v1 = T.axis.spatial(T.int64(64), rc_0 * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(144) // T.int64(9))
                                    v2 = T.axis.spatial(T.int64(3), ax0_ax1_ax2_ax3_fused % T.int64(9) // T.int64(3))
                                    v3 = T.axis.spatial(T.int64(3), ax0_ax1_ax2_ax3_fused % T.int64(3))
                                    T.reads(self_rrdb_conv_body_weight[v0, v1, v2, v3])
                                    T.writes(self_rrdb_conv_body_weight_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                    self_rrdb_conv_body_weight_shared[v0, v1, v2, v3] = self_rrdb_conv_body_weight[v0, v1, v2, v3]
                            for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                                with T.block("conv2d_nchw"):
                                    v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                    v_ff = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused // T.int64(320) * T.int64(8) + ff_3 * T.int64(4) + ff_4)
                                    v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(7) * T.int64(160) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(320) // T.int64(16) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused + yy_3 + yy_4)
                                    v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(7) * T.int64(64) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(16) * T.int64(4) + xx_3 + xx_4)
                                    v_rc = T.axis.reduce(T.int64(64), rc_0 * T.int64(16) + rc_1 * T.int64(16) + rc_2)
                                    v_ry = T.axis.reduce(T.int64(3), ry_0 * T.int64(3) + ry_1 * T.int64(3) + ry_2)
                                    v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 + rx_2)
                                    T.reads(pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                    T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                                    var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(4)):
                            with T.block("var_conv2d_nchw_intermediate_local"):
                                v0 = T.axis.spatial(T.int64(1), ax0)
                                v1 = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused // T.int64(320) * T.int64(8) + ax1)
                                v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(7) * T.int64(160) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(320) // T.int64(16) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused + ax2)
                                v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(7) * T.int64(64) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(16) * T.int64(4) + ax3)
                                T.reads(lv2[v0, v1, v2, v3], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv1775[v0, v1, T.int64(0), T.int64(0)])
                                T.writes(var_T_add_intermediate[v0, v1, v2, v3])
                                var_T_add_intermediate[v0, v1, v2, v3] = lv2[v0, v1, v2, v3] + (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv1775[v0, v1, T.int64(0), T.int64(0)])
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 8, 1, 2, 4])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[4, 20, 8, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[7, 16, 1, 4, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[4, 1, 16])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
2023-05-18 11:59:23 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 11:59:23 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2023-05-18 11:59:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 507 failure(s)
2023-05-18 11:59:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1010 failure(s)
2023-05-18 11:59:27 [INFO] [evolutionary_search.cc:723] Sampled 14 candidate(s)
2023-05-18 11:59:31 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 106 failure(s)
2023-05-18 11:59:35 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 102 failure(s)
2023-05-18 11:59:39 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 101 failure(s)
2023-05-18 11:59:43 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 96 failure(s)
2023-05-18 11:59:43 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9981  0.9971  0.9963  0.9962  0.9961  0.9944  0.9943  0.9937  0.9933  0.9913  0.9898  0.9854  0.9841  0.9840  0.9839  0.9833
[17 : 32]:	0.9832  0.9813  0.9813  0.9799  0.9791  0.9781  0.9762  0.9761  0.9759  0.9757  0.9744  0.9744  0.9744  0.9718  0.9704  0.9701
[33 : 48]:	0.9700  0.9696  0.9685  0.9641  0.9633  0.9629  0.9621  0.9617  0.9616  0.9611  0.9610  0.9602  0.9576  0.9567  0.9561  0.9534
[49 : 64]:	0.9524  0.9516  0.9513  0.9506  0.9499  0.9495  0.9474  0.9466  0.9462  0.9451  0.9449  0.9442  0.9442  0.9435  0.9435  0.9431
2023-05-18 11:59:43 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 11:59:43 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #1: GFLOPs: 186.3252. Time: 113650.7223 us. Best GFLOPs: 186.3252
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #2: GFLOPs: 484.4167. Time: 43714.4167 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #3: GFLOPs: 10.3114. Time: 2053648.1113 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #4: GFLOPs: 10.3578. Time: 2044452.4860 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:121] [Task #10: fused_conv2d6_add_add2] Trial #5: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x0000000116cff4ff
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:109
      int2 v__1 = ((int2((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)), (((((int)threadIdx) / 3) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 109
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[12:13:42] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: Fail to compile metal source:program_source:34:161: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
program_source:34:683: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__1 = ((int2((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)), (((((int)threadIdx) / 3) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:34:1174: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__1 = ((int2((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)), (((((int)threadIdx) / 3) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:34:1649: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__1 = ((int2((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)), (((((int)threadIdx) / 3) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:34:2184: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__1 = ((int2((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)), (((((int)threadIdx) / 3) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:36:187: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__2 = ((int2((((((((int)threadIdx) * 2) + 64) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 64) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:36:765: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__2 = ((int2((((((((int)threadIdx) * 2) + 64) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 64) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:36:1312: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__2 = ((int2((((((((int)threadIdx) * 2) + 64) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 64) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:36:1843: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__2 = ((int2((((((((int)threadIdx) * 2) + 64) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 64) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:36:2434: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__2 = ((int2((((((((int)threadIdx) * 2) + 64) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 64) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 64))+(1*0), (((((int)threadIdx) * 2) + 64))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:38:189: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__3 = ((int2((((((((int)threadIdx) * 2) + 128) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 128) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:38:775: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__3 = ((int2((((((((int)threadIdx) * 2) + 128) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 128) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:38:1330: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__3 = ((int2((((((((int)threadIdx) * 2) + 128) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 128) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:38:1869: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__3 = ((int2((((((((int)threadIdx) * 2) + 128) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 128) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:38:2468: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__3 = ((int2((((((((int)threadIdx) * 2) + 128) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 128) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:40:181: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__4 = ((int2(((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)) + 18432), ((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)) + 18432)) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:40:767: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__4 = ((int2(((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)) + 18432), ((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)) + 18432)) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:40:1322: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__4 = ((int2(((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)) + 18432), ((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)) + 18432)) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:40:1861: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__4 = ((int2(((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)) + 18432), ((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)) + 18432)) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:40:2460: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__4 = ((int2(((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)) + 18432), ((((((int)threadIdx) / 3) * 576) + (rc_0 * 18)) + 18432)) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 192))+(1*0), (((((int)threadIdx) * 2) + 192))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:42:189: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__5 = ((int2((((((((int)threadIdx) * 2) + 256) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 256) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:42:775: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__5 = ((int2((((((((int)threadIdx) * 2) + 256) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 256) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:42:1330: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__5 = ((int2((((((((int)threadIdx) * 2) + 256) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 256) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:42:1869: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__5 = ((int2((((((((int)threadIdx) * 2) + 256) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 256) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:42:2468: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__5 = ((int2((((((((int)threadIdx) * 2) + 256) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 256) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:44:189: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__6 = ((int2((((((((int)threadIdx) * 2) + 320) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 320) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:44:775: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__6 = ((int2((((((((int)threadIdx) * 2) + 320) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 320) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:44:1330: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__6 = ((int2((((((((int)threadIdx) * 2) + 320) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 320) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:44:1869: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__6 = ((int2((((((((int)threadIdx) * 2) + 320) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 320) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:44:2468: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__6 = ((int2((((((((int)threadIdx) * 2) + 320) / 6) * 576) + (rc_0 * 18)), (((((((int)threadIdx) * 2) + 320) / 6) * 576) + (rc_0 * 18))) + (((((int2(2, 2) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) >= int2(0, 0))) || ((int2(2, 2) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(2, 2)) + int2(2, 2))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 320))+(1*0), (((((int)threadIdx) * 2) + 320))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv1773: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), self_rrdb_conv_body_weight: T.Buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), "float32"), lv1775: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1)), "float32"), lv2: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_conv_body_weight_shared = T.alloc_buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(320), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(112), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused // T.int64(28) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(28) // T.int64(7) * T.int64(2) + yy_3_init * T.int64(2) + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) * T.int64(112) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(4) + xx_3_init + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(32), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(57)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(64), rc_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(912))
                                    v2 = T.axis.spatial(T.int64(642), ry_0 + nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(912) // T.int64(114))
                                    v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) * T.int64(112) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(114))
                                    T.reads(lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(6)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("self_rrdb_conv_body.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(6))
                                        v1 = T.axis.spatial(T.int64(64), rc_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(6) // T.int64(3))
                                        v2 = T.axis.spatial(T.int64(3), ry_0)
                                        v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        T.reads(self_rrdb_conv_body_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_conv_body_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_conv_body_weight_shared[v0, v1, v2, v3] = self_rrdb_conv_body_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused // T.int64(28) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(28) // T.int64(7) * T.int64(2) + yy_3 * T.int64(2) + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) * T.int64(112) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(4) + xx_3 + xx_4)
                                v_rc = T.axis.reduce(T.int64(64), rc_0 * T.int64(2) + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(4)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused // T.int64(28) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(28) // T.int64(7) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) * T.int64(112) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(4) + ax3)
                            T.reads(lv2[v0, v1, v2, v3], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv1775[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_T_add_intermediate[v0, v1, v2, v3])
                            var_T_add_intermediate[v0, v1, v2, v3] = lv2[v0, v1, v2, v3] + (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv1775[v0, v1, T.int64(0), T.int64(0)])
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 4, 8, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[80, 4, 1, 1, 2])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[4, 7, 4, 4, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[32, 2, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #6: GFLOPs: 23.7457. Time: 891781.1803 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #7: GFLOPs: 5.7213. Time: 3701272.7500 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #8: GFLOPs: 46.5413. Time: 454993.7640 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #9: GFLOPs: 6.2612. Time: 3382095.2917 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #10: GFLOPs: 215.6776. Time: 98183.5557 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #11: GFLOPs: 272.4950. Time: 77711.5000 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #12: GFLOPs: 47.2543. Time: 448127.9303 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #13: GFLOPs: 9.1349. Time: 2318152.0000 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #14: GFLOPs: 16.1168. Time: 1313909.6527 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #15: GFLOPs: 102.2529. Time: 207094.2360 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #16: GFLOPs: 48.7548. Time: 434336.6667 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #17: GFLOPs: 46.0649. Time: 459699.0417 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #18: GFLOPs: 472.6523. Time: 44802.4720 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #19: GFLOPs: 176.2556. Time: 120143.6387 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #20: GFLOPs: 8.1025. Time: 2613512.8057 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #21: GFLOPs: 101.5665. Time: 208493.7917 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #22: GFLOPs: 20.9462. Time: 1010971.0833 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #23: GFLOPs: 31.4640. Time: 673021.8333 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #24: GFLOPs: 21.0330. Time: 1006800.5000 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #25: GFLOPs: 263.5147. Time: 80359.8193 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #26: GFLOPs: 64.3497. Time: 329076.6390 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #27: GFLOPs: 31.2911. Time: 676742.5973 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #28: GFLOPs: 12.3872. Time: 1709512.5973 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:121] [Task #10: fused_conv2d6_add_add2] Trial #29: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x0000000112ef219f
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:109
      int4 v__1 = (((((((int4(6, 6, 6, 6) >= int4(0, 0, 0, 0)) && ((int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) % int4(6, 6, 6, 6)) >= int4(0, 0, 0, 0))) || ((int4(6, 6, 6, 6) < int4(0, 0, 0, 0)) && ((int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) % int4(6, 6, 6, 6)) <= int4(0, 0, 0, 0)))) ? (int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) / int4(6, 6, 6, 6)) : ((int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) / int4(6, 6, 6, 6)) - int4(1, 1, 1, 1))) * int4(576, 576, 576, 576)) + int4((rc_0 * 18), (rc_0 * 18), (rc_0 * 18), (rc_0 * 18))) + (((((int4(6, 6, 6, 6) >= int4(0, 0, 0, 0)) && ((int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) % int4(6, 6, 6, 6)) >= int4(0, 0, 0, 0))) || ((int4(6, 6, 6, 6) < int4(0, 0, 0, 0)) && ((int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) % int4(6, 6, 6, 6)) <= int4(0, 0, 0, 0)))) ? (int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) % int4(6, 6, 6, 6)) : ((int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) % int4(6, 6, 6, 6)) + int4(6, 6, 6, 6))) * int4(3, 3, 3, 3))) + int4(rx_0, rx_0, rx_0, rx_0);
                      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 109
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[12:15:39] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: Fail to compile metal source:program_source:94:23: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:94:893: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
      int4 v__1 = (((((((int4(6, 6, 6, 6) >= int4(0, 0, 0, 0)) && ((int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) % int4(6, 6, 6, 6)) >= int4(0, 0, 0, 0))) || ((int4(6, 6, 6, 6) < int4(0, 0, 0, 0)) && ((int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) % int4(6, 6, 6, 6)) <= int4(0, 0, 0, 0)))) ? (int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) / int4(6, 6, 6, 6)) : ((int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) / int4(6, 6, 6, 6)) - int4(1, 1, 1, 1))) * int4(576, 576, 576, 576)) + int4((rc_0 * 18), (rc_0 * 18), (rc_0 * 18), (rc_0 * 18))) + (((((int4(6, 6, 6, 6) >= int4(0, 0, 0, 0)) && ((int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) % int4(6, 6, 6, 6)) >= int4(0, 0, 0, 0))) || ((int4(6, 6, 6, 6) < int4(0, 0, 0, 0)) && ((int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) % int4(6, 6, 6, 6)) <= int4(0, 0, 0, 0)))) ? (int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) % int4(6, 6, 6, 6)) : ((int4(((((int)threadIdx) * 4))+(1*0), ((((int)threadIdx) * 4))+(1*1), ((((int)threadIdx) * 4))+(1*2), ((((int)threadIdx) * 4))+(1*3)) % int4(6, 6, 6, 6)) + int4(6, 6, 6, 6))) * int4(3, 3, 3, 3))) + int4(rx_0, rx_0, rx_0, rx_0);
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:96:23: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
      int4 v__2 = (((((((int4(6, 6, 6, 6) >= int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) % int4(6, 6, 6, 6)) >= int4(0, 0, 0, 0))) || ((int4(6, 6, 6, 6) < int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) % int4(6, 6, 6, 6)) <= int4(0, 0, 0, 0)))) ? (int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) / int4(6, 6, 6, 6)) : ((int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) / int4(6, 6, 6, 6)) - int4(1, 1, 1, 1))) * int4(576, 576, 576, 576)) + int4((rc_0 * 18), (rc_0 * 18), (rc_0 * 18), (rc_0 * 18))) + (((((int4(6, 6, 6, 6) >= int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) % int4(6, 6, 6, 6)) >= int4(0, 0, 0, 0))) || ((int4(6, 6, 6, 6) < int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) % int4(6, 6, 6, 6)) <= int4(0, 0, 0, 0)))) ? (int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) % int4(6, 6, 6, 6)) : ((int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) % int4(6, 6, 6, 6)) + int4(6, 6, 6, 6))) * int4(3, 3, 3, 3))) + int4(rx_0, rx_0, rx_0, rx_0);
                      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:96:1021: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
      int4 v__2 = (((((((int4(6, 6, 6, 6) >= int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) % int4(6, 6, 6, 6)) >= int4(0, 0, 0, 0))) || ((int4(6, 6, 6, 6) < int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) % int4(6, 6, 6, 6)) <= int4(0, 0, 0, 0)))) ? (int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) / int4(6, 6, 6, 6)) : ((int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) / int4(6, 6, 6, 6)) - int4(1, 1, 1, 1))) * int4(576, 576, 576, 576)) + int4((rc_0 * 18), (rc_0 * 18), (rc_0 * 18), (rc_0 * 18))) + (((((int4(6, 6, 6, 6) >= int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) % int4(6, 6, 6, 6)) >= int4(0, 0, 0, 0))) || ((int4(6, 6, 6, 6) < int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) % int4(6, 6, 6, 6)) <= int4(0, 0, 0, 0)))) ? (int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) % int4(6, 6, 6, 6)) : ((int4((((((int)threadIdx) * 4) + 128))+(1*0), (((((int)threadIdx) * 4) + 128))+(1*1), (((((int)threadIdx) * 4) + 128))+(1*2), (((((int)threadIdx) * 4) + 128))+(1*3)) % int4(6, 6, 6, 6)) + int4(6, 6, 6, 6))) * int4(3, 3, 3, 3))) + int4(rx_0, rx_0, rx_0, rx_0);
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:98:23: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
      int4 v__3 = (((((((int4(6, 6, 6, 6) >= int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) % int4(6, 6, 6, 6)) >= int4(0, 0, 0, 0))) || ((int4(6, 6, 6, 6) < int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) % int4(6, 6, 6, 6)) <= int4(0, 0, 0, 0)))) ? (int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) / int4(6, 6, 6, 6)) : ((int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) / int4(6, 6, 6, 6)) - int4(1, 1, 1, 1))) * int4(576, 576, 576, 576)) + int4((rc_0 * 18), (rc_0 * 18), (rc_0 * 18), (rc_0 * 18))) + (((((int4(6, 6, 6, 6) >= int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) % int4(6, 6, 6, 6)) >= int4(0, 0, 0, 0))) || ((int4(6, 6, 6, 6) < int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) % int4(6, 6, 6, 6)) <= int4(0, 0, 0, 0)))) ? (int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) % int4(6, 6, 6, 6)) : ((int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) % int4(6, 6, 6, 6)) + int4(6, 6, 6, 6))) * int4(3, 3, 3, 3))) + int4(rx_0, rx_0, rx_0, rx_0);
                      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:98:1021: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
      int4 v__3 = (((((((int4(6, 6, 6, 6) >= int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) % int4(6, 6, 6, 6)) >= int4(0, 0, 0, 0))) || ((int4(6, 6, 6, 6) < int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) % int4(6, 6, 6, 6)) <= int4(0, 0, 0, 0)))) ? (int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) / int4(6, 6, 6, 6)) : ((int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) / int4(6, 6, 6, 6)) - int4(1, 1, 1, 1))) * int4(576, 576, 576, 576)) + int4((rc_0 * 18), (rc_0 * 18), (rc_0 * 18), (rc_0 * 18))) + (((((int4(6, 6, 6, 6) >= int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) % int4(6, 6, 6, 6)) >= int4(0, 0, 0, 0))) || ((int4(6, 6, 6, 6) < int4(0, 0, 0, 0)) && ((int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) % int4(6, 6, 6, 6)) <= int4(0, 0, 0, 0)))) ? (int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) % int4(6, 6, 6, 6)) : ((int4((((((int)threadIdx) * 4) + 256))+(1*0), (((((int)threadIdx) * 4) + 256))+(1*1), (((((int)threadIdx) * 4) + 256))+(1*2), (((((int)threadIdx) * 4) + 256))+(1*3)) % int4(6, 6, 6, 6)) + int4(6, 6, 6, 6))) * int4(3, 3, 3, 3))) + int4(rx_0, rx_0, rx_0, rx_0);
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv1773: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), self_rrdb_conv_body_weight: T.Buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), "float32"), lv1775: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1)), "float32"), lv2: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_conv_body_weight_shared = T.alloc_buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(640), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(8), T.int64(4), T.int64(14), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(64), nn_2_ff_2_yy_2_xx_2_fused // T.int64(8) * T.int64(16) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(8) // T.int64(4) * T.int64(4) + yy_3_init + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(56) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(14) + xx_3_init + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(32), T.int64(1), T.int64(3)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(18)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v1 = T.axis.spatial(T.int64(64), rc_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(560))
                                        v2 = T.axis.spatial(T.int64(642), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(560) // T.int64(56))
                                        v3 = T.axis.spatial(T.int64(450), rx_0 + nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(56) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(56))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(1120))
                                        T.reads(lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("self_rrdb_conv_body.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(6))
                                        v1 = T.axis.spatial(T.int64(64), rc_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(6) // T.int64(3))
                                        v2 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        v3 = T.axis.spatial(T.int64(3), rx_0)
                                        T.reads(self_rrdb_conv_body_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_conv_body_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_conv_body_weight_shared[v0, v1, v2, v3] = self_rrdb_conv_body_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(8), T.int64(4), T.int64(14), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(64), nn_2_ff_2_yy_2_xx_2_fused // T.int64(8) * T.int64(16) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(8) // T.int64(4) * T.int64(4) + yy_3 + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(56) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(14) + xx_3 + xx_4)
                                v_rc = T.axis.reduce(T.int64(64), rc_0 * T.int64(2) + rc_1 * T.int64(2) + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 * T.int64(3) + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 + rx_1 + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(4), T.int64(14)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(64), nn_2_ff_2_yy_2_xx_2_fused // T.int64(8) * T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(8) // T.int64(4) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(56) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(14) + ax3)
                            T.reads(lv2[v0, v1, v2, v3], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv1775[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_T_add_intermediate[v0, v1, v2, v3])
                            var_T_add_intermediate[v0, v1, v2, v3] = lv2[v0, v1, v2, v3] + (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv1775[v0, v1, T.int64(0), T.int64(0)])
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 1, 4, 8, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[80, 1, 2, 4, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[8, 1, 4, 14, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[32, 1, 2])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #30: GFLOPs: 16.5388. Time: 1280381.9860 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #31: GFLOPs: 15.8752. Time: 1333904.8750 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #32: GFLOPs: 17.5535. Time: 1206367.0970 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #33: GFLOPs: 17.5709. Time: 1205170.8197 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #34: GFLOPs: 396.0305. Time: 53470.6110 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #35: GFLOPs: 22.4808. Time: 941959.7780 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #36: GFLOPs: 135.8793. Time: 155844.1667 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #37: GFLOPs: 16.4594. Time: 1286555.7360 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #38: GFLOPs: 12.3514. Time: 1714462.3333 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #39: GFLOPs: 27.8590. Time: 760112.3890 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #40: GFLOPs: 189.5172. Time: 111736.5140 us. Best GFLOPs: 484.4167
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #41: GFLOPs: 511.3157. Time: 41414.7083 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #42: GFLOPs: 16.8286. Time: 1258334.9027 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #43: GFLOPs: 266.8945. Time: 79342.1947 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #44: GFLOPs: 17.7129. Time: 1195511.5137 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #45: GFLOPs: 9.1553. Time: 2312968.9583 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #46: GFLOPs: 7.2785. Time: 2909403.0693 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #47: GFLOPs: 10.4024. Time: 2035685.0000 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #48: GFLOPs: 7.2375. Time: 2925854.5417 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #49: GFLOPs: 3.7083. Time: 5710354.4863 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #50: GFLOPs: 352.3662. Time: 60096.5557 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #51: GFLOPs: 364.5439. Time: 58089.0000 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #52: GFLOPs: 269.0731. Time: 78699.7777 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #53: GFLOPs: 21.8455. Time: 969352.1527 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #54: GFLOPs: 392.2272. Time: 53989.0970 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #55: GFLOPs: 138.0631. Time: 153379.1110 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #56: GFLOPs: 146.8554. Time: 144196.2220 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #57: GFLOPs: 333.3194. Time: 63530.6390 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #58: GFLOPs: 71.9852. Time: 294171.4863 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #59: GFLOPs: 42.8053. Time: 494705.3193 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:121] [Task #10: fused_conv2d6_add_add2] Trial #60: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x0000000114d5ba6f
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:109
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 109
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[12:18:22] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: Fail to compile metal source:program_source:36:269: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:36:1137: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:36:1962: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:36:2765: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:36:3664: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:38:329: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:38:1325: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:38:2278: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:38:3209: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:38:4236: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:40:329: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:40:1325: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:40:2278: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:40:3209: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:40:4236: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:42:309: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:42:1305: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:42:2258: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:42:3189: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:42:4216: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:44:329: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:44:1325: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:44:2278: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:44:3209: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:44:4236: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:46:329: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:46:1325: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:46:2278: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:46:3209: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:46:4236: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'



# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv1773: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), self_rrdb_conv_body_weight: T.Buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), "float32"), lv1775: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1)), "float32"), lv2: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_conv_body_weight_shared = T.alloc_buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(320), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(56), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(4), T.int64(1)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused // T.int64(14) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(14) // T.int64(7) * T.int64(4) + yy_3_init * T.int64(4) + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) * T.int64(112) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(4) + xx_3_init + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(16), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(38)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(3)):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v1 = T.axis.spatial(T.int64(64), rc_0 * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) // T.int64(912))
                                        v2 = T.axis.spatial(T.int64(642), ry_0 + nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) % T.int64(912) // T.int64(114))
                                        v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) * T.int64(112) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) % T.int64(114))
                                        T.reads(lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(6)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("self_rrdb_conv_body.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(12))
                                        v1 = T.axis.spatial(T.int64(64), rc_0 * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(12) // T.int64(3))
                                        v2 = T.axis.spatial(T.int64(3), ry_0)
                                        v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        T.reads(self_rrdb_conv_body_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_conv_body_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_conv_body_weight_shared[v0, v1, v2, v3] = self_rrdb_conv_body_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused // T.int64(14) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(14) // T.int64(7) * T.int64(4) + yy_3 * T.int64(4) + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) * T.int64(112) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(4) + xx_3 + xx_4)
                                v_rc = T.axis.reduce(T.int64(64), rc_0 * T.int64(4) + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(4)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused // T.int64(14) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(14) // T.int64(7) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) * T.int64(112) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(4) + ax3)
                            T.reads(lv2[v0, v1, v2, v3], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv1775[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_T_add_intermediate[v0, v1, v2, v3])
                            var_T_add_intermediate[v0, v1, v2, v3] = lv2[v0, v1, v2, v3] + (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv1775[v0, v1, T.int64(0), T.int64(0)])
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 4, 8, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[80, 2, 1, 1, 4])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[4, 7, 4, 4, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[16, 4, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 32, 3], preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #61: GFLOPs: 33.9779. Time: 623228.4720 us. Best GFLOPs: 511.3157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #62: GFLOPs: 554.9157. Time: 38160.7363 us. Best GFLOPs: 554.9157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #63: GFLOPs: 32.0259. Time: 661215.5697 us. Best GFLOPs: 554.9157
2023-05-18 12:18:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #64: GFLOPs: 16.9353. Time: 1250402.2220 us. Best GFLOPs: 554.9157
2023-05-18 17:13:49 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 17:13:49 [INFO] [evolutionary_search.cc:715] Picked top 61 candidate(s) from database
2023-05-18 17:13:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 448 failure(s)
2023-05-18 17:13:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 898 failure(s)
2023-05-18 17:13:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1343 failure(s)
2023-05-18 17:13:55 [INFO] [evolutionary_search.cc:723] Sampled 10 candidate(s)
2023-05-18 17:13:59 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 93 failure(s)
2023-05-18 17:14:05 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 81 failure(s)
2023-05-18 17:14:12 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 90 failure(s)
2023-05-18 17:14:18 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 103 failure(s)
2023-05-18 17:14:21 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9463  0.9403  0.9357  0.9195  0.9176  0.9106  0.9094  0.9074  0.9067  0.9049  0.9034  0.9023  0.9017  0.9004  0.8999  0.8990
[17 : 32]:	0.8955  0.8951  0.8931  0.8930  0.8908  0.8886  0.8870  0.8863  0.8861  0.8860  0.8819  0.8807  0.8801  0.8797  0.8779  0.8766
[33 : 48]:	0.8744  0.8720  0.8705  0.8704  0.8690  0.8669  0.8668  0.8652  0.8651  0.8651  0.8644  0.8609  0.8609  0.8609  0.8558  0.8539
[49 : 64]:	0.8532  0.8531  0.8510  0.8492  0.8482  0.8482  0.8481  0.8469  0.8468  0.8453  0.8452  0.8446  0.8423  0.8393  0.8356  0.8355
2023-05-18 17:14:21 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 17:14:21 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #65: GFLOPs: 541.2465. Time: 39124.4863 us. Best GFLOPs: 554.9157
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #66: GFLOPs: 495.6023. Time: 42727.7917 us. Best GFLOPs: 554.9157
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #67: GFLOPs: 644.1064. Time: 32876.5418 us. Best GFLOPs: 644.1064
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #68: GFLOPs: 710.2051. Time: 29816.7293 us. Best GFLOPs: 710.2051
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #69: GFLOPs: 517.5214. Time: 40918.0973 us. Best GFLOPs: 710.2051
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #70: GFLOPs: 615.0892. Time: 34427.5140 us. Best GFLOPs: 710.2051
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #71: GFLOPs: 757.3352. Time: 27961.1875 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #72: GFLOPs: 510.0051. Time: 41521.1390 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #73: GFLOPs: 688.4599. Time: 30758.5000 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #74: GFLOPs: 428.3318. Time: 49438.2917 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #75: GFLOPs: 465.4841. Time: 45492.4030 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #76: GFLOPs: 452.3401. Time: 46814.3197 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #77: GFLOPs: 677.4635. Time: 31257.7603 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #78: GFLOPs: 382.9233. Time: 55300.8750 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #79: GFLOPs: 425.3740. Time: 49782.0557 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #80: GFLOPs: 706.8376. Time: 29958.7812 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #81: GFLOPs: 618.5149. Time: 34236.8333 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #82: GFLOPs: 499.6929. Time: 42378.0140 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #83: GFLOPs: 374.3459. Time: 56567.9860 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #84: GFLOPs: 498.0095. Time: 42521.2640 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #85: GFLOPs: 692.0473. Time: 30599.0523 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #86: GFLOPs: 503.5818. Time: 42050.7500 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #87: GFLOPs: 533.0544. Time: 39725.7637 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #88: GFLOPs: 371.5600. Time: 56992.1250 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #89: GFLOPs: 527.4612. Time: 40147.0140 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #90: GFLOPs: 539.3077. Time: 39265.1390 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #91: GFLOPs: 588.1022. Time: 36007.3333 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #92: GFLOPs: 501.3271. Time: 42239.8750 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #93: GFLOPs: 680.9810. Time: 31096.3020 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #94: GFLOPs: 473.1428. Time: 44756.0277 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #95: GFLOPs: 577.8306. Time: 36647.4030 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #96: GFLOPs: 565.3508. Time: 37456.3750 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #97: GFLOPs: 683.6430. Time: 30975.2188 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #98: GFLOPs: 586.6851. Time: 36094.3053 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #99: GFLOPs: 491.7164. Time: 43065.4583 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #100: GFLOPs: 580.7416. Time: 36463.7083 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #101: GFLOPs: 723.5806. Time: 29265.5625 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #102: GFLOPs: 480.4242. Time: 44077.6943 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #103: GFLOPs: 498.7031. Time: 42462.1250 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #104: GFLOPs: 509.7933. Time: 41538.3890 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #105: GFLOPs: 518.8841. Time: 40810.6387 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #106: GFLOPs: 530.9675. Time: 39881.9027 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #107: GFLOPs: 649.6166. Time: 32597.6770 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #108: GFLOPs: 478.8198. Time: 44225.3890 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #109: GFLOPs: 483.9755. Time: 43754.2640 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #110: GFLOPs: 481.5147. Time: 43977.8750 us. Best GFLOPs: 757.3352
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #111: GFLOPs: 871.0774. Time: 24310.1166 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #112: GFLOPs: 618.6580. Time: 34228.9167 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #113: GFLOPs: 387.5142. Time: 54645.7223 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #114: GFLOPs: 485.9086. Time: 43580.1943 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #115: GFLOPs: 572.6773. Time: 36977.1807 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #116: GFLOPs: 526.4779. Time: 40222.0000 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #117: GFLOPs: 476.0552. Time: 44482.2223 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #118: GFLOPs: 478.6635. Time: 44239.8333 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #119: GFLOPs: 467.6865. Time: 45278.1807 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #120: GFLOPs: 501.5537. Time: 42220.7917 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #121: GFLOPs: 574.7920. Time: 36841.1387 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #122: GFLOPs: 499.2473. Time: 42415.8333 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #123: GFLOPs: 625.7624. Time: 33840.3057 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #124: GFLOPs: 508.2053. Time: 41668.1807 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #125: GFLOPs: 538.4594. Time: 39327.0000 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #126: GFLOPs: 391.0356. Time: 54153.6113 us. Best GFLOPs: 871.0774
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:121] [Task #10: fused_conv2d6_add_add2] Trial #127: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x0000000112ed510f
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:109
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 109
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[17:18:28] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: Fail to compile metal source:program_source:82:269: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:82:1137: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:82:1962: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:82:2765: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:82:3664: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:84:329: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:84:1325: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:84:2278: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:84:3209: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:84:4236: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:86:329: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:86:1325: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:86:2278: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:86:3209: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:86:4236: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:88:305: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:88:1301: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:88:2254: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:88:3185: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:88:4212: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:90:329: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:90:1325: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:90:2278: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:90:3209: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:90:4236: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:92:329: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:92:1325: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:92:2278: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:92:3209: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:92:4236: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:94:309: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:94:1305: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:94:2258: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:94:3189: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:94:4216: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:96:329: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:96:1325: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:96:2278: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:96:3209: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:96:4236: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:98:333: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:98:1345: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:98:2314: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:98:3261: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:98:4304: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:100:310: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:100:1322: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:100:2291: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:100:3238: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:100:4281: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:102:334: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:102:1346: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:102:2315: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:102:3262: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:102:4305: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:104:334: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:104:1346: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:104:2315: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:104:3262: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'
program_source:104:4305: error: value of type 'bool __attribute__((ext_vector_type(4)))' (vector of 4 'bool' values) is not contextually convertible to 'bool'



# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv1773: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), self_rrdb_conv_body_weight: T.Buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), "float32"), lv1775: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1)), "float32"), lv2: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_conv_body_weight_shared = T.alloc_buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(2240), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused * T.int64(32) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(4) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(112) * T.int64(32) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) // T.int64(2) * T.int64(16) + yy_3_init + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(112) * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(2) * T.int64(2) + xx_3_init * T.int64(2) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(8), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(12)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v1 = T.axis.spatial(T.int64(64), rc_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(192))
                                        v2 = T.axis.spatial(T.int64(642), ry_0 + nn_0_ff_0_yy_0_xx_0_fused // T.int64(112) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(192) // T.int64(6))
                                        v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(112) * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(6))
                                        T.reads(lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(12)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("self_rrdb_conv_body.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(24))
                                        v1 = T.axis.spatial(T.int64(64), rc_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(24) // T.int64(3))
                                        v2 = T.axis.spatial(T.int64(3), ry_0)
                                        v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        T.reads(self_rrdb_conv_body_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_conv_body_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_conv_body_weight_shared[v0, v1, v2, v3] = self_rrdb_conv_body_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(1), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused * T.int64(32) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(4) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(112) * T.int64(32) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) // T.int64(2) * T.int64(16) + yy_3 + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(112) * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(2) * T.int64(2) + xx_3 * T.int64(2) + xx_4)
                                v_rc = T.axis.reduce(T.int64(64), rc_0 * T.int64(8) + rc_1 * T.int64(2) + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 * T.int64(3) + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(16), T.int64(2)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused * T.int64(32) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(4) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(112) * T.int64(32) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) // T.int64(2) * T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(112) * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(2) * T.int64(2) + ax3)
                            T.reads(lv2[v0, v1, v2, v3], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv1775[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_T_add_intermediate[v0, v1, v2, v3])
                            var_T_add_intermediate[v0, v1, v2, v3] = lv2[v0, v1, v2, v3] + (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv1775[v0, v1, T.int64(0), T.int64(0)])
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 2, 8, 2, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[20, 1, 2, 16, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[112, 1, 2, 1, 2])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[8, 4, 2])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
2023-05-18 17:18:30 [INFO] [task_scheduler.cc:121] [Task #10: fused_conv2d6_add_add2] Trial #128: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x00000001066d933f
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:130
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 130
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[17:18:29] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (state != nil) is false: cannot get state: for function main_kernel0Compute function exceeds available temporary registers


# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv1773: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), self_rrdb_conv_body_weight: T.Buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), "float32"), lv1775: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1)), "float32"), lv2: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_conv_body_weight_shared = T.alloc_buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(140), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(8), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(16)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(64), nn_0_ff_0_yy_0_xx_0_fused // T.int64(70) * T.int64(32) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(16) * T.int64(2) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused % T.int64(70) // T.int64(7) * T.int64(64) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(16) // T.int64(4) * T.int64(16) + yy_3_init * T.int64(16) + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(7) * T.int64(64) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(16) + xx_3_init * T.int64(16) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(64), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(44)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(3)):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v1 = T.axis.spatial(T.int64(64), rc_0)
                                        v2 = T.axis.spatial(T.int64(642), ry_0 + nn_0_ff_0_yy_0_xx_0_fused % T.int64(70) // T.int64(7) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) // T.int64(66))
                                        v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(7) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) % T.int64(66))
                                        T.reads(lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("self_rrdb_conv_body.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(64), nn_0_ff_0_yy_0_xx_0_fused // T.int64(70) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(3))
                                        v1, v2 = T.axis.remap("SS", [rc_0, ry_0])
                                        v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(96))
                                        T.reads(self_rrdb_conv_body_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_conv_body_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_conv_body_weight_shared[v0, v1, v2, v3] = self_rrdb_conv_body_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(16), T.int64(16)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(64), nn_0_ff_0_yy_0_xx_0_fused // T.int64(70) * T.int64(32) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(16) * T.int64(2) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused % T.int64(70) // T.int64(7) * T.int64(64) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(16) // T.int64(4) * T.int64(16) + yy_3 * T.int64(16) + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(7) * T.int64(64) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(16) + xx_3 * T.int64(16) + xx_4)
                                v_rc = T.axis.reduce(T.int64(64), rc_0 + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(16)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(64), nn_0_ff_0_yy_0_xx_0_fused // T.int64(70) * T.int64(32) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(16) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused % T.int64(70) // T.int64(7) * T.int64(64) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(16) // T.int64(4) * T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(7) * T.int64(64) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(16) + ax3)
                            T.reads(lv2[v0, v1, v2, v3], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv1775[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_T_add_intermediate[v0, v1, v2, v3])
                            var_T_add_intermediate[v0, v1, v2, v3] = lv2[v0, v1, v2, v3] + (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv1775[v0, v1, T.int64(0), T.int64(0)])
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 8, 2, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[10, 1, 4, 1, 16])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[7, 1, 4, 1, 16])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[64, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 32, 3], preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
2023-05-18 17:18:30 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 17:18:30 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 17:18:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 407 failure(s)
2023-05-18 17:18:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 811 failure(s)
2023-05-18 17:18:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1213 failure(s)
2023-05-18 17:18:36 [INFO] [evolutionary_search.cc:723] Sampled 17 candidate(s)
2023-05-18 17:18:40 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 90 failure(s)
2023-05-18 17:18:47 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 96 failure(s)
2023-05-18 17:18:53 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 64 failure(s)
2023-05-18 17:18:59 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 91 failure(s)
2023-05-18 17:19:02 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9776  0.9660  0.9565  0.9453  0.9315  0.9287  0.9195  0.9129  0.9094  0.9093  0.9024  0.9021  0.9012  0.8979  0.8979  0.8977
[17 : 32]:	0.8953  0.8951  0.8937  0.8936  0.8922  0.8906  0.8902  0.8877  0.8868  0.8854  0.8849  0.8847  0.8834  0.8827  0.8821  0.8814
[33 : 48]:	0.8788  0.8766  0.8757  0.8748  0.8729  0.8725  0.8725  0.8725  0.8725  0.8725  0.8717  0.8715  0.8711  0.8699  0.8699  0.8698
[49 : 64]:	0.8697  0.8695  0.8693  0.8689  0.8683  0.8673  0.8668  0.8668  0.8659  0.8655  0.8653  0.8651  0.8651  0.8649  0.8645  0.8636
2023-05-18 17:19:02 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 17:19:02 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #129: GFLOPs: 618.9189. Time: 34214.4863 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #130: GFLOPs: 403.2149. Time: 52517.8750 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #131: GFLOPs: 524.2927. Time: 40389.6390 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #132: GFLOPs: 516.0838. Time: 41032.0833 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #133: GFLOPs: 432.8938. Time: 48917.2917 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #134: GFLOPs: 465.9122. Time: 45450.6113 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #135: GFLOPs: 722.6384. Time: 29303.7188 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #136: GFLOPs: 403.8496. Time: 52435.3470 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #137: GFLOPs: 753.8631. Time: 28089.9688 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #138: GFLOPs: 497.6077. Time: 42555.5973 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #139: GFLOPs: 460.6585. Time: 45968.9583 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #140: GFLOPs: 533.9048. Time: 39662.4860 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #141: GFLOPs: 352.4358. Time: 60084.6807 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #142: GFLOPs: 645.3486. Time: 32813.2605 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #143: GFLOPs: 634.3568. Time: 33381.8333 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #144: GFLOPs: 596.4462. Time: 35503.6110 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #145: GFLOPs: 418.0311. Time: 50656.5000 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #146: GFLOPs: 413.5870. Time: 51200.8197 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #147: GFLOPs: 644.3719. Time: 32863.0000 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #148: GFLOPs: 532.7318. Time: 39749.8197 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #149: GFLOPs: 478.3519. Time: 44268.6527 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #150: GFLOPs: 604.9537. Time: 35004.3193 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #151: GFLOPs: 371.1673. Time: 57052.4167 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #152: GFLOPs: 692.9886. Time: 30557.4897 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #153: GFLOPs: 672.0019. Time: 31511.8022 us. Best GFLOPs: 871.0774
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #154: GFLOPs: 924.5523. Time: 22904.0500 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #155: GFLOPs: 781.1440. Time: 27108.9480 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #156: GFLOPs: 514.4459. Time: 41162.7223 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #157: GFLOPs: 371.2447. Time: 57040.5277 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #158: GFLOPs: 666.8814. Time: 31753.7602 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #159: GFLOPs: 630.3765. Time: 33592.6110 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #160: GFLOPs: 419.4436. Time: 50485.9167 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #161: GFLOPs: 580.9919. Time: 36448.0000 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #162: GFLOPs: 574.5037. Time: 36859.6250 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #163: GFLOPs: 383.3843. Time: 55234.3750 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #164: GFLOPs: 691.4967. Time: 30623.4168 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #165: GFLOPs: 485.1944. Time: 43644.3470 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #166: GFLOPs: 686.6704. Time: 30838.6562 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #167: GFLOPs: 719.4951. Time: 29431.7395 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #168: GFLOPs: 696.5252. Time: 30402.3335 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #169: GFLOPs: 698.0334. Time: 30336.6460 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #170: GFLOPs: 698.6336. Time: 30310.5835 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #171: GFLOPs: 691.6219. Time: 30617.8750 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #172: GFLOPs: 661.3713. Time: 32018.3125 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #173: GFLOPs: 469.4423. Time: 45108.8333 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #174: GFLOPs: 516.0029. Time: 41038.5140 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #175: GFLOPs: 870.2844. Time: 24332.2668 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #176: GFLOPs: 569.8614. Time: 37159.9027 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #177: GFLOPs: 489.6921. Time: 43243.4860 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #178: GFLOPs: 471.1339. Time: 44946.8613 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #179: GFLOPs: 566.6875. Time: 37368.0277 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #180: GFLOPs: 393.6720. Time: 53790.9583 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #181: GFLOPs: 642.3044. Time: 32968.7812 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #182: GFLOPs: 574.5851. Time: 36854.4030 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #183: GFLOPs: 744.3888. Time: 28447.4895 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #184: GFLOPs: 583.0136. Time: 36321.6113 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #185: GFLOPs: 582.8870. Time: 36329.5000 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #186: GFLOPs: 579.0435. Time: 36570.6387 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #187: GFLOPs: 522.2343. Time: 40548.8333 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #188: GFLOPs: 522.4664. Time: 40530.8197 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #189: GFLOPs: 539.6343. Time: 39241.3750 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #190: GFLOPs: 7.4931. Time: 2826071.8887 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #191: GFLOPs: 498.9258. Time: 42443.1667 us. Best GFLOPs: 924.5523
2023-05-18 17:21:07 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #192: GFLOPs: 233.4757. Time: 90698.9167 us. Best GFLOPs: 924.5523
2023-05-18 17:52:18 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 17:52:19 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 17:52:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 403 failure(s)
2023-05-18 17:52:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 808 failure(s)
2023-05-18 17:52:22 [INFO] [evolutionary_search.cc:723] Sampled 12 candidate(s)
2023-05-18 17:52:26 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 72 failure(s)
2023-05-18 17:52:32 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 83 failure(s)
2023-05-18 17:52:39 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 91 failure(s)
2023-05-18 17:52:45 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 72 failure(s)
2023-05-18 17:52:47 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9754  0.9605  0.9408  0.9397  0.9323  0.9280  0.9208  0.9142  0.9127  0.9119  0.9094  0.9094  0.9084  0.9078  0.9077  0.9060
[17 : 32]:	0.9025  0.9024  0.9013  0.9011  0.9002  0.8994  0.8983  0.8979  0.8967  0.8961  0.8950  0.8924  0.8912  0.8904  0.8866  0.8847
[33 : 48]:	0.8844  0.8833  0.8824  0.8816  0.8813  0.8805  0.8796  0.8788  0.8788  0.8784  0.8764  0.8756  0.8752  0.8745  0.8741  0.8736
[49 : 64]:	0.8725  0.8725  0.8720  0.8715  0.8715  0.8709  0.8708  0.8699  0.8699  0.8699  0.8699  0.8690  0.8685  0.8685  0.8679  0.8679
2023-05-18 17:52:47 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 17:52:47 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #193: GFLOPs: 533.8497. Time: 39666.5833 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #194: GFLOPs: 426.3735. Time: 49665.3613 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #195: GFLOPs: 595.0602. Time: 35586.3053 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #196: GFLOPs: 559.1782. Time: 37869.8470 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #197: GFLOPs: 615.6068. Time: 34398.5693 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #198: GFLOPs: 422.1045. Time: 50167.6527 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #199: GFLOPs: 418.1054. Time: 50647.5000 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #200: GFLOPs: 712.6644. Time: 29713.8332 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #201: GFLOPs: 757.0473. Time: 27971.8230 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #202: GFLOPs: 714.8492. Time: 29623.0210 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #203: GFLOPs: 757.2393. Time: 27964.7290 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #204: GFLOPs: 756.8260. Time: 27980.0000 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #205: GFLOPs: 482.3345. Time: 43903.1250 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #206: GFLOPs: 563.4086. Time: 37585.5000 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #207: GFLOPs: 461.0428. Time: 45930.6387 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #208: GFLOPs: 524.9702. Time: 40337.5137 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #209: GFLOPs: 421.4805. Time: 50241.9303 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #210: GFLOPs: 899.9518. Time: 23530.1416 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #211: GFLOPs: 506.3439. Time: 41821.3610 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #212: GFLOPs: 450.0620. Time: 47051.2777 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #213: GFLOPs: 574.2607. Time: 36875.2223 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #214: GFLOPs: 880.8588. Time: 24040.1666 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #215: GFLOPs: 359.7606. Time: 58861.3473 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #216: GFLOPs: 643.7426. Time: 32895.1250 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #217: GFLOPs: 699.9082. Time: 30255.3855 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #218: GFLOPs: 404.8240. Time: 52309.1390 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #219: GFLOPs: 613.4055. Time: 34522.0137 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #220: GFLOPs: 480.4880. Time: 44071.8473 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #221: GFLOPs: 418.6974. Time: 50575.8887 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #222: GFLOPs: 484.5201. Time: 43705.0833 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #223: GFLOPs: 410.3704. Time: 51602.1387 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #224: GFLOPs: 395.1402. Time: 53591.0833 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #225: GFLOPs: 653.5676. Time: 32400.6145 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #226: GFLOPs: 484.8754. Time: 43673.0557 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #227: GFLOPs: 384.7717. Time: 55035.2083 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #228: GFLOPs: 622.8917. Time: 33996.2640 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #229: GFLOPs: 428.4534. Time: 49424.2640 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #230: GFLOPs: 642.6977. Time: 32948.6043 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #231: GFLOPs: 649.7894. Time: 32589.0105 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #232: GFLOPs: 591.5545. Time: 35797.1943 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #233: GFLOPs: 627.7758. Time: 33731.7780 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #234: GFLOPs: 779.8004. Time: 27155.6562 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #235: GFLOPs: 476.4728. Time: 44443.2360 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #236: GFLOPs: 393.2287. Time: 53851.5973 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #237: GFLOPs: 342.5454. Time: 61819.5280 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #238: GFLOPs: 403.0869. Time: 52534.5557 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #239: GFLOPs: 549.3482. Time: 38547.4860 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #240: GFLOPs: 698.5719. Time: 30313.2605 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #241: GFLOPs: 698.3413. Time: 30323.2710 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #242: GFLOPs: 628.8197. Time: 33675.7780 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #243: GFLOPs: 592.6407. Time: 35731.5833 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #244: GFLOPs: 675.9884. Time: 31325.9688 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #245: GFLOPs: 662.8227. Time: 31948.1980 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #246: GFLOPs: 794.9866. Time: 26636.9168 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #247: GFLOPs: 523.5797. Time: 40444.6390 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #248: GFLOPs: 902.9866. Time: 23451.0584 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #249: GFLOPs: 892.0157. Time: 23739.4834 us. Best GFLOPs: 924.5523
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #250: GFLOPs: 1120.6403. Time: 18896.3333 us. Best GFLOPs: 1120.6403
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #251: GFLOPs: 906.1464. Time: 23369.2834 us. Best GFLOPs: 1120.6403
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #252: GFLOPs: 867.1986. Time: 24418.8500 us. Best GFLOPs: 1120.6403
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #253: GFLOPs: 575.3716. Time: 36804.0280 us. Best GFLOPs: 1120.6403
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #254: GFLOPs: 8.4367. Time: 2509982.0693 us. Best GFLOPs: 1120.6403
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:121] [Task #10: fused_conv2d6_add_add2] Trial #255: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x00000001167ec96f
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:109
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 109
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[17:55:24] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: Fail to compile metal source:program_source:48:247: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
program_source:48:1049: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
program_source:48:1820: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
program_source:48:2575: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
program_source:48:3390: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'



# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv1773: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), self_rrdb_conv_body_weight: T.Buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), "float32"), lv1775: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1)), "float32"), lv2: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_conv_body_weight_shared = T.alloc_buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(5120), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(64), nn_2_ff_2_yy_2_xx_2_fused // T.int64(2) * T.int64(4) + ff_3_init + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) + yy_3_init + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(56) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(2) * T.int64(28) + xx_3_init * T.int64(4) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(8), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(15)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(64), rc_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(58))
                                    v2 = T.axis.spatial(T.int64(642), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) + ry_0)
                                    v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(56) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(58))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1 < T.int64(464))
                                    T.reads(lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(24)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("self_rrdb_conv_body.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(24))
                                        v1 = T.axis.spatial(T.int64(64), rc_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(24) // T.int64(3))
                                        v2 = T.axis.spatial(T.int64(3), ry_0)
                                        v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        T.reads(self_rrdb_conv_body_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_conv_body_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_conv_body_weight_shared[v0, v1, v2, v3] = self_rrdb_conv_body_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(64), nn_2_ff_2_yy_2_xx_2_fused // T.int64(2) * T.int64(4) + ff_3 + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) + yy_3 + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(56) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(2) * T.int64(28) + xx_3 * T.int64(4) + xx_4)
                                v_rc = T.axis.reduce(T.int64(64), rc_0 * T.int64(8) + rc_1 * T.int64(4) + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(28)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(64), nn_2_ff_2_yy_2_xx_2_fused // T.int64(2) * T.int64(4) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(56) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(2) * T.int64(28) + ax3)
                            T.reads(lv2[v0, v1, v2, v3], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv1775[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_T_add_intermediate[v0, v1, v2, v3])
                            var_T_add_intermediate[v0, v1, v2, v3] = lv2[v0, v1, v2, v3] + (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv1775[v0, v1, T.int64(0), T.int64(0)])
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 1, 16, 4, 1])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[640, 1, 1, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[8, 1, 2, 7, 4])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[8, 2, 4])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
2023-05-18 17:55:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #256: GFLOPs: 382.1195. Time: 55417.1947 us. Best GFLOPs: 1120.6403
2023-05-18 17:55:34 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 17:55:34 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 17:55:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 407 failure(s)
2023-05-18 17:55:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 811 failure(s)
2023-05-18 17:55:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1218 failure(s)
2023-05-18 17:55:39 [INFO] [evolutionary_search.cc:723] Sampled 12 candidate(s)
2023-05-18 17:55:44 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 98 failure(s)
2023-05-18 17:55:50 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 81 failure(s)
2023-05-18 17:55:56 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 80 failure(s)
2023-05-18 17:56:02 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 127 failure(s)
2023-05-18 17:56:05 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8252  0.8224  0.8146  0.8138  0.8134  0.8111  0.8111  0.8048  0.8048  0.8048  0.8016  0.7997  0.7994  0.7943  0.7938  0.7908
[17 : 32]:	0.7908  0.7903  0.7839  0.7808  0.7790  0.7746  0.7733  0.7733  0.7733  0.7733  0.7733  0.7627  0.7592  0.7566  0.7566  0.7566
[33 : 48]:	0.7566  0.7534  0.7534  0.7531  0.7518  0.7500  0.7487  0.7482  0.7482  0.7482  0.7482  0.7478  0.7396  0.7363  0.7363  0.7341
[49 : 64]:	0.7341  0.7341  0.7332  0.7332  0.7332  0.7293  0.7281  0.7245  0.7236  0.7218  0.7197  0.7167  0.7159  0.7086  0.7081  0.7078
2023-05-18 17:56:05 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 17:56:05 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #257: GFLOPs: 1043.7938. Time: 20287.5250 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #258: GFLOPs: 870.1104. Time: 24337.1334 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #259: GFLOPs: 894.3058. Time: 23678.6918 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #260: GFLOPs: 678.7617. Time: 31197.9790 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #261: GFLOPs: 1034.8851. Time: 20462.1668 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #262: GFLOPs: 893.6608. Time: 23695.7834 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #263: GFLOPs: 906.4952. Time: 23360.2918 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #264: GFLOPs: 1062.5258. Time: 19929.8610 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #265: GFLOPs: 873.9979. Time: 24228.8834 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #266: GFLOPs: 923.6963. Time: 22925.2750 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #267: GFLOPs: 871.7737. Time: 24290.7000 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #268: GFLOPs: 676.7590. Time: 31290.3020 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #269: GFLOPs: 1046.1228. Time: 20242.3584 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #270: GFLOPs: 903.6427. Time: 23434.0334 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #271: GFLOPs: 1111.1292. Time: 19058.0833 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #272: GFLOPs: 868.6930. Time: 24376.8418 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #273: GFLOPs: 910.9394. Time: 23246.3250 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #274: GFLOPs: 777.5129. Time: 27235.5520 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #275: GFLOPs: 876.1174. Time: 24170.2666 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #276: GFLOPs: 709.1952. Time: 29859.1875 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #277: GFLOPs: 1047.1501. Time: 20222.5000 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #278: GFLOPs: 894.8945. Time: 23663.1166 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #279: GFLOPs: 832.6556. Time: 25431.8750 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #280: GFLOPs: 858.9156. Time: 24654.3334 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #281: GFLOPs: 833.1330. Time: 25417.3020 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #282: GFLOPs: 879.7893. Time: 24069.3916 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #283: GFLOPs: 874.7046. Time: 24209.3084 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #284: GFLOPs: 759.5829. Time: 27878.4477 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #285: GFLOPs: 884.1806. Time: 23949.8500 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #286: GFLOPs: 777.0192. Time: 27252.8543 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #287: GFLOPs: 757.9138. Time: 27939.8438 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #288: GFLOPs: 912.8911. Time: 23196.6250 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #289: GFLOPs: 785.6512. Time: 26953.4273 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #290: GFLOPs: 872.9629. Time: 24257.6084 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #291: GFLOPs: 867.4698. Time: 24411.2166 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #292: GFLOPs: 1052.0864. Time: 20127.6166 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #293: GFLOPs: 848.3716. Time: 24960.7500 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #294: GFLOPs: 839.2192. Time: 25232.9688 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #295: GFLOPs: 782.3384. Time: 27067.5625 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #296: GFLOPs: 872.3713. Time: 24274.0582 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #297: GFLOPs: 884.8142. Time: 23932.7000 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #298: GFLOPs: 843.6395. Time: 25100.7602 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #299: GFLOPs: 848.0925. Time: 24968.9666 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #300: GFLOPs: 676.3537. Time: 31309.0520 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #301: GFLOPs: 894.8053. Time: 23665.4750 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #302: GFLOPs: 797.2904. Time: 26559.9480 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #303: GFLOPs: 756.9376. Time: 27975.8750 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #304: GFLOPs: 859.3231. Time: 24642.6416 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #305: GFLOPs: 889.3039. Time: 23811.8750 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #306: GFLOPs: 844.9527. Time: 25061.7500 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #307: GFLOPs: 886.9538. Time: 23874.9668 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #308: GFLOPs: 837.6824. Time: 25279.2605 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #309: GFLOPs: 861.1817. Time: 24589.4582 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #310: GFLOPs: 880.3547. Time: 24053.9334 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #311: GFLOPs: 932.7104. Time: 22703.7166 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #312: GFLOPs: 919.0384. Time: 23041.4668 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #313: GFLOPs: 770.0673. Time: 27498.8855 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #314: GFLOPs: 667.5048. Time: 31724.1040 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #315: GFLOPs: 914.7271. Time: 23150.0666 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #316: GFLOPs: 1014.0901. Time: 20881.7668 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #317: GFLOPs: 918.1630. Time: 23063.4334 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #318: GFLOPs: 22.5551. Time: 938855.7500 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:121] [Task #10: fused_conv2d6_add_add2] Trial #319: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x0000000103edeb3f
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:109
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 109
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[17:57:11] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: Fail to compile metal source:program_source:39:249: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
program_source:39:1067: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
program_source:39:1854: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
program_source:39:2625: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
program_source:39:3456: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'



# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv1773: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), self_rrdb_conv_body_weight: T.Buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), "float32"), lv1775: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1)), "float32"), lv2: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_conv_body_weight_shared = T.alloc_buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(224), thread="blockIdx.x"):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(32), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(2), T.int64(10), T.int64(1)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused // T.int64(2) * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(16) * T.int64(2) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(7) * T.int64(20) + yy_3_init * T.int64(10) + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(7) * T.int64(64) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(32) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(16) * T.int64(2) + xx_3_init + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(32), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(83)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(64), rc_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(1320))
                                    v2 = T.axis.spatial(T.int64(642), ry_0 + nn_0_ff_0_yy_0_xx_0_fused // T.int64(7) * T.int64(20) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(1320) // T.int64(66))
                                    v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(7) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(66))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1 < T.int64(2640))
                                    T.reads(lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(6)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("self_rrdb_conv_body.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(6))
                                        v1 = T.axis.spatial(T.int64(64), rc_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(6) // T.int64(3))
                                        v2 = T.axis.spatial(T.int64(3), ry_0)
                                        v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        T.reads(self_rrdb_conv_body_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_conv_body_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_conv_body_weight_shared[v0, v1, v2, v3] = self_rrdb_conv_body_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(10), T.int64(1)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused // T.int64(2) * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(16) * T.int64(2) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(7) * T.int64(20) + yy_3 * T.int64(10) + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(7) * T.int64(64) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(32) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(16) * T.int64(2) + xx_3 + xx_4)
                                v_rc = T.axis.reduce(T.int64(64), rc_0 * T.int64(2) + rc_1 * T.int64(2) + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(20), T.int64(2)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused // T.int64(2) * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(16) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(7) * T.int64(20) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(7) * T.int64(64) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(32) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(16) * T.int64(2) + ax3)
                            T.reads(lv2[v0, v1, v2, v3], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv1775[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_T_add_intermediate[v0, v1, v2, v3])
                            var_T_add_intermediate[v0, v1, v2, v3] = lv2[v0, v1, v2, v3] + (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv1775[v0, v1, T.int64(0), T.int64(0)])
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 16, 2, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[32, 1, 1, 2, 10])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[7, 2, 16, 2, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[32, 1, 2])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
2023-05-18 17:57:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #320: GFLOPs: 306.8850. Time: 69003.0277 us. Best GFLOPs: 1120.6403
2023-05-18 17:57:12 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 17:57:13 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 17:57:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 407 failure(s)
2023-05-18 17:57:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 814 failure(s)
2023-05-18 17:57:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1220 failure(s)
2023-05-18 17:57:18 [INFO] [evolutionary_search.cc:723] Sampled 10 candidate(s)
2023-05-18 17:57:23 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 103 failure(s)
2023-05-18 17:57:29 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 115 failure(s)
2023-05-18 17:57:35 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 97 failure(s)
2023-05-18 17:57:42 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 112 failure(s)
2023-05-18 17:57:44 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8517  0.8252  0.8233  0.8225  0.8224  0.8224  0.8224  0.8224  0.8134  0.8111  0.8111  0.8111  0.8104  0.8104  0.8084  0.8048
[17 : 32]:	0.8048  0.8048  0.8030  0.8016  0.8016  0.8016  0.8006  0.7994  0.7990  0.7931  0.7908  0.7908  0.7908  0.7895  0.7889  0.7851
[33 : 48]:	0.7851  0.7851  0.7851  0.7851  0.7851  0.7849  0.7842  0.7840  0.7839  0.7839  0.7839  0.7833  0.7798  0.7794  0.7790  0.7765
[49 : 64]:	0.7765  0.7737  0.7737  0.7735  0.7734  0.7733  0.7733  0.7733  0.7667  0.7665  0.7648  0.7648  0.7648  0.7648  0.7640  0.7640
2023-05-18 17:57:44 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 17:57:44 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #321: GFLOPs: 1026.1625. Time: 20636.1000 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #322: GFLOPs: 912.2488. Time: 23212.9582 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #323: GFLOPs: 1044.9046. Time: 20265.9584 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #324: GFLOPs: 991.0100. Time: 21368.0918 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #325: GFLOPs: 906.4176. Time: 23362.2918 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #326: GFLOPs: 891.6373. Time: 23749.5584 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #327: GFLOPs: 1044.8715. Time: 20266.6000 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #328: GFLOPs: 905.8215. Time: 23377.6666 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #329: GFLOPs: 1040.9354. Time: 20343.2332 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #330: GFLOPs: 912.9724. Time: 23194.5582 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #331: GFLOPs: 1106.0442. Time: 19145.7013 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #332: GFLOPs: 1042.9712. Time: 20303.5250 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #333: GFLOPs: 909.9102. Time: 23272.6166 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #334: GFLOPs: 890.3330. Time: 23784.3500 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #335: GFLOPs: 995.2141. Time: 21277.8250 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #336: GFLOPs: 1037.5972. Time: 20408.6834 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #337: GFLOPs: 870.8606. Time: 24316.1666 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #338: GFLOPs: 910.3076. Time: 23262.4584 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #339: GFLOPs: 1042.4223. Time: 20314.2168 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #340: GFLOPs: 908.5971. Time: 23306.2500 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #341: GFLOPs: 924.0823. Time: 22915.7000 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #342: GFLOPs: 867.1604. Time: 24419.9250 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #343: GFLOPs: 891.9487. Time: 23741.2666 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #344: GFLOPs: 1043.6292. Time: 20290.7250 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #345: GFLOPs: 714.3327. Time: 29644.4375 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #346: GFLOPs: 1028.4742. Time: 20589.7166 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #347: GFLOPs: 896.7849. Time: 23613.2334 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #348: GFLOPs: 1060.1955. Time: 19973.6667 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #349: GFLOPs: 866.6718. Time: 24433.6918 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #350: GFLOPs: 924.4235. Time: 22907.2418 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #351: GFLOPs: 1049.2432. Time: 20182.1584 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #352: GFLOPs: 870.6897. Time: 24320.9416 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #353: GFLOPs: 850.3179. Time: 24903.6168 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #354: GFLOPs: 1053.6154. Time: 20098.4084 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #355: GFLOPs: 891.7618. Time: 23746.2418 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #356: GFLOPs: 1032.8484. Time: 20502.5166 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #357: GFLOPs: 908.0942. Time: 23319.1584 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #358: GFLOPs: 716.4851. Time: 29555.3852 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #359: GFLOPs: 906.2185. Time: 23367.4250 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #360: GFLOPs: 788.9693. Time: 26840.0727 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #361: GFLOPs: 891.0705. Time: 23764.6666 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #362: GFLOPs: 1034.3830. Time: 20472.1000 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #363: GFLOPs: 850.3251. Time: 24903.4082 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #364: GFLOPs: 1022.0994. Time: 20718.1334 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #365: GFLOPs: 1100.9396. Time: 19234.4722 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #366: GFLOPs: 690.9026. Time: 30649.7500 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #367: GFLOPs: 1047.3702. Time: 20218.2500 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #368: GFLOPs: 837.1791. Time: 25294.4583 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #369: GFLOPs: 859.0472. Time: 24650.5584 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #370: GFLOPs: 859.8992. Time: 24626.1332 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #371: GFLOPs: 868.1716. Time: 24391.4832 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #372: GFLOPs: 1061.6155. Time: 19946.9515 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #373: GFLOPs: 1028.8265. Time: 20582.6666 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #374: GFLOPs: 887.6435. Time: 23856.4168 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #375: GFLOPs: 1023.2935. Time: 20693.9584 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #376: GFLOPs: 786.8451. Time: 26912.5312 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #377: GFLOPs: 712.8764. Time: 29705.0000 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #378: GFLOPs: 891.8755. Time: 23743.2166 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #379: GFLOPs: 888.1501. Time: 23842.8084 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #380: GFLOPs: 1041.5174. Time: 20331.8668 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #381: GFLOPs: 870.4019. Time: 24328.9834 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #382: GFLOPs: 138.7292. Time: 152642.6667 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #383: GFLOPs: 16.9377. Time: 1250225.1667 us. Best GFLOPs: 1120.6403
2023-05-18 18:02:25 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #384: GFLOPs: 16.8266. Time: 1258482.5557 us. Best GFLOPs: 1120.6403
2023-05-18 18:24:17 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 18:24:18 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 18:24:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 406 failure(s)
2023-05-18 18:24:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 811 failure(s)
2023-05-18 18:24:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1217 failure(s)
2023-05-18 18:24:23 [INFO] [evolutionary_search.cc:723] Sampled 13 candidate(s)
2023-05-18 18:24:28 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 120 failure(s)
2023-05-18 18:24:34 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 104 failure(s)
2023-05-18 18:24:41 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 93 failure(s)
2023-05-18 18:24:48 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 118 failure(s)
2023-05-18 18:24:50 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8398  0.8376  0.8199  0.8134  0.8134  0.8117  0.8111  0.8104  0.8104  0.8058  0.8051  0.8022  0.8016  0.8016  0.7998  0.7994
[17 : 32]:	0.7994  0.7994  0.7930  0.7913  0.7908  0.7908  0.7895  0.7895  0.7893  0.7893  0.7878  0.7854  0.7853  0.7851  0.7851  0.7845
[33 : 48]:	0.7845  0.7845  0.7839  0.7825  0.7817  0.7802  0.7799  0.7791  0.7790  0.7787  0.7783  0.7772  0.7765  0.7765  0.7765  0.7747
[49 : 64]:	0.7737  0.7734  0.7734  0.7731  0.7714  0.7705  0.7684  0.7657  0.7651  0.7648  0.7648  0.7648  0.7644  0.7644  0.7644  0.7644
2023-05-18 18:24:50 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 18:24:50 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #385: GFLOPs: 1144.3329. Time: 18505.0972 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #386: GFLOPs: 1038.2030. Time: 20396.7750 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #387: GFLOPs: 1036.3040. Time: 20434.1500 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #388: GFLOPs: 1039.8752. Time: 20363.9750 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #389: GFLOPs: 1040.4406. Time: 20352.9084 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #390: GFLOPs: 1015.7232. Time: 20848.1918 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #391: GFLOPs: 917.4805. Time: 23080.5916 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #392: GFLOPs: 880.9635. Time: 24037.3082 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #393: GFLOPs: 1045.4574. Time: 20255.2416 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #394: GFLOPs: 1043.6712. Time: 20289.9084 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #395: GFLOPs: 895.7882. Time: 23639.5084 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #396: GFLOPs: 1005.9241. Time: 21051.2834 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #397: GFLOPs: 1047.2739. Time: 20220.1084 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #398: GFLOPs: 1060.9598. Time: 19959.2778 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #399: GFLOPs: 882.3284. Time: 24000.1250 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #400: GFLOPs: 1043.3129. Time: 20296.8750 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #401: GFLOPs: 1040.5101. Time: 20351.5500 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #402: GFLOPs: 1042.1431. Time: 20319.6584 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #403: GFLOPs: 895.3381. Time: 23651.3918 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #404: GFLOPs: 1040.5369. Time: 20351.0250 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #405: GFLOPs: 1047.0905. Time: 20223.6500 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #406: GFLOPs: 1049.3771. Time: 20179.5834 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #407: GFLOPs: 894.4758. Time: 23674.1916 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #408: GFLOPs: 868.7070. Time: 24376.4500 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #409: GFLOPs: 1044.0185. Time: 20283.1584 us. Best GFLOPs: 1144.3329
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #410: GFLOPs: 1148.6435. Time: 18435.6528 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #411: GFLOPs: 995.3077. Time: 21275.8250 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #412: GFLOPs: 867.2314. Time: 24417.9250 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #413: GFLOPs: 922.3967. Time: 22957.5750 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #414: GFLOPs: 878.8098. Time: 24096.2166 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #415: GFLOPs: 858.0656. Time: 24678.7582 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #416: GFLOPs: 629.3819. Time: 33645.6947 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #417: GFLOPs: 637.7995. Time: 33201.6457 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #418: GFLOPs: 641.8446. Time: 32992.3958 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #419: GFLOPs: 908.0072. Time: 23321.3916 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #420: GFLOPs: 980.2603. Time: 21602.4166 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #421: GFLOPs: 1046.8455. Time: 20228.3832 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #422: GFLOPs: 755.1810. Time: 28040.9480 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #423: GFLOPs: 1025.9115. Time: 20641.1500 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #424: GFLOPs: 814.1087. Time: 26011.2605 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #425: GFLOPs: 1006.5608. Time: 21037.9668 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #426: GFLOPs: 1049.9212. Time: 20169.1250 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #427: GFLOPs: 863.7105. Time: 24517.4668 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #428: GFLOPs: 1047.1082. Time: 20223.3084 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #429: GFLOPs: 883.0045. Time: 23981.7500 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #430: GFLOPs: 886.9098. Time: 23876.1500 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #431: GFLOPs: 874.5850. Time: 24212.6166 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #432: GFLOPs: 874.2511. Time: 24221.8666 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #433: GFLOPs: 820.6265. Time: 25804.6668 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #434: GFLOPs: 1026.8392. Time: 20622.5000 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #435: GFLOPs: 1025.7934. Time: 20643.5250 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #436: GFLOPs: 1021.1835. Time: 20736.7166 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #437: GFLOPs: 885.5561. Time: 23912.6500 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #438: GFLOPs: 634.6118. Time: 33368.4167 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #439: GFLOPs: 1030.4665. Time: 20549.9084 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #440: GFLOPs: 886.2782. Time: 23893.1668 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #441: GFLOPs: 871.6316. Time: 24294.6584 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #442: GFLOPs: 1072.4793. Time: 19744.8958 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #443: GFLOPs: 904.5498. Time: 23410.5334 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #444: GFLOPs: 913.5994. Time: 23178.6416 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #445: GFLOPs: 871.4030. Time: 24301.0332 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #446: GFLOPs: 249.7042. Time: 84804.3057 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #447: GFLOPs: 120.6328. Time: 175540.9443 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #448: GFLOPs: 251.5889. Time: 84169.0140 us. Best GFLOPs: 1148.6435
2023-05-18 18:27:11 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 18:27:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 18:27:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 406 failure(s)
2023-05-18 18:27:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 810 failure(s)
2023-05-18 18:27:15 [INFO] [evolutionary_search.cc:723] Sampled 10 candidate(s)
2023-05-18 18:27:20 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 141 failure(s)
2023-05-18 18:27:26 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 122 failure(s)
2023-05-18 18:27:33 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 109 failure(s)
2023-05-18 18:27:40 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 120 failure(s)
2023-05-18 18:27:42 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8336  0.8314  0.8252  0.8224  0.8205  0.8134  0.8134  0.8111  0.8111  0.8104  0.8104  0.8087  0.8033  0.7995  0.7994  0.7994
[17 : 32]:	0.7931  0.7895  0.7895  0.7895  0.7893  0.7893  0.7893  0.7881  0.7881  0.7880  0.7852  0.7839  0.7790  0.7790  0.7772  0.7734
[33 : 48]:	0.7734  0.7726  0.7722  0.7684  0.7684  0.7684  0.7659  0.7659  0.7644  0.7640  0.7630  0.7630  0.7630  0.7630  0.7629  0.7621
[49 : 64]:	0.7616  0.7615  0.7613  0.7604  0.7598  0.7598  0.7594  0.7592  0.7592  0.7592  0.7592  0.7592  0.7592  0.7591  0.7587  0.7583
2023-05-18 18:27:42 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 18:27:42 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #449: GFLOPs: 1082.8567. Time: 19555.6735 us. Best GFLOPs: 1148.6435
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #450: GFLOPs: 1044.5592. Time: 20272.6584 us. Best GFLOPs: 1148.6435
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #451: GFLOPs: 877.0110. Time: 24145.6418 us. Best GFLOPs: 1148.6435
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #452: GFLOPs: 1107.8613. Time: 19114.2987 us. Best GFLOPs: 1148.6435
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #453: GFLOPs: 1088.8127. Time: 19448.7013 us. Best GFLOPs: 1148.6435
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #454: GFLOPs: 1153.6086. Time: 18356.3057 us. Best GFLOPs: 1153.6086
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #455: GFLOPs: 1031.1067. Time: 20537.1500 us. Best GFLOPs: 1153.6086
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #456: GFLOPs: 885.2186. Time: 23921.7666 us. Best GFLOPs: 1153.6086
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #457: GFLOPs: 916.1055. Time: 23115.2332 us. Best GFLOPs: 1153.6086
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #458: GFLOPs: 1125.6587. Time: 18812.0902 us. Best GFLOPs: 1153.6086
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #459: GFLOPs: 906.3313. Time: 23364.5166 us. Best GFLOPs: 1153.6086
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #460: GFLOPs: 1039.3346. Time: 20374.5668 us. Best GFLOPs: 1153.6086
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #461: GFLOPs: 1029.0669. Time: 20577.8584 us. Best GFLOPs: 1153.6086
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #462: GFLOPs: 865.9627. Time: 24453.7000 us. Best GFLOPs: 1153.6086
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #463: GFLOPs: 1161.9568. Time: 18224.4237 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #464: GFLOPs: 1149.4072. Time: 18423.4027 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #465: GFLOPs: 1028.9444. Time: 20580.3082 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #466: GFLOPs: 906.5835. Time: 23358.0168 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #467: GFLOPs: 1050.6288. Time: 20155.5418 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #468: GFLOPs: 1069.0791. Time: 19807.6945 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #469: GFLOPs: 1037.6366. Time: 20407.9082 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #470: GFLOPs: 1041.0135. Time: 20341.7084 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #471: GFLOPs: 1041.1355. Time: 20339.3250 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #472: GFLOPs: 1035.3738. Time: 20452.5084 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #473: GFLOPs: 1008.8634. Time: 20989.9500 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #474: GFLOPs: 1046.4519. Time: 20235.9916 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #475: GFLOPs: 1039.2199. Time: 20376.8166 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #476: GFLOPs: 1026.3109. Time: 20633.1166 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #477: GFLOPs: 1047.7161. Time: 20211.5750 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #478: GFLOPs: 1031.9668. Time: 20520.0334 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #479: GFLOPs: 1043.0911. Time: 20301.1916 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #480: GFLOPs: 1078.2325. Time: 19639.5417 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #481: GFLOPs: 1029.8430. Time: 20562.3500 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #482: GFLOPs: 863.8473. Time: 24513.5832 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #483: GFLOPs: 898.8605. Time: 23558.7084 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #484: GFLOPs: 1099.7588. Time: 19255.1250 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #485: GFLOPs: 1023.5935. Time: 20687.8916 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #486: GFLOPs: 1028.5866. Time: 20587.4666 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #487: GFLOPs: 893.9595. Time: 23687.8666 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #488: GFLOPs: 931.0836. Time: 22743.3834 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #489: GFLOPs: 839.1240. Time: 25235.8335 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #490: GFLOPs: 785.3835. Time: 26962.6145 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #491: GFLOPs: 1056.3045. Time: 20047.2416 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #492: GFLOPs: 913.1309. Time: 23190.5334 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #493: GFLOPs: 1077.3974. Time: 19654.7640 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #494: GFLOPs: 888.1079. Time: 23843.9418 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #495: GFLOPs: 1056.3770. Time: 20045.8666 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #496: GFLOPs: 1008.1290. Time: 21005.2416 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #497: GFLOPs: 1027.6727. Time: 20605.7750 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #498: GFLOPs: 1016.2651. Time: 20837.0750 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #499: GFLOPs: 979.9050. Time: 21610.2500 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #500: GFLOPs: 723.5546. Time: 29266.6145 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #501: GFLOPs: 943.0228. Time: 22455.4416 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #502: GFLOPs: 885.2926. Time: 23919.7666 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #503: GFLOPs: 1062.1162. Time: 19937.5485 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #504: GFLOPs: 866.5323. Time: 24437.6250 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #505: GFLOPs: 791.7174. Time: 26746.9062 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #506: GFLOPs: 888.9343. Time: 23821.7750 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #507: GFLOPs: 837.5454. Time: 25283.3957 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #508: GFLOPs: 1013.6107. Time: 20891.6416 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #509: GFLOPs: 838.2302. Time: 25262.7395 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #510: GFLOPs: 636.2708. Time: 33281.4165 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #511: GFLOPs: 6.9186. Time: 3060754.9863 us. Best GFLOPs: 1161.9568
2023-05-18 18:32:00 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #512: GFLOPs: 21.6150. Time: 979690.3890 us. Best GFLOPs: 1161.9568
2023-05-18 18:34:39 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 18:34:40 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 18:34:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 407 failure(s)
2023-05-18 18:34:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 814 failure(s)
2023-05-18 18:34:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1220 failure(s)
2023-05-18 18:34:45 [INFO] [evolutionary_search.cc:723] Sampled 10 candidate(s)
2023-05-18 18:34:50 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 113 failure(s)
2023-05-18 18:34:56 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 101 failure(s)
2023-05-18 18:35:03 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 103 failure(s)
2023-05-18 18:35:09 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 98 failure(s)
2023-05-18 18:35:12 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8539  0.8433  0.8311  0.8225  0.8225  0.8195  0.8174  0.8173  0.8139  0.8134  0.8134  0.8116  0.8093  0.8048  0.8043  0.8020
[17 : 32]:	0.8011  0.7996  0.7983  0.7938  0.7931  0.7931  0.7931  0.7893  0.7893  0.7881  0.7878  0.7858  0.7857  0.7855  0.7849  0.7843
[33 : 48]:	0.7825  0.7805  0.7790  0.7790  0.7790  0.7780  0.7778  0.7772  0.7772  0.7765  0.7745  0.7734  0.7727  0.7720  0.7712  0.7706
[49 : 64]:	0.7703  0.7695  0.7684  0.7684  0.7680  0.7656  0.7655  0.7650  0.7644  0.7644  0.7644  0.7643  0.7630  0.7629  0.7628  0.7621
2023-05-18 18:35:12 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 18:35:12 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #513: GFLOPs: 1139.1236. Time: 18589.7223 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #514: GFLOPs: 1031.7263. Time: 20524.8166 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #515: GFLOPs: 1048.6833. Time: 20192.9334 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #516: GFLOPs: 1019.7381. Time: 20766.1082 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #517: GFLOPs: 1030.8900. Time: 20541.4666 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #518: GFLOPs: 1095.1050. Time: 19336.9513 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #519: GFLOPs: 1009.8910. Time: 20968.5918 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #520: GFLOPs: 1043.1806. Time: 20299.4500 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #521: GFLOPs: 1070.7681. Time: 19776.4513 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #522: GFLOPs: 1140.5791. Time: 18566.0000 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #523: GFLOPs: 1040.9832. Time: 20342.3000 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #524: GFLOPs: 1045.1057. Time: 20262.0582 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #525: GFLOPs: 1046.3123. Time: 20238.6916 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #526: GFLOPs: 1024.1732. Time: 20676.1832 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #527: GFLOPs: 782.6799. Time: 27055.7500 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #528: GFLOPs: 1045.7056. Time: 20250.4334 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #529: GFLOPs: 1076.4865. Time: 19671.3958 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #530: GFLOPs: 1050.1759. Time: 20164.2332 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #531: GFLOPs: 984.7711. Time: 21503.4666 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #532: GFLOPs: 1055.7783. Time: 20057.2334 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #533: GFLOPs: 1027.8049. Time: 20603.1250 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #534: GFLOPs: 1025.0106. Time: 20659.2916 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #535: GFLOPs: 1100.0127. Time: 19250.6807 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #536: GFLOPs: 1037.2440. Time: 20415.6334 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #537: GFLOPs: 1038.2017. Time: 20396.8000 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #538: GFLOPs: 1054.5008. Time: 20081.5332 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #539: GFLOPs: 1014.0148. Time: 20883.3168 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #540: GFLOPs: 741.3960. Time: 28562.3230 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #541: GFLOPs: 880.9642. Time: 24037.2916 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #542: GFLOPs: 1047.7589. Time: 20210.7500 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #543: GFLOPs: 1026.7762. Time: 20623.7666 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #544: GFLOPs: 837.2484. Time: 25292.3645 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #545: GFLOPs: 1045.1074. Time: 20262.0250 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #546: GFLOPs: 1021.2003. Time: 20736.3750 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #547: GFLOPs: 1047.2113. Time: 20221.3168 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #548: GFLOPs: 1048.6379. Time: 20193.8082 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #549: GFLOPs: 1099.5224. Time: 19259.2638 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #550: GFLOPs: 881.4075. Time: 24025.2000 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #551: GFLOPs: 720.0785. Time: 29407.8960 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #552: GFLOPs: 1043.4295. Time: 20294.6084 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #553: GFLOPs: 1043.7406. Time: 20288.5584 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #554: GFLOPs: 1019.5720. Time: 20769.4916 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #555: GFLOPs: 983.4608. Time: 21532.1168 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #556: GFLOPs: 1076.3505. Time: 19673.8820 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #557: GFLOPs: 997.1081. Time: 21237.4084 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #558: GFLOPs: 1071.5499. Time: 19762.0208 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #559: GFLOPs: 1144.2745. Time: 18506.0417 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #560: GFLOPs: 849.4854. Time: 24928.0250 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #561: GFLOPs: 838.9224. Time: 25241.8957 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #562: GFLOPs: 902.6781. Time: 23459.0750 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #563: GFLOPs: 1024.3193. Time: 20673.2334 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #564: GFLOPs: 1022.7441. Time: 20705.0750 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #565: GFLOPs: 1015.3429. Time: 20856.0000 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #566: GFLOPs: 1124.7651. Time: 18827.0348 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #567: GFLOPs: 879.0467. Time: 24089.7250 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #568: GFLOPs: 940.7625. Time: 22509.3916 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #569: GFLOPs: 1008.0258. Time: 21007.3918 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #570: GFLOPs: 881.4586. Time: 24023.8084 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #571: GFLOPs: 1043.4762. Time: 20293.7000 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #572: GFLOPs: 913.8625. Time: 23171.9666 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #573: GFLOPs: 1040.8659. Time: 20344.5918 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #574: GFLOPs: 34.9004. Time: 606755.6943 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:121] [Task #10: fused_conv2d6_add_add2] Trial #575: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x00000001028eb34f
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:130
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 130
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[18:37:33] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (state != nil) is false: cannot get state: for function main_kernel0Compute function exceeds available temporary registers


# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv1773: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), self_rrdb_conv_body_weight: T.Buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), "float32"), lv1775: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1)), "float32"), lv2: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_conv_body_weight_shared = T.alloc_buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(112), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(640), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(64), nn_0_ff_0_yy_0_xx_0_fused // T.int64(56) * T.int64(32) + nn_1_ff_1_yy_1_xx_1_fused // T.int64(160) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) + ff_3_init + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused % T.int64(56) // T.int64(14) * T.int64(160) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(160) // T.int64(8) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(2) + yy_3_init + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(14) * T.int64(32) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(8) * T.int64(4) + xx_3_init * T.int64(4) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(64), T.int64(1), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(173)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(64), rc_0)
                                    v2 = T.axis.spatial(T.int64(642), nn_0_ff_0_yy_0_xx_0_fused % T.int64(56) // T.int64(14) * T.int64(160) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(34))
                                    v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(14) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(34))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1 < T.int64(5508))
                                    T.reads(lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("self_rrdb_conv_body.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(64), nn_0_ff_0_yy_0_xx_0_fused // T.int64(56) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(9))
                                        v1 = T.axis.spatial(T.int64(64), rc_0)
                                        v2 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(9) // T.int64(3))
                                        v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(288))
                                        T.reads(self_rrdb_conv_body_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_conv_body_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_conv_body_weight_shared[v0, v1, v2, v3] = self_rrdb_conv_body_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(64), nn_0_ff_0_yy_0_xx_0_fused // T.int64(56) * T.int64(32) + nn_1_ff_1_yy_1_xx_1_fused // T.int64(160) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) + ff_3 + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused % T.int64(56) // T.int64(14) * T.int64(160) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(160) // T.int64(8) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(2) + yy_3 + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(14) * T.int64(32) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(8) * T.int64(4) + xx_3 * T.int64(4) + xx_4)
                                v_rc = T.axis.reduce(T.int64(64), rc_0 + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 * T.int64(3) + ry_1 * T.int64(3) + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(64), nn_0_ff_0_yy_0_xx_0_fused // T.int64(56) * T.int64(32) + nn_1_ff_1_yy_1_xx_1_fused // T.int64(160) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused % T.int64(56) // T.int64(14) * T.int64(160) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(160) // T.int64(8) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(14) * T.int64(32) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(8) * T.int64(4) + ax3)
                            T.reads(lv2[v0, v1, v2, v3], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv1775[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_T_add_intermediate[v0, v1, v2, v3])
                            var_T_add_intermediate[v0, v1, v2, v3] = lv2[v0, v1, v2, v3] + (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv1775[v0, v1, T.int64(0), T.int64(0)])
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 4, 8, 1, 1])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[4, 20, 4, 2, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[14, 8, 1, 1, 4])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[64, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
2023-05-18 18:37:38 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #576: GFLOPs: 24.8515. Time: 852099.5973 us. Best GFLOPs: 1161.9568
2023-05-18 18:37:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 18:37:39 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 18:37:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 408 failure(s)
2023-05-18 18:37:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 817 failure(s)
2023-05-18 18:37:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1225 failure(s)
2023-05-18 18:37:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1634 failure(s)
2023-05-18 18:37:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 2041 failure(s)
2023-05-18 18:37:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 2449 failure(s)
2023-05-18 18:37:49 [INFO] [evolutionary_search.cc:723] Sampled 11 candidate(s)
2023-05-18 18:37:54 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 105 failure(s)
2023-05-18 18:38:00 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 88 failure(s)
2023-05-18 18:38:06 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 102 failure(s)
2023-05-18 18:38:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 90 failure(s)
2023-05-18 18:38:16 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8408  0.8397  0.8276  0.8225  0.8189  0.8134  0.8104  0.8084  0.8064  0.8022  0.8022  0.7999  0.7999  0.7999  0.7996  0.7973
[17 : 32]:	0.7935  0.7931  0.7931  0.7931  0.7893  0.7831  0.7825  0.7803  0.7790  0.7790  0.7776  0.7772  0.7772  0.7769  0.7734  0.7734
[33 : 48]:	0.7700  0.7683  0.7670  0.7638  0.7630  0.7629  0.7621  0.7620  0.7616  0.7615  0.7615  0.7615  0.7615  0.7607  0.7606  0.7598
[49 : 64]:	0.7596  0.7595  0.7594  0.7587  0.7585  0.7574  0.7568  0.7566  0.7565  0.7564  0.7564  0.7552  0.7539  0.7539  0.7536  0.7531
2023-05-18 18:38:16 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 18:38:16 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #577: GFLOPs: 1136.6910. Time: 18629.5070 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #578: GFLOPs: 1143.5287. Time: 18518.1110 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #579: GFLOPs: 1151.1229. Time: 18395.9443 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #580: GFLOPs: 1037.0018. Time: 20420.4000 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #581: GFLOPs: 1091.8313. Time: 19394.9305 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #582: GFLOPs: 1036.4059. Time: 20432.1416 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #583: GFLOPs: 1039.3049. Time: 20375.1500 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #584: GFLOPs: 1043.5272. Time: 20292.7084 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #585: GFLOPs: 1088.5386. Time: 19453.5972 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #586: GFLOPs: 1062.2264. Time: 19935.4792 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #587: GFLOPs: 1025.8216. Time: 20642.9582 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #588: GFLOPs: 1016.2696. Time: 20836.9832 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #589: GFLOPs: 1037.4764. Time: 20411.0584 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #590: GFLOPs: 995.4492. Time: 21272.8000 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #591: GFLOPs: 1023.4089. Time: 20691.6250 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #592: GFLOPs: 1034.8232. Time: 20463.3918 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #593: GFLOPs: 1085.3168. Time: 19511.3472 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #594: GFLOPs: 1091.6820. Time: 19397.5833 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #595: GFLOPs: 1023.7729. Time: 20684.2668 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #596: GFLOPs: 1019.3417. Time: 20774.1834 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #597: GFLOPs: 1145.7867. Time: 18481.6180 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #598: GFLOPs: 898.0270. Time: 23580.5750 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #599: GFLOPs: 981.1191. Time: 21583.5084 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #600: GFLOPs: 1054.2702. Time: 20085.9250 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #601: GFLOPs: 1107.5394. Time: 19119.8542 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #602: GFLOPs: 1062.1454. Time: 19937.0000 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #603: GFLOPs: 1107.6271. Time: 19118.3403 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #604: GFLOPs: 1041.3624. Time: 20334.8916 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #605: GFLOPs: 1153.9168. Time: 18351.4028 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #606: GFLOPs: 1026.0817. Time: 20637.7250 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #607: GFLOPs: 1026.8824. Time: 20621.6334 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #608: GFLOPs: 1026.0042. Time: 20639.2834 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #609: GFLOPs: 790.2006. Time: 26798.2500 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #610: GFLOPs: 1022.8009. Time: 20703.9250 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #611: GFLOPs: 1034.6724. Time: 20466.3750 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #612: GFLOPs: 1029.6632. Time: 20565.9416 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #613: GFLOPs: 902.7980. Time: 23455.9584 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #614: GFLOPs: 1037.8722. Time: 20403.2750 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #615: GFLOPs: 1056.9473. Time: 20035.0500 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #616: GFLOPs: 1038.0944. Time: 20398.9082 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #617: GFLOPs: 797.3126. Time: 26559.2085 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #618: GFLOPs: 1057.8660. Time: 20017.6500 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #619: GFLOPs: 1009.6366. Time: 20973.8750 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #620: GFLOPs: 1012.1226. Time: 20922.3582 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #621: GFLOPs: 1017.3551. Time: 20814.7500 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #622: GFLOPs: 998.7812. Time: 21201.8334 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #623: GFLOPs: 997.5496. Time: 21228.0084 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #624: GFLOPs: 1049.8371. Time: 20170.7416 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #625: GFLOPs: 828.6749. Time: 25554.0418 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #626: GFLOPs: 1047.5843. Time: 20214.1168 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #627: GFLOPs: 862.8594. Time: 24541.6500 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #628: GFLOPs: 1031.1966. Time: 20535.3582 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #629: GFLOPs: 1142.5163. Time: 18534.5208 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #630: GFLOPs: 879.4230. Time: 24079.4166 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #631: GFLOPs: 1065.3995. Time: 19876.1042 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #632: GFLOPs: 906.5948. Time: 23357.7250 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #633: GFLOPs: 776.7152. Time: 27263.5210 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #634: GFLOPs: 1042.9532. Time: 20303.8750 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #635: GFLOPs: 1048.2365. Time: 20201.5416 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #636: GFLOPs: 1042.6528. Time: 20309.7250 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #637: GFLOPs: 886.9572. Time: 23874.8750 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #638: GFLOPs: 22.5637. Time: 938499.8613 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #639: GFLOPs: 10.1205. Time: 2092388.8333 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #640: GFLOPs: 39.9815. Time: 529645.2500 us. Best GFLOPs: 1161.9568
2023-05-18 18:39:40 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 18:39:41 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 18:39:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 405 failure(s)
2023-05-18 18:39:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 813 failure(s)
2023-05-18 18:39:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1222 failure(s)
2023-05-18 18:39:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1632 failure(s)
2023-05-18 18:39:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 2039 failure(s)
2023-05-18 18:39:50 [INFO] [evolutionary_search.cc:723] Sampled 11 candidate(s)
2023-05-18 18:39:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 121 failure(s)
2023-05-18 18:40:01 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 94 failure(s)
2023-05-18 18:40:08 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 111 failure(s)
2023-05-18 18:40:14 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 115 failure(s)
2023-05-18 18:40:17 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8313  0.8268  0.8203  0.8084  0.8068  0.8008  0.7995  0.7931  0.7924  0.7874  0.7804  0.7803  0.7764  0.7722  0.7690  0.7676
[17 : 32]:	0.7613  0.7584  0.7583  0.7573  0.7570  0.7566  0.7565  0.7564  0.7564  0.7564  0.7564  0.7557  0.7553  0.7543  0.7539  0.7536
[33 : 48]:	0.7536  0.7536  0.7531  0.7531  0.7531  0.7522  0.7518  0.7518  0.7518  0.7513  0.7510  0.7509  0.7507  0.7507  0.7486  0.7482
[49 : 64]:	0.7480  0.7475  0.7475  0.7464  0.7461  0.7456  0.7455  0.7453  0.7451  0.7449  0.7449  0.7447  0.7444  0.7434  0.7433  0.7433
2023-05-18 18:40:17 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 18:40:17 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #641: GFLOPs: 1029.9749. Time: 20559.7166 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #642: GFLOPs: 1139.4574. Time: 18584.2778 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #643: GFLOPs: 1142.8516. Time: 18529.0833 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #644: GFLOPs: 1012.4694. Time: 20915.1916 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #645: GFLOPs: 1100.5637. Time: 19241.0417 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #646: GFLOPs: 1071.7450. Time: 19758.4237 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #647: GFLOPs: 1092.0600. Time: 19390.8682 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #648: GFLOPs: 1023.1942. Time: 20695.9666 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #649: GFLOPs: 1052.0708. Time: 20127.9166 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #650: GFLOPs: 1100.7020. Time: 19238.6250 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #651: GFLOPs: 1090.0441. Time: 19426.7292 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #652: GFLOPs: 1102.1091. Time: 19214.0625 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #653: GFLOPs: 1025.9052. Time: 20641.2750 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #654: GFLOPs: 926.4369. Time: 22857.4584 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #655: GFLOPs: 1031.8570. Time: 20522.2166 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #656: GFLOPs: 734.9862. Time: 28811.4168 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #657: GFLOPs: 1048.8231. Time: 20190.2418 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #658: GFLOPs: 1136.9457. Time: 18625.3333 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #659: GFLOPs: 644.5682. Time: 32852.9898 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #660: GFLOPs: 1004.1675. Time: 21088.1084 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #661: GFLOPs: 1041.6250. Time: 20329.7666 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #662: GFLOPs: 995.4913. Time: 21271.9000 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #663: GFLOPs: 1042.7093. Time: 20308.6250 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #664: GFLOPs: 1099.6453. Time: 19257.1112 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #665: GFLOPs: 1048.4293. Time: 20197.8250 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #666: GFLOPs: 1047.7459. Time: 20211.0000 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #667: GFLOPs: 1103.6172. Time: 19187.8055 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #668: GFLOPs: 728.9075. Time: 29051.6875 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #669: GFLOPs: 903.0316. Time: 23449.8918 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #670: GFLOPs: 1037.4498. Time: 20411.5832 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #671: GFLOPs: 897.9892. Time: 23581.5668 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #672: GFLOPs: 881.9609. Time: 24010.1250 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #673: GFLOPs: 647.6742. Time: 32695.4375 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #674: GFLOPs: 664.5596. Time: 31864.6978 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #675: GFLOPs: 1047.2265. Time: 20221.0250 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #676: GFLOPs: 1046.7709. Time: 20229.8250 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #677: GFLOPs: 1043.3296. Time: 20296.5500 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #678: GFLOPs: 1055.7459. Time: 20057.8500 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #679: GFLOPs: 843.7232. Time: 25098.2707 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #680: GFLOPs: 872.4064. Time: 24273.0834 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #681: GFLOPs: 1007.5030. Time: 21018.2916 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #682: GFLOPs: 1009.9127. Time: 20968.1416 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #683: GFLOPs: 894.1639. Time: 23682.4500 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #684: GFLOPs: 1032.1332. Time: 20516.7250 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #685: GFLOPs: 1083.0032. Time: 19553.0277 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #686: GFLOPs: 1033.8317. Time: 20483.0166 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #687: GFLOPs: 750.6320. Time: 28210.8852 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #688: GFLOPs: 1008.1722. Time: 21004.3416 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #689: GFLOPs: 900.9358. Time: 23504.4418 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #690: GFLOPs: 879.1218. Time: 24087.6666 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #691: GFLOPs: 887.2815. Time: 23866.1500 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #692: GFLOPs: 726.9679. Time: 29129.1980 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #693: GFLOPs: 1090.3782. Time: 19420.7778 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #694: GFLOPs: 937.7394. Time: 22581.9584 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #695: GFLOPs: 998.5488. Time: 21206.7666 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #696: GFLOPs: 1013.8352. Time: 20887.0166 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #697: GFLOPs: 944.2092. Time: 22427.2250 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #698: GFLOPs: 904.8090. Time: 23403.8250 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #699: GFLOPs: 906.5114. Time: 23359.8750 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #700: GFLOPs: 1068.0052. Time: 19827.6112 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #701: GFLOPs: 791.3082. Time: 26760.7395 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:121] [Task #10: fused_conv2d6_add_add2] Trial #702: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x000000010248baaf
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:130
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 130
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[18:41:18] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (state != nil) is false: cannot get state: for function main_kernel0Compute function exceeds available temporary registers


# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv1773: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), self_rrdb_conv_body_weight: T.Buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), "float32"), lv1775: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1)), "float32"), lv2: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_conv_body_weight_shared = T.alloc_buffer((T.int64(64), T.int64(64), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(80), thread="blockIdx.x"):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(32), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused // T.int64(4) * T.int64(8) + ff_3_init + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(64) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(4) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(7) * T.int64(2) + yy_3_init + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(56) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(7) * T.int64(8) + xx_3_init * T.int64(2) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(64), T.int64(1), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(23)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(3)):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v1 = T.axis.spatial(T.int64(64), rc_0)
                                        v2 = T.axis.spatial(T.int64(642), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(168) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) // T.int64(58))
                                        v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(56) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(168) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) % T.int64(58))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) * T.int64(3) + ax0_ax1_ax2_ax3_fused_2 < T.int64(3828))
                                        T.reads(lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv1773[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(11)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                                with T.block("self_rrdb_conv_body.weight_shared"):
                                    v0 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) // T.int64(9))
                                    v1 = T.axis.spatial(T.int64(64), rc_0)
                                    v2 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(9) // T.int64(3))
                                    v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(3))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1 < T.int64(576))
                                    T.reads(self_rrdb_conv_body_weight[v0, v1, v2, v3])
                                    T.writes(self_rrdb_conv_body_weight_shared[v0, v1, v2, v3])
                                    self_rrdb_conv_body_weight_shared[v0, v1, v2, v3] = self_rrdb_conv_body_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(2), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused // T.int64(4) * T.int64(8) + ff_3 + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(64) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(4) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(7) * T.int64(2) + yy_3 + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(56) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(7) * T.int64(8) + xx_3 * T.int64(2) + xx_4)
                                v_rc = T.axis.reduce(T.int64(64), rc_0 + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 * T.int64(3) + ry_1 * T.int64(3) + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_conv_body_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(8)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(64), nn_1_ff_1_yy_1_xx_1_fused // T.int64(4) * T.int64(8) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(64) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(4) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(7) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(56) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(7) * T.int64(8) + ax3)
                            T.reads(lv2[v0, v1, v2, v3], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv1775[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_T_add_intermediate[v0, v1, v2, v3])
                            var_T_add_intermediate[v0, v1, v2, v3] = lv2[v0, v1, v2, v3] + (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv1775[v0, v1, T.int64(0), T.int64(0)])
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 8, 1, 8, 1])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[10, 4, 8, 2, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[8, 1, 7, 4, 2])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[64, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 56, 3], preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119 = sch.split(loop=l117, factors=[None, 56], preserve_unit_iters=True)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b121)
l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #703: GFLOPs: 195.8727. Time: 108111.0137 us. Best GFLOPs: 1161.9568
2023-05-18 18:44:18 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #704: GFLOPs: 148.1720. Time: 142914.9443 us. Best GFLOPs: 1161.9568
2023-05-18 18:47:01 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 18:47:02 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 18:47:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 403 failure(s)
2023-05-18 18:47:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 808 failure(s)
2023-05-18 18:47:05 [INFO] [evolutionary_search.cc:723] Sampled 12 candidate(s)
2023-05-18 18:47:10 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 103 failure(s)
2023-05-18 18:47:17 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 98 failure(s)
2023-05-18 18:47:23 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 118 failure(s)
2023-05-18 18:47:30 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 123 failure(s)
2023-05-18 18:47:33 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8118  0.8028  0.7987  0.7900  0.7893  0.7889  0.7830  0.7813  0.7796  0.7790  0.7772  0.7759  0.7749  0.7734  0.7734  0.7706
[17 : 32]:	0.7706  0.7700  0.7684  0.7684  0.7625  0.7621  0.7616  0.7615  0.7609  0.7600  0.7576  0.7571  0.7570  0.7567  0.7542  0.7531
[33 : 48]:	0.7531  0.7531  0.7531  0.7524  0.7507  0.7501  0.7495  0.7486  0.7486  0.7486  0.7476  0.7475  0.7475  0.7465  0.7461  0.7450
[49 : 64]:	0.7449  0.7443  0.7433  0.7433  0.7433  0.7429  0.7427  0.7417  0.7417  0.7410  0.7397  0.7397  0.7394  0.7393  0.7393  0.7393
2023-05-18 18:47:33 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 18:47:33 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #705: GFLOPs: 1053.9077. Time: 20092.8332 us. Best GFLOPs: 1161.9568
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #706: GFLOPs: 1097.9906. Time: 19286.1320 us. Best GFLOPs: 1161.9568
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #707: GFLOPs: 1030.3809. Time: 20551.6166 us. Best GFLOPs: 1161.9568
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #708: GFLOPs: 975.9283. Time: 21698.3082 us. Best GFLOPs: 1161.9568
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #709: GFLOPs: 1037.2097. Time: 20416.3084 us. Best GFLOPs: 1161.9568
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #710: GFLOPs: 1048.0324. Time: 20205.4750 us. Best GFLOPs: 1161.9568
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #711: GFLOPs: 1051.2034. Time: 20144.5250 us. Best GFLOPs: 1161.9568
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #712: GFLOPs: 1031.2163. Time: 20534.9668 us. Best GFLOPs: 1161.9568
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #713: GFLOPs: 1104.5943. Time: 19170.8333 us. Best GFLOPs: 1161.9568
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #714: GFLOPs: 1048.7279. Time: 20192.0750 us. Best GFLOPs: 1161.9568
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #715: GFLOPs: 1162.5233. Time: 18215.5417 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #716: GFLOPs: 1044.8689. Time: 20266.6500 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #717: GFLOPs: 1037.0657. Time: 20419.1416 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #718: GFLOPs: 966.1473. Time: 21917.9750 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #719: GFLOPs: 1025.3783. Time: 20651.8834 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #720: GFLOPs: 942.5579. Time: 22466.5168 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #721: GFLOPs: 998.2648. Time: 21212.8000 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #722: GFLOPs: 1045.7930. Time: 20248.7416 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #723: GFLOPs: 1084.2154. Time: 19531.1667 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #724: GFLOPs: 1023.4637. Time: 20690.5168 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #725: GFLOPs: 1022.3898. Time: 20712.2500 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #726: GFLOPs: 1029.0256. Time: 20578.6834 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #727: GFLOPs: 1033.7459. Time: 20484.7166 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #728: GFLOPs: 1063.5871. Time: 19909.9740 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #729: GFLOPs: 1105.0150. Time: 19163.5347 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #730: GFLOPs: 889.5504. Time: 23805.2750 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #731: GFLOPs: 960.2699. Time: 22052.1250 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #732: GFLOPs: 898.3013. Time: 23573.3750 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #733: GFLOPs: 1040.0403. Time: 20360.7416 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #734: GFLOPs: 1020.1684. Time: 20757.3500 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #735: GFLOPs: 796.5507. Time: 26584.6145 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #736: GFLOPs: 1047.5848. Time: 20214.1084 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #737: GFLOPs: 1106.6086. Time: 19135.9375 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #738: GFLOPs: 1110.8572. Time: 19062.7500 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #739: GFLOPs: 1047.0685. Time: 20224.0750 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #740: GFLOPs: 1010.6441. Time: 20952.9668 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #741: GFLOPs: 1072.6672. Time: 19741.4375 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #742: GFLOPs: 651.2438. Time: 32516.2293 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #743: GFLOPs: 995.8257. Time: 21264.7584 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #744: GFLOPs: 908.9569. Time: 23297.0250 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #745: GFLOPs: 774.1995. Time: 27352.1145 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #746: GFLOPs: 924.4393. Time: 22906.8500 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #747: GFLOPs: 1032.7401. Time: 20504.6666 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #748: GFLOPs: 1046.7506. Time: 20230.2168 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #749: GFLOPs: 886.4306. Time: 23889.0582 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #750: GFLOPs: 927.5697. Time: 22829.5418 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #751: GFLOPs: 1033.0790. Time: 20497.9418 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #752: GFLOPs: 823.2332. Time: 25722.9582 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #753: GFLOPs: 902.4501. Time: 23465.0000 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #754: GFLOPs: 837.0305. Time: 25298.9480 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #755: GFLOPs: 1013.4365. Time: 20895.2334 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #756: GFLOPs: 1063.1055. Time: 19918.9947 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #757: GFLOPs: 635.0493. Time: 33345.4303 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #758: GFLOPs: 1004.6216. Time: 21078.5750 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #759: GFLOPs: 1025.6423. Time: 20646.5666 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #760: GFLOPs: 643.4113. Time: 32912.0625 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #761: GFLOPs: 728.4319. Time: 29070.6562 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #762: GFLOPs: 875.0645. Time: 24199.3500 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #763: GFLOPs: 844.8979. Time: 25063.3750 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #764: GFLOPs: 1013.0192. Time: 20903.8416 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #765: GFLOPs: 954.9859. Time: 22174.1416 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #766: GFLOPs: 807.7667. Time: 26215.4793 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #767: GFLOPs: 81.0265. Time: 261346.6250 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #768: GFLOPs: 118.6377. Time: 178492.8750 us. Best GFLOPs: 1162.5233
2023-05-18 18:48:39 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 18:48:40 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 18:48:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 407 failure(s)
2023-05-18 18:48:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 811 failure(s)
2023-05-18 18:48:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1216 failure(s)
2023-05-18 18:48:45 [INFO] [evolutionary_search.cc:723] Sampled 14 candidate(s)
2023-05-18 18:48:50 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 95 failure(s)
2023-05-18 18:48:57 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 108 failure(s)
2023-05-18 18:49:03 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 118 failure(s)
2023-05-18 18:49:09 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 112 failure(s)
2023-05-18 18:49:12 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8208  0.8082  0.7994  0.7971  0.7934  0.7878  0.7846  0.7817  0.7810  0.7790  0.7744  0.7715  0.7676  0.7670  0.7670  0.7659
[17 : 32]:	0.7640  0.7638  0.7613  0.7601  0.7574  0.7572  0.7564  0.7555  0.7545  0.7539  0.7534  0.7528  0.7521  0.7519  0.7515  0.7507
[33 : 48]:	0.7507  0.7507  0.7501  0.7500  0.7498  0.7496  0.7495  0.7489  0.7480  0.7480  0.7475  0.7475  0.7449  0.7449  0.7449  0.7437
[49 : 64]:	0.7433  0.7433  0.7433  0.7433  0.7433  0.7425  0.7423  0.7421  0.7419  0.7413  0.7404  0.7380  0.7380  0.7379  0.7378  0.7378
2023-05-18 18:49:12 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 18:49:12 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #769: GFLOPs: 1004.4024. Time: 21083.1750 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #770: GFLOPs: 1147.5019. Time: 18453.9930 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #771: GFLOPs: 1043.4749. Time: 20293.7250 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #772: GFLOPs: 1040.1306. Time: 20358.9750 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #773: GFLOPs: 685.3088. Time: 30899.9270 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #774: GFLOPs: 1043.4882. Time: 20293.4666 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #775: GFLOPs: 862.4813. Time: 24552.4082 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #776: GFLOPs: 1070.7274. Time: 19777.2015 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #777: GFLOPs: 1035.2022. Time: 20455.9000 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #778: GFLOPs: 1042.1713. Time: 20319.1082 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #779: GFLOPs: 1055.0165. Time: 20071.7168 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #780: GFLOPs: 1106.0009. Time: 19146.4515 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #781: GFLOPs: 1026.0096. Time: 20639.1750 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #782: GFLOPs: 1049.1197. Time: 20184.5332 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #783: GFLOPs: 1012.6179. Time: 20912.1250 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #784: GFLOPs: 975.7993. Time: 21701.1750 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #785: GFLOPs: 654.0367. Time: 32377.3750 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #786: GFLOPs: 812.2007. Time: 26072.3645 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #787: GFLOPs: 643.8435. Time: 32889.9688 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #788: GFLOPs: 965.3215. Time: 21936.7250 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #789: GFLOPs: 975.2189. Time: 21714.0918 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #790: GFLOPs: 1136.4550. Time: 18633.3750 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #791: GFLOPs: 1043.3279. Time: 20296.5834 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #792: GFLOPs: 970.3676. Time: 21822.6500 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #793: GFLOPs: 1128.1294. Time: 18770.8890 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #794: GFLOPs: 996.2860. Time: 21254.9334 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #795: GFLOPs: 834.6092. Time: 25372.3438 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #796: GFLOPs: 1033.6362. Time: 20486.8916 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #797: GFLOPs: 662.7208. Time: 31953.1145 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #798: GFLOPs: 941.0479. Time: 22502.5668 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #799: GFLOPs: 885.3913. Time: 23917.1000 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #800: GFLOPs: 1024.0427. Time: 20678.8168 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #801: GFLOPs: 1030.5977. Time: 20547.2916 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #802: GFLOPs: 1030.4556. Time: 20550.1250 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #803: GFLOPs: 1036.3552. Time: 20433.1416 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #804: GFLOPs: 961.4609. Time: 22024.8084 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #805: GFLOPs: 1035.1794. Time: 20456.3500 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #806: GFLOPs: 1031.4139. Time: 20531.0334 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #807: GFLOPs: 1036.5670. Time: 20428.9668 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #808: GFLOPs: 1035.7283. Time: 20445.5082 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #809: GFLOPs: 1051.9022. Time: 20131.1416 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #810: GFLOPs: 1020.1164. Time: 20758.4084 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #811: GFLOPs: 1049.4304. Time: 20178.5584 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #812: GFLOPs: 887.3487. Time: 23864.3418 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #813: GFLOPs: 938.8505. Time: 22555.2334 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #814: GFLOPs: 928.4794. Time: 22807.1750 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #815: GFLOPs: 902.7942. Time: 23456.0584 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #816: GFLOPs: 622.6270. Time: 34010.7220 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #817: GFLOPs: 1010.9955. Time: 20945.6832 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #818: GFLOPs: 1011.8550. Time: 20927.8916 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #819: GFLOPs: 1055.4025. Time: 20064.3750 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #820: GFLOPs: 1126.0910. Time: 18804.8680 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #821: GFLOPs: 908.3604. Time: 23312.3250 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #822: GFLOPs: 1032.8207. Time: 20503.0666 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #823: GFLOPs: 970.5811. Time: 21817.8500 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #824: GFLOPs: 967.9322. Time: 21877.5584 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #825: GFLOPs: 1022.0090. Time: 20719.9666 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #826: GFLOPs: 633.9437. Time: 33403.5833 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #827: GFLOPs: 876.9650. Time: 24146.9084 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #828: GFLOPs: 1039.5408. Time: 20370.5250 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #829: GFLOPs: 990.8303. Time: 21371.9668 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #830: GFLOPs: 87.3847. Time: 242330.7083 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #831: GFLOPs: 553.0291. Time: 38290.9167 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #832: GFLOPs: 379.3061. Time: 55828.2360 us. Best GFLOPs: 1162.5233
2023-05-18 18:50:26 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 18:50:27 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 18:50:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 406 failure(s)
2023-05-18 18:50:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 811 failure(s)
2023-05-18 18:50:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1214 failure(s)
2023-05-18 18:50:32 [INFO] [evolutionary_search.cc:723] Sampled 16 candidate(s)
2023-05-18 18:50:36 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 97 failure(s)
2023-05-18 18:50:43 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 116 failure(s)
2023-05-18 18:50:49 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 106 failure(s)
2023-05-18 18:50:55 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 104 failure(s)
2023-05-18 18:50:58 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9560  0.9549  0.9545  0.9523  0.9507  0.9428  0.9367  0.9355  0.9325  0.9299  0.9295  0.9225  0.9192  0.9149  0.9142  0.9120
[17 : 32]:	0.9088  0.9088  0.9078  0.9067  0.9066  0.9066  0.9066  0.9066  0.9050  0.9027  0.9021  0.9015  0.9012  0.9008  0.8990  0.8977
[33 : 48]:	0.8939  0.8939  0.8935  0.8923  0.8905  0.8887  0.8878  0.8878  0.8871  0.8866  0.8860  0.8858  0.8852  0.8850  0.8836  0.8833
[49 : 64]:	0.8794  0.8793  0.8761  0.8753  0.8752  0.8744  0.8741  0.8722  0.8710  0.8700  0.8695  0.8695  0.8695  0.8689  0.8689  0.8640
2023-05-18 18:50:58 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 18:50:58 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #833: GFLOPs: 1069.6202. Time: 19797.6735 us. Best GFLOPs: 1162.5233
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #834: GFLOPs: 1095.0095. Time: 19338.6388 us. Best GFLOPs: 1162.5233
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #835: GFLOPs: 1149.9347. Time: 18414.9513 us. Best GFLOPs: 1162.5233
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #836: GFLOPs: 1098.2358. Time: 19281.8263 us. Best GFLOPs: 1162.5233
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #837: GFLOPs: 1089.5678. Time: 19435.2222 us. Best GFLOPs: 1162.5233
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #838: GFLOPs: 1053.7792. Time: 20095.2834 us. Best GFLOPs: 1162.5233
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #839: GFLOPs: 1067.6436. Time: 19834.3265 us. Best GFLOPs: 1162.5233
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #840: GFLOPs: 1045.0605. Time: 20262.9334 us. Best GFLOPs: 1162.5233
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #841: GFLOPs: 1091.8364. Time: 19394.8402 us. Best GFLOPs: 1162.5233
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #842: GFLOPs: 1167.7736. Time: 18133.6458 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #843: GFLOPs: 1068.0969. Time: 19825.9097 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #844: GFLOPs: 1093.1790. Time: 19371.0208 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #845: GFLOPs: 1047.9425. Time: 20207.2082 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #846: GFLOPs: 1020.8504. Time: 20743.4832 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #847: GFLOPs: 1039.0006. Time: 20381.1166 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #848: GFLOPs: 1099.0477. Time: 19267.5833 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #849: GFLOPs: 1026.2541. Time: 20634.2584 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #850: GFLOPs: 1025.6705. Time: 20646.0000 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #851: GFLOPs: 1032.3843. Time: 20511.7334 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #852: GFLOPs: 1032.2761. Time: 20513.8834 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #853: GFLOPs: 1114.6575. Time: 18997.7570 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #854: GFLOPs: 1048.0428. Time: 20205.2750 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #855: GFLOPs: 1042.4497. Time: 20313.6834 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #856: GFLOPs: 1106.6736. Time: 19134.8125 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #857: GFLOPs: 1046.3597. Time: 20237.7750 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #858: GFLOPs: 1041.3505. Time: 20335.1250 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #859: GFLOPs: 1073.1527. Time: 19732.5070 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #860: GFLOPs: 1041.4252. Time: 20333.6666 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #861: GFLOPs: 1031.8586. Time: 20522.1834 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #862: GFLOPs: 1028.0423. Time: 20598.3668 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #863: GFLOPs: 1042.4146. Time: 20314.3668 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #864: GFLOPs: 1039.4213. Time: 20372.8666 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #865: GFLOPs: 945.6861. Time: 22392.2000 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #866: GFLOPs: 959.6262. Time: 22066.9168 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #867: GFLOPs: 1125.6038. Time: 18813.0070 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #868: GFLOPs: 1023.3017. Time: 20693.7916 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #869: GFLOPs: 977.4197. Time: 21665.2000 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #870: GFLOPs: 1120.4258. Time: 18899.9513 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #871: GFLOPs: 1057.6085. Time: 20022.5250 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #872: GFLOPs: 1011.7539. Time: 20929.9832 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #873: GFLOPs: 1149.4207. Time: 18423.1875 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #874: GFLOPs: 1043.9593. Time: 20284.3084 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #875: GFLOPs: 1024.4399. Time: 20670.8000 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #876: GFLOPs: 1019.5217. Time: 20770.5166 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #877: GFLOPs: 1048.6119. Time: 20194.3082 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #878: GFLOPs: 1009.8842. Time: 20968.7334 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #879: GFLOPs: 1030.0442. Time: 20558.3334 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #880: GFLOPs: 1096.7624. Time: 19307.7292 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #881: GFLOPs: 1026.7969. Time: 20623.3500 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #882: GFLOPs: 1091.2608. Time: 19405.0695 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #883: GFLOPs: 986.9447. Time: 21456.1084 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #884: GFLOPs: 1124.0947. Time: 18838.2638 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #885: GFLOPs: 966.0672. Time: 21919.7918 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #886: GFLOPs: 1164.1633. Time: 18189.8820 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #887: GFLOPs: 1007.2786. Time: 21022.9750 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #888: GFLOPs: 1018.3311. Time: 20794.8000 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #889: GFLOPs: 1009.1062. Time: 20984.9000 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #890: GFLOPs: 1130.4258. Time: 18732.7570 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #891: GFLOPs: 1048.9357. Time: 20188.0750 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #892: GFLOPs: 1054.0970. Time: 20089.2250 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #893: GFLOPs: 886.3174. Time: 23892.1084 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #894: GFLOPs: 47.2943. Time: 447749.3750 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #895: GFLOPs: 40.5594. Time: 522098.1110 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #896: GFLOPs: 121.5810. Time: 174171.8610 us. Best GFLOPs: 1167.7736
2023-05-18 18:52:08 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 18:52:08 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 18:52:10 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 404 failure(s)
2023-05-18 18:52:12 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 808 failure(s)
2023-05-18 18:52:12 [INFO] [evolutionary_search.cc:723] Sampled 12 candidate(s)
2023-05-18 18:52:17 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 121 failure(s)
2023-05-18 18:52:23 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 96 failure(s)
2023-05-18 18:52:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 105 failure(s)
2023-05-18 18:52:36 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 136 failure(s)
2023-05-18 18:52:39 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9591  0.9560  0.9491  0.9382  0.9332  0.9315  0.9310  0.9283  0.9228  0.9151  0.9142  0.9120  0.9114  0.9110  0.9097  0.9075
[17 : 32]:	0.9066  0.9066  0.9050  0.9047  0.9043  0.9038  0.9024  0.9005  0.8981  0.8965  0.8964  0.8955  0.8953  0.8941  0.8939  0.8935
[33 : 48]:	0.8935  0.8929  0.8923  0.8884  0.8871  0.8861  0.8829  0.8829  0.8811  0.8798  0.8792  0.8775  0.8775  0.8774  0.8772  0.8767
[49 : 64]:	0.8765  0.8744  0.8744  0.8744  0.8729  0.8715  0.8712  0.8710  0.8708  0.8698  0.8680  0.8669  0.8660  0.8647  0.8647  0.8647
2023-05-18 18:52:39 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 18:52:39 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #897: GFLOPs: 1089.7582. Time: 19431.8263 us. Best GFLOPs: 1167.7736
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #898: GFLOPs: 1090.7912. Time: 19413.4237 us. Best GFLOPs: 1167.7736
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #899: GFLOPs: 1074.0867. Time: 19715.3472 us. Best GFLOPs: 1167.7736
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #900: GFLOPs: 1169.9569. Time: 18099.8057 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #901: GFLOPs: 1029.5476. Time: 20568.2500 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #902: GFLOPs: 1031.3167. Time: 20532.9668 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #903: GFLOPs: 1076.4535. Time: 19672.0000 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #904: GFLOPs: 1117.7935. Time: 18944.4583 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #905: GFLOPs: 1105.2300. Time: 19159.8057 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #906: GFLOPs: 1048.1500. Time: 20203.2084 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #907: GFLOPs: 1039.5685. Time: 20369.9834 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #908: GFLOPs: 1048.5072. Time: 20196.3250 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #909: GFLOPs: 1047.4142. Time: 20217.4000 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #910: GFLOPs: 1034.7794. Time: 20464.2582 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #911: GFLOPs: 1044.4536. Time: 20274.7082 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #912: GFLOPs: 1134.2374. Time: 18669.8057 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #913: GFLOPs: 1048.6076. Time: 20194.3916 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #914: GFLOPs: 1052.3714. Time: 20122.1668 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #915: GFLOPs: 1013.9832. Time: 20883.9666 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #916: GFLOPs: 966.2483. Time: 21915.6834 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #917: GFLOPs: 1046.3485. Time: 20237.9918 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #918: GFLOPs: 1039.4065. Time: 20373.1584 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #919: GFLOPs: 1039.0184. Time: 20380.7668 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #920: GFLOPs: 1158.8855. Time: 18272.7222 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #921: GFLOPs: 1068.5494. Time: 19817.5138 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #922: GFLOPs: 983.6412. Time: 21528.1668 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #923: GFLOPs: 1085.1970. Time: 19513.5000 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #924: GFLOPs: 1042.2299. Time: 20317.9666 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #925: GFLOPs: 1107.4324. Time: 19121.7015 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #926: GFLOPs: 1161.6133. Time: 18229.8125 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #927: GFLOPs: 945.3385. Time: 22400.4334 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #928: GFLOPs: 945.2270. Time: 22403.0750 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #929: GFLOPs: 944.8812. Time: 22411.2750 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #930: GFLOPs: 1035.7870. Time: 20444.3500 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #931: GFLOPs: 1044.4274. Time: 20275.2166 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #932: GFLOPs: 1023.1950. Time: 20695.9500 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #933: GFLOPs: 1168.8178. Time: 18117.4443 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #934: GFLOPs: 1047.8401. Time: 20209.1834 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #935: GFLOPs: 1130.6308. Time: 18729.3610 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #936: GFLOPs: 1036.8317. Time: 20423.7500 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #937: GFLOPs: 1014.9954. Time: 20863.1416 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #938: GFLOPs: 941.1984. Time: 22498.9668 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #939: GFLOPs: 1155.3544. Time: 18328.5693 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #940: GFLOPs: 1019.5393. Time: 20770.1582 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #941: GFLOPs: 1095.4000. Time: 19331.7432 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #942: GFLOPs: 1091.4897. Time: 19401.0000 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #943: GFLOPs: 1027.8103. Time: 20603.0166 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #944: GFLOPs: 1034.8084. Time: 20463.6834 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #945: GFLOPs: 1045.8855. Time: 20246.9500 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #946: GFLOPs: 1099.4225. Time: 19261.0138 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #947: GFLOPs: 1146.1455. Time: 18475.8333 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #948: GFLOPs: 1099.7334. Time: 19255.5695 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #949: GFLOPs: 1036.0687. Time: 20438.7916 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #950: GFLOPs: 1068.6996. Time: 19814.7292 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #951: GFLOPs: 1023.5218. Time: 20689.3418 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #952: GFLOPs: 1022.0604. Time: 20718.9250 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #953: GFLOPs: 900.4550. Time: 23516.9918 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #954: GFLOPs: 1001.8459. Time: 21136.9750 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #955: GFLOPs: 1035.9133. Time: 20441.8584 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #956: GFLOPs: 965.3538. Time: 21935.9918 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #957: GFLOPs: 1113.3397. Time: 19020.2430 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #958: GFLOPs: 20.1783. Time: 1049443.5557 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #959: GFLOPs: 25.7979. Time: 820842.3750 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #960: GFLOPs: 35.9037. Time: 589800.2637 us. Best GFLOPs: 1169.9569
2023-05-18 18:55:36 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 18:55:36 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 18:55:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 406 failure(s)
2023-05-18 18:55:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 813 failure(s)
2023-05-18 18:55:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1221 failure(s)
2023-05-18 18:55:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 1625 failure(s)
2023-05-18 18:55:44 [INFO] [evolutionary_search.cc:723] Sampled 15 candidate(s)
2023-05-18 18:55:48 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 136 failure(s)
2023-05-18 18:55:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 107 failure(s)
2023-05-18 18:56:01 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 111 failure(s)
2023-05-18 18:56:07 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f601e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f60788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f62408)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f61ae8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f63a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x600001492798)]: 118 failure(s)
2023-05-18 18:56:10 [INFO] [evolutionary_search.cc:649] Scores of the best 40 candidates:
[1 : 16]:	0.9516  0.9387  0.9252  0.9180  0.9178  0.9151  0.9120  0.9110  0.9106  0.9105  0.9069  0.9066  0.9058  0.9036  0.9010  0.8996
[17 : 32]:	0.8994  0.8984  0.8978  0.8968  0.8966  0.8949  0.8939  0.8939  0.8939  0.8938  0.8935  0.8929  0.8925  0.8920  0.8897  0.8886
[33 : 40]:	0.8871  0.8871  0.8871  0.8871  0.8865  0.8830  0.8828  0.8772
2023-05-18 18:56:10 [INFO] [evolutionary_search.cc:727] Got 40 candidate(s) with evolutionary search
2023-05-18 18:56:10 [INFO] [evolutionary_search.cc:730] Sending 40 candidates(s) for measurement
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #961: GFLOPs: 1163.2187. Time: 18204.6528 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #962: GFLOPs: 1042.1141. Time: 20320.2250 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #963: GFLOPs: 1050.1954. Time: 20163.8584 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #964: GFLOPs: 1069.8353. Time: 19793.6945 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #965: GFLOPs: 1019.1897. Time: 20777.2834 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #966: GFLOPs: 1153.6226. Time: 18356.0833 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #967: GFLOPs: 1046.7916. Time: 20229.4250 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #968: GFLOPs: 1034.7098. Time: 20465.6334 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #969: GFLOPs: 1081.7811. Time: 19575.1180 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #970: GFLOPs: 1025.0354. Time: 20658.7918 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #971: GFLOPs: 975.0019. Time: 21718.9250 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #972: GFLOPs: 1042.5138. Time: 20312.4334 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #973: GFLOPs: 1045.6346. Time: 20251.8084 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #974: GFLOPs: 1113.2454. Time: 19021.8542 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #975: GFLOPs: 1009.8842. Time: 20968.7332 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #976: GFLOPs: 1047.6314. Time: 20213.2084 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #977: GFLOPs: 1166.2046. Time: 18158.0417 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #978: GFLOPs: 1042.8086. Time: 20306.6918 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #979: GFLOPs: 1107.2901. Time: 19124.1597 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #980: GFLOPs: 945.6590. Time: 22392.8418 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #981: GFLOPs: 1018.9432. Time: 20782.3084 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #982: GFLOPs: 1105.1431. Time: 19161.3125 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #983: GFLOPs: 1107.5479. Time: 19119.7083 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #984: GFLOPs: 941.0838. Time: 22501.7082 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #985: GFLOPs: 1009.5889. Time: 20974.8666 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #986: GFLOPs: 1086.6557. Time: 19487.3055 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #987: GFLOPs: 945.1687. Time: 22404.4584 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #988: GFLOPs: 1086.0454. Time: 19498.2568 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #989: GFLOPs: 1011.2603. Time: 20940.2000 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #990: GFLOPs: 1096.9692. Time: 19304.0903 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #991: GFLOPs: 1046.7321. Time: 20230.5750 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #992: GFLOPs: 1043.8126. Time: 20287.1584 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #993: GFLOPs: 1099.2632. Time: 19263.8055 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #994: GFLOPs: 1099.3302. Time: 19262.6318 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #995: GFLOPs: 1095.4744. Time: 19330.4305 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #996: GFLOPs: 1078.6452. Time: 19632.0277 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #997: GFLOPs: 1011.7136. Time: 20930.8166 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #998: GFLOPs: 1057.4663. Time: 20025.2168 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #999: GFLOPs: 16.6611. Time: 1270985.9583 us. Best GFLOPs: 1169.9569
2023-05-18 18:57:08 [INFO] [task_scheduler.cc:131] [Task #10: fused_conv2d6_add_add2] Trial #1000: GFLOPs: 22.1483. Time: 956098.6250 us. Best GFLOPs: 1169.9569
