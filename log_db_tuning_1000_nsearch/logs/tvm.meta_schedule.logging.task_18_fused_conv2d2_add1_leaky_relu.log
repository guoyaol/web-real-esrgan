2023-05-18 11:57:31 [INFO] [task_scheduler.cc:160] Initializing Task #18: "fused_conv2d2_add1_leaky_relu"
2023-05-18 11:57:31 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv7: T.Buffer((T.int64(1), T.int64(96), T.int64(640), T.int64(448)), "float32"), self_rrdb_body_0_rdb1_conv2_weight: T.Buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), "float32"), lv9: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(642), T.int64(450)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(96), T.int64(642), T.int64(450)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv7[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(641) and T.int64(1) <= v_i3 and v_i3 < T.int64(449), lv7[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(32), T.int64(640), T.int64(448), T.int64(96), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_body_0_rdb1_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_body_0_rdb1_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(640), T.int64(448)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv9[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv9[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(32), T.int64(640), T.int64(448)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_add_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(var_compute_intermediate[v_i0, v_i1, v_i2, v_i3])
                var_compute_intermediate[v_i0, v_i1, v_i2, v_i3] = T.Select(T.float32(0) < var_T_add_intermediate[v_i0, v_i1, v_i2, v_i3], var_T_add_intermediate[v_i0, v_i1, v_i2, v_i3], var_T_add_intermediate[v_i0, v_i1, v_i2, v_i3] * T.float32(0.20000000000000001))
2023-05-18 11:57:31 [INFO] [task_scheduler.cc:164] Total 1 design space(s) generated
2023-05-18 11:57:31 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv7: T.Buffer((T.int64(1), T.int64(96), T.int64(640), T.int64(448)), "float32"), self_rrdb_body_0_rdb1_conv2_weight: T.Buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), "float32"), lv9: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 16})
            var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), scope="local")
            pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(642), T.int64(450)), scope="shared")
            self_rrdb_body_0_rdb1_conv2_weight_shared = T.alloc_buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), scope="shared")
            for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x"):
                for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                    for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(448), thread="threadIdx.x"):
                        for rc_0, ry_0, rx_0 in T.grid(T.int64(1), T.int64(1), T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(6924288)):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(96), ax0_ax1_ax2_ax3_fused // T.int64(72128))
                                    v2 = T.axis.spatial(T.int64(642), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) // T.int64(2) * T.int64(320) + ax0_ax1_ax2_ax3_fused % T.int64(72128) // T.int64(224))
                                    v3 = T.axis.spatial(T.int64(450), rx_0 + nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(224) + ax0_ax1_ax2_ax3_fused % T.int64(224))
                                    T.reads(lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(4608)):
                                with T.block("self_rrdb_body_0_rdb1_conv2.weight_shared"):
                                    v0 = T.axis.spatial(T.int64(32), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(16) + ax0_ax1_ax2_ax3_fused // T.int64(288))
                                    v1 = T.axis.spatial(T.int64(96), ax0_ax1_ax2_ax3_fused % T.int64(288) // T.int64(3))
                                    v2 = T.axis.spatial(T.int64(3), ax0_ax1_ax2_ax3_fused % T.int64(3))
                                    v3 = T.axis.spatial(T.int64(3), rx_0)
                                    T.reads(self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3])
                                    T.writes(self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                    self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3] = self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3]
                            for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(40), T.int64(1)):
                                with T.block("conv2d_nchw"):
                                    v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                    v_ff = T.axis.spatial(T.int64(32), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(16) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(8) + ff_3 + ff_4)
                                    v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) // T.int64(2) * T.int64(320) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(56) * T.int64(40) + yy_3 * T.int64(40) + yy_4)
                                    v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(224) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(56) * T.int64(4) + xx_3 + xx_4)
                                    v_rc = T.axis.reduce(T.int64(96), rc_0 * T.int64(96) + rc_1 * T.int64(3) + rc_2)
                                    v_ry = T.axis.reduce(T.int64(3), ry_0 * T.int64(3) + ry_1 * T.int64(3) + ry_2)
                                    v_rx = T.axis.reduce(T.int64(3), rx_0 + rx_1 + rx_2)
                                    T.reads(pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                    T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                                    var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(40), T.int64(4)):
                            with T.block("var_conv2d_nchw_intermediate_local"):
                                v0 = T.axis.spatial(T.int64(1), ax0)
                                v1 = T.axis.spatial(T.int64(32), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(16) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(8) + ax1)
                                v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) // T.int64(2) * T.int64(320) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(56) * T.int64(40) + ax2)
                                v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(224) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(56) * T.int64(4) + ax3)
                                T.reads(var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv9[v0, v1, T.int64(0), T.int64(0)])
                                T.writes(var_compute_intermediate[v0, v1, v2, v3])
                                var_compute_intermediate[v0, v1, v2, v3] = T.Select(T.float32(0) < var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)]) * T.float32(0.20000000000000001))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="compute", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 2, 1, 8, 1])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[2, 1, 8, 1, 40])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[2, 1, 56, 4, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[1, 32, 3])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
2023-05-18 12:03:56 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 12:03:56 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2023-05-18 12:03:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 511 failure(s)
2023-05-18 12:04:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1020 failure(s)
2023-05-18 12:04:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1529 failure(s)
2023-05-18 12:04:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 2035 failure(s)
2023-05-18 12:04:04 [INFO] [evolutionary_search.cc:723] Sampled 13 candidate(s)
2023-05-18 12:04:09 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 157 failure(s)
2023-05-18 12:04:13 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 118 failure(s)
2023-05-18 12:04:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 86 failure(s)
2023-05-18 12:04:20 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 98 failure(s)
2023-05-18 12:04:21 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9976  0.9976  0.9961  0.9948  0.9941  0.9936  0.9930  0.9927  0.9917  0.9895  0.9895  0.9886  0.9879  0.9868  0.9864  0.9855
[17 : 32]:	0.9854  0.9852  0.9851  0.9845  0.9840  0.9836  0.9816  0.9809  0.9804  0.9801  0.9780  0.9775  0.9770  0.9766  0.9756  0.9753
[33 : 48]:	0.9753  0.9735  0.9728  0.9719  0.9719  0.9713  0.9706  0.9703  0.9693  0.9684  0.9671  0.9669  0.9664  0.9662  0.9661  0.9659
[49 : 64]:	0.9657  0.9657  0.9631  0.9628  0.9593  0.9590  0.9589  0.9578  0.9573  0.9550  0.9547  0.9544  0.9530  0.9529  0.9528  0.9516
2023-05-18 12:04:21 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 12:04:21 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #1: GFLOPs: 38.5390. Time: 411863.6943 us. Best GFLOPs: 38.5390
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #2: GFLOPs: 21.0239. Time: 754990.5140 us. Best GFLOPs: 38.5390
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #3: GFLOPs: 7.7542. Time: 2046992.7777 us. Best GFLOPs: 38.5390
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:121] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #4: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x00000001132ae993
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:130
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 130
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[13:16:27] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (state != nil) is false: cannot get state: for function main_kernel0Compute function exceeds available temporary registers


# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv7: T.Buffer((T.int64(1), T.int64(96), T.int64(640), T.int64(448)), "float32"), self_rrdb_body_0_rdb1_conv2_weight: T.Buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), "float32"), lv9: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_body_0_rdb1_conv2_weight_shared = T.alloc_buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(20), T.int64(14)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(32), nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(4) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + yy_3_init * T.int64(20) + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + xx_3_init * T.int64(14) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(96), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(160)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(96), rc_0)
                                    v2 = T.axis.spatial(T.int64(642), ry_0 + nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("self_rrdb_body_0_rdb1_conv2.weight_shared"):
                                    v0 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(3))
                                    v1, v2 = T.axis.remap("SS", [rc_0, ry_0])
                                    v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(3))
                                    T.reads(self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3])
                                    T.writes(self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3])
                                    self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3] = self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(20), T.int64(14)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(32), nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(4) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + yy_3 * T.int64(20) + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + xx_3 * T.int64(14) + xx_4)
                                v_rc = T.axis.reduce(T.int64(96), rc_0 + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 * T.int64(3) + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(20), T.int64(14)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(32), nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(4) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + ax3)
                            T.reads(var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv9[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_compute_intermediate[v0, v1, v2, v3])
                            var_compute_intermediate[v0, v1, v2, v3] = T.Select(T.float32(0) < var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)]) * T.float32(0.20000000000000001))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="compute", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 1, 8, 2, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[2, 4, 4, 1, 20])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[32, 1, 1, 1, 14])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[96, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118 = sch.split(loop=l116, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b119 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b119, ann_key="meta_schedule.unroll_explicit")
b120, b121, b122, b123 = sch.get_child_blocks(b119)
l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b120)
l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b121)
l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l140, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l140, ann_key="pragma_unroll_explicit", ann_val=1)
l160, l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b123)
b167 = sch.get_block(name="conv2d_nchw", func_name="main")
l168, l169, l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b167)
b188 = sch.decompose_reduction(block=b167, loop=l171)
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:121] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #5: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x0000000101bd7d63
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:130
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 130
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[13:16:27] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (state != nil) is false: cannot get state: for function main_kernel0Compute function exceeds available temporary registers


# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv7: T.Buffer((T.int64(1), T.int64(96), T.int64(640), T.int64(448)), "float32"), self_rrdb_body_0_rdb1_conv2_weight: T.Buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), "float32"), lv9: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_body_0_rdb1_conv2_weight_shared = T.alloc_buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(56), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(160), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(80) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_1_ff_1_yy_1_xx_1_fused % T.int64(80) // T.int64(2) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(4) + yy_3_init + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(4) + xx_3_init * T.int64(4) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(96), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(50)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v1 = T.axis.spatial(T.int64(96), rc_0)
                                        v2 = T.axis.spatial(T.int64(642), ry_0 + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(10))
                                        v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(10))
                                        T.reads(lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(3)):
                                    with T.block("self_rrdb_body_0_rdb1_conv2.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) // T.int64(3))
                                        v1, v2 = T.axis.remap("SS", [rc_0, ry_0])
                                        v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        T.reads(self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3] = self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(80) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_1_ff_1_yy_1_xx_1_fused % T.int64(80) // T.int64(2) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(4) + yy_3 + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(4) + xx_3 * T.int64(4) + xx_4)
                                v_rc = T.axis.reduce(T.int64(96), rc_0 + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(4)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(80) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_1_ff_1_yy_1_xx_1_fused % T.int64(80) // T.int64(2) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(4) + ax3)
                            T.reads(var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv9[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_compute_intermediate[v0, v1, v2, v3])
                            var_compute_intermediate[v0, v1, v2, v3] = T.Select(T.float32(0) < var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)]) * T.float32(0.20000000000000001))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="compute", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 2, 8, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 40, 4, 4, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[56, 2, 1, 1, 4])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[96, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 32, 3], preserve_unit_iters=True)
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #6: GFLOPs: 29.3105. Time: 541540.8887 us. Best GFLOPs: 38.5390
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #7: GFLOPs: 142.1896. Time: 111631.4027 us. Best GFLOPs: 142.1896
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #8: GFLOPs: 465.5309. Time: 34096.1667 us. Best GFLOPs: 465.5309
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #9: GFLOPs: 107.9030. Time: 147102.6803 us. Best GFLOPs: 465.5309
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #10: GFLOPs: 6.9781. Time: 2274672.7083 us. Best GFLOPs: 465.5309
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #11: GFLOPs: 22.1848. Time: 715482.7083 us. Best GFLOPs: 465.5309
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #12: GFLOPs: 645.5695. Time: 24587.3125 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #13: GFLOPs: 439.9987. Time: 36074.6947 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #14: GFLOPs: 203.9572. Time: 77824.2640 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:121] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #15: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x00000001129ac323
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:130
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 130
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[13:16:51] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (state != nil) is false: cannot get state: for function main_kernel0Compute function exceeds available temporary registers


# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv7: T.Buffer((T.int64(1), T.int64(96), T.int64(640), T.int64(448)), "float32"), self_rrdb_body_0_rdb1_conv2_weight: T.Buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), "float32"), lv9: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_body_0_rdb1_conv2_weight_shared = T.alloc_buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(16), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(10), T.int64(7)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(8) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(8) // T.int64(2) * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + yy_3_init * T.int64(10) + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(7) + xx_3_init * T.int64(7) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(96), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(160)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(96), rc_0)
                                    v2 = T.axis.spatial(T.int64(642), ry_0 + nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("self_rrdb_body_0_rdb1_conv2.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(3))
                                        v1, v2 = T.axis.remap("SS", [rc_0, ry_0])
                                        v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(96))
                                        T.reads(self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3] = self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(10), T.int64(7)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(8) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(8) // T.int64(2) * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + yy_3 * T.int64(10) + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(7) + xx_3 * T.int64(7) + xx_4)
                                v_rc = T.axis.reduce(T.int64(96), rc_0 + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 * T.int64(3) + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(20), T.int64(7)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(8) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(8) // T.int64(2) * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(7) + ax3)
                            T.reads(var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv9[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_compute_intermediate[v0, v1, v2, v3])
                            var_compute_intermediate[v0, v1, v2, v3] = T.Select(T.float32(0) < var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)]) * T.float32(0.20000000000000001))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="compute", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 2, 8, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[2, 4, 4, 2, 10])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[32, 2, 1, 1, 7])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[96, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #16: GFLOPs: 6.4090. Time: 2476626.4723 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #17: GFLOPs: 202.5627. Time: 78360.0417 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:121] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #18: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x000000011294d913
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:130
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 130
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[13:17:05] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (state != nil) is false: cannot get state: for function main_kernel0Compute function exceeds available temporary registers


# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv7: T.Buffer((T.int64(1), T.int64(96), T.int64(640), T.int64(448)), "float32"), self_rrdb_body_0_rdb1_conv2_weight: T.Buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), "float32"), lv9: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_body_0_rdb1_conv2_weight_shared = T.alloc_buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(5), T.int64(14)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(32), nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(4) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + yy_3_init * T.int64(5) + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + xx_3_init * T.int64(14) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(96), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(160)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(96), rc_0)
                                    v2 = T.axis.spatial(T.int64(642), ry_0 + nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("self_rrdb_body_0_rdb1_conv2.weight_shared"):
                                    v0 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(3))
                                    v1, v2 = T.axis.remap("SS", [rc_0, ry_0])
                                    v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(3))
                                    T.reads(self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3])
                                    T.writes(self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3])
                                    self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3] = self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(5), T.int64(14)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(32), nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(4) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + yy_3 * T.int64(5) + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + xx_3 * T.int64(14) + xx_4)
                                v_rc = T.axis.reduce(T.int64(96), rc_0 + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 * T.int64(3) + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(20), T.int64(14)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(32), nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(4) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + ax3)
                            T.reads(var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv9[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_compute_intermediate[v0, v1, v2, v3])
                            var_compute_intermediate[v0, v1, v2, v3] = T.Select(T.float32(0) < var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)]) * T.float32(0.20000000000000001))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="compute", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 1, 8, 2, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[2, 4, 4, 4, 5])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[32, 1, 1, 1, 14])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[96, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118 = sch.split(loop=l116, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b119 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b119, ann_key="meta_schedule.unroll_explicit")
b120, b121, b122, b123 = sch.get_child_blocks(b119)
l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b120)
l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b121)
l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l140, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l140, ann_key="pragma_unroll_explicit", ann_val=1)
l160, l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b123)
b167 = sch.get_block(name="conv2d_nchw", func_name="main")
l168, l169, l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b167)
b188 = sch.decompose_reduction(block=b167, loop=l171)
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #19: GFLOPs: 57.1099. Time: 277934.6250 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #20: GFLOPs: 447.5109. Time: 35469.1250 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #21: GFLOPs: 13.8848. Time: 1143181.7360 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #22: GFLOPs: 87.3251. Time: 181766.9027 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:121] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #23: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x0000000112a24323
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:130
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 130
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[13:17:17] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (state != nil) is false: cannot get state: for function main_kernel0Compute function exceeds available temporary registers


# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv7: T.Buffer((T.int64(1), T.int64(96), T.int64(640), T.int64(448)), "float32"), self_rrdb_body_0_rdb1_conv2_weight: T.Buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), "float32"), lv9: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_body_0_rdb1_conv2_weight_shared = T.alloc_buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(56), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(40), T.int64(4)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(2) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(160) + yy_3_init * T.int64(40) + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(4) + xx_3_init * T.int64(4) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(96), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(50)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v1 = T.axis.spatial(T.int64(96), rc_0)
                                        v2 = T.axis.spatial(T.int64(642), ry_0 + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(10))
                                        v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(10))
                                        T.reads(lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("self_rrdb_body_0_rdb1_conv2.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(3))
                                        v1, v2 = T.axis.remap("SS", [rc_0, ry_0])
                                        v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(96))
                                        T.reads(self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3] = self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(40), T.int64(4)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(2) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(160) + yy_3 * T.int64(40) + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(4) + xx_3 * T.int64(4) + xx_4)
                                v_rc = T.axis.reduce(T.int64(96), rc_0 + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(160), T.int64(4)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(2) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(160) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(4) + ax3)
                            T.reads(var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv9[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_compute_intermediate[v0, v1, v2, v3])
                            var_compute_intermediate[v0, v1, v2, v3] = T.Select(T.float32(0) < var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)]) * T.float32(0.20000000000000001))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="compute", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 2, 8, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 4, 4, 40])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[56, 2, 1, 1, 4])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[96, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #24: GFLOPs: 39.8433. Time: 398381.4860 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #25: GFLOPs: 4.3240. Time: 3670828.8890 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:121] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #26: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x0000000106016753
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:130
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 130
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[13:17:39] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (state != nil) is false: cannot get state: for function main_kernel0Compute function exceeds available temporary registers


# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv7: T.Buffer((T.int64(1), T.int64(96), T.int64(640), T.int64(448)), "float32"), self_rrdb_body_0_rdb1_conv2_weight: T.Buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), "float32"), lv9: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_body_0_rdb1_conv2_weight_shared = T.alloc_buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(8), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(10), T.int64(14)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(4) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3_init + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(4) * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + yy_3_init * T.int64(10) + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + xx_3_init * T.int64(14) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(96), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(160)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(96), rc_0)
                                    v2 = T.axis.spatial(T.int64(642), ry_0 + nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("self_rrdb_body_0_rdb1_conv2.weight_shared"):
                                    v0 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(3))
                                    v1, v2 = T.axis.remap("SS", [rc_0, ry_0])
                                    v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(3))
                                    T.reads(self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3])
                                    T.writes(self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3])
                                    self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3] = self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(10), T.int64(14)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(4) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3 + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(4) * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + yy_3 * T.int64(10) + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + xx_3 * T.int64(14) + xx_4)
                                v_rc = T.axis.reduce(T.int64(96), rc_0 + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 * T.int64(3) + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(20), T.int64(14)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(4) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(4) * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + ax3)
                            T.reads(var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv9[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_compute_intermediate[v0, v1, v2, v3])
                            var_compute_intermediate[v0, v1, v2, v3] = T.Select(T.float32(0) < var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)]) * T.float32(0.20000000000000001))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="compute", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 2, 8, 2, 1])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[2, 4, 4, 2, 10])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[32, 1, 1, 1, 14])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[96, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118 = sch.split(loop=l116, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b119 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b119, ann_key="meta_schedule.unroll_explicit")
b120, b121, b122, b123 = sch.get_child_blocks(b119)
l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b120)
l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b121)
l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l140, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l140, ann_key="pragma_unroll_explicit", ann_val=1)
l160, l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b123)
b167 = sch.get_block(name="conv2d_nchw", func_name="main")
l168, l169, l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b167)
b188 = sch.decompose_reduction(block=b167, loop=l171)
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:121] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #27: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x0000000112978173
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:130
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 130
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[13:17:40] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (state != nil) is false: cannot get state: for function main_kernel0Compute function exceeds available temporary registers


# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv7: T.Buffer((T.int64(1), T.int64(96), T.int64(640), T.int64(448)), "float32"), self_rrdb_body_0_rdb1_conv2_weight: T.Buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), "float32"), lv9: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_body_0_rdb1_conv2_weight_shared = T.alloc_buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(56), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(40), T.int64(4)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(2) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(160) + yy_3_init * T.int64(40) + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(4) + xx_3_init * T.int64(4) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(96), T.int64(1), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(51)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v1 = T.axis.spatial(T.int64(96), rc_0)
                                        v2 = T.axis.spatial(T.int64(642), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(10))
                                        v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(10))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(6420))
                                        T.reads(lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(3)):
                                    with T.block("self_rrdb_body_0_rdb1_conv2.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) // T.int64(9))
                                        v1 = T.axis.spatial(T.int64(96), rc_0)
                                        v2 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) % T.int64(9) // T.int64(3))
                                        v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        T.reads(self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3] = self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(40), T.int64(4)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(2) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(160) + yy_3 * T.int64(40) + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(4) + xx_3 * T.int64(4) + xx_4)
                                v_rc = T.axis.reduce(T.int64(96), rc_0 + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 * T.int64(3) + ry_1 * T.int64(3) + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(160), T.int64(4)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(2) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(160) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(4) + ax3)
                            T.reads(var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv9[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_compute_intermediate[v0, v1, v2, v3])
                            var_compute_intermediate[v0, v1, v2, v3] = T.Select(T.float32(0) < var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)]) * T.float32(0.20000000000000001))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="compute", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 2, 8, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 4, 4, 40])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[56, 2, 1, 1, 4])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[96, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 32, 3], preserve_unit_iters=True)
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #28: GFLOPs: 96.1106. Time: 165151.6110 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:121] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #29: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x00000001169348d3
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:130
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 130
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[13:17:42] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (state != nil) is false: cannot get state: for function main_kernel0Compute function exceeds available temporary registers


# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv7: T.Buffer((T.int64(1), T.int64(96), T.int64(640), T.int64(448)), "float32"), self_rrdb_body_0_rdb1_conv2_weight: T.Buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), "float32"), lv9: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_body_0_rdb1_conv2_weight_shared = T.alloc_buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(56), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(40), T.int64(4)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(2) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(160) + yy_3_init * T.int64(40) + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(4) + xx_3_init * T.int64(4) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(96), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(100)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v1 = T.axis.spatial(T.int64(96), rc_0)
                                        v2 = T.axis.spatial(T.int64(642), ry_0 + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(10))
                                        v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(10))
                                        T.reads(lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("self_rrdb_body_0_rdb1_conv2.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(3))
                                        v1, v2 = T.axis.remap("SS", [rc_0, ry_0])
                                        v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(96))
                                        T.reads(self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3] = self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(40), T.int64(4)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(2) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(160) + yy_3 * T.int64(40) + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(4) + xx_3 * T.int64(4) + xx_4)
                                v_rc = T.axis.reduce(T.int64(96), rc_0 + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(160), T.int64(4)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(2) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(160) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused * T.int64(8) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(2) * T.int64(4) + ax3)
                            T.reads(var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv9[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_compute_intermediate[v0, v1, v2, v3])
                            var_compute_intermediate[v0, v1, v2, v3] = T.Select(T.float32(0) < var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)]) * T.float32(0.20000000000000001))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="compute", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 2, 8, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 4, 4, 40])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[56, 2, 1, 1, 4])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[96, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #30: GFLOPs: 86.9276. Time: 182598.1530 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #31: GFLOPs: 13.0428. Time: 1216979.2637 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #32: GFLOPs: 16.8146. Time: 943987.9027 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #33: GFLOPs: 29.2051. Time: 543495.5417 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #34: GFLOPs: 483.8441. Time: 32805.6457 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #35: GFLOPs: 266.7394. Time: 59506.8333 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #36: GFLOPs: 17.8426. Time: 889600.3473 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #37: GFLOPs: 136.7807. Time: 116045.7777 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #38: GFLOPs: 32.0611. Time: 495081.0693 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #39: GFLOPs: 11.2015. Time: 1417026.8750 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #40: GFLOPs: 68.7182. Time: 230984.1807 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #41: GFLOPs: 69.4826. Time: 228443.0833 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #42: GFLOPs: 41.6262. Time: 381318.1250 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #43: GFLOPs: 84.1769. Time: 188565.1110 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #44: GFLOPs: 17.7246. Time: 895526.0553 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #45: GFLOPs: 42.3604. Time: 374709.3193 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #46: GFLOPs: 17.6705. Time: 898266.8890 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #47: GFLOPs: 88.0574. Time: 180255.3890 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #48: GFLOPs: 6.1656. Time: 2574433.1807 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #49: GFLOPs: 189.5130. Time: 83755.8193 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #50: GFLOPs: 430.9548. Time: 36831.7500 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #51: GFLOPs: 36.9893. Time: 429119.3333 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #52: GFLOPs: 43.1336. Time: 367992.2500 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #53: GFLOPs: 527.3404. Time: 30099.7602 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #54: GFLOPs: 522.2781. Time: 30391.5102 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #55: GFLOPs: 89.5135. Time: 177323.1947 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #56: GFLOPs: 25.5347. Time: 621616.4443 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:121] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #57: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x0000000106704643
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:130
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 130
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[13:19:06] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (state != nil) is false: cannot get state: for function main_kernel0Compute function exceeds available temporary registers


# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv7: T.Buffer((T.int64(1), T.int64(96), T.int64(640), T.int64(448)), "float32"), self_rrdb_body_0_rdb1_conv2_weight: T.Buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), "float32"), lv9: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_body_0_rdb1_conv2_weight_shared = T.alloc_buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(112), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(10), T.int64(1)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(56) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(56) // T.int64(14) * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + yy_3_init * T.int64(10) + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(14) + xx_3_init + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(96), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(160)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(96), rc_0)
                                    v2 = T.axis.spatial(T.int64(642), ry_0 + nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(3)):
                                    with T.block("self_rrdb_body_0_rdb1_conv2.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) // T.int64(3))
                                        v1, v2 = T.axis.remap("SS", [rc_0, ry_0])
                                        v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        T.reads(self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3] = self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(10), T.int64(1)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(56) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(56) // T.int64(14) * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + yy_3 * T.int64(10) + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(14) + xx_3 + xx_4)
                                v_rc = T.axis.reduce(T.int64(96), rc_0 + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 * T.int64(3) + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(20), T.int64(1)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(56) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(56) // T.int64(14) * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(14) + ax3)
                            T.reads(var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv9[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_compute_intermediate[v0, v1, v2, v3])
                            var_compute_intermediate[v0, v1, v2, v3] = T.Select(T.float32(0) < var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)]) * T.float32(0.20000000000000001))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="compute", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 2, 8, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[2, 4, 4, 2, 10])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[32, 14, 1, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[96, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 32, 3], preserve_unit_iters=True)
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #58: GFLOPs: 15.0348. Time: 1055741.5140 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #59: GFLOPs: 369.5053. Time: 42956.9443 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #60: GFLOPs: 540.4964. Time: 29367.1148 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #61: GFLOPs: 22.7546. Time: 697566.8057 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #62: GFLOPs: 108.4274. Time: 146391.1803 us. Best GFLOPs: 645.5695
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:121] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #63: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x0000000101e9e753
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:130
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 130
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[13:19:19] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (state != nil) is false: cannot get state: for function main_kernel0Compute function exceeds available temporary registers


# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv7: T.Buffer((T.int64(1), T.int64(96), T.int64(640), T.int64(448)), "float32"), self_rrdb_body_0_rdb1_conv2_weight: T.Buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), "float32"), lv9: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_body_0_rdb1_conv2_weight_shared = T.alloc_buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(8), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(10), T.int64(14)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(4) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(4) * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + yy_3_init * T.int64(10) + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + xx_3_init * T.int64(14) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(96), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(160)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(96), rc_0)
                                    v2 = T.axis.spatial(T.int64(642), ry_0 + nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("self_rrdb_body_0_rdb1_conv2.weight_shared"):
                                    v0 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(3))
                                    v1, v2 = T.axis.remap("SS", [rc_0, ry_0])
                                    v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(3))
                                    T.reads(self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3])
                                    T.writes(self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3])
                                    self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3] = self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(10), T.int64(14)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(4) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(4) * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + yy_3 * T.int64(10) + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + xx_3 * T.int64(14) + xx_4)
                                v_rc = T.axis.reduce(T.int64(96), rc_0 + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 * T.int64(3) + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(20), T.int64(14)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused // T.int64(4) * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(32) * T.int64(320) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(4) * T.int64(80) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(20) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(32) * T.int64(14) + ax3)
                            T.reads(var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv9[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_compute_intermediate[v0, v1, v2, v3])
                            var_compute_intermediate[v0, v1, v2, v3] = T.Select(T.float32(0) < var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)]) * T.float32(0.20000000000000001))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="compute", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 2, 8, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[2, 4, 4, 2, 10])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[32, 1, 1, 1, 14])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[96, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118 = sch.split(loop=l116, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b119 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b119, ann_key="meta_schedule.unroll_explicit")
b120, b121, b122, b123 = sch.get_child_blocks(b119)
l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b120)
l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b121)
l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l140, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l140, ann_key="pragma_unroll_explicit", ann_val=1)
l160, l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b123)
b167 = sch.get_block(name="conv2d_nchw", func_name="main")
l168, l169, l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b167)
b188 = sch.decompose_reduction(block=b167, loop=l171)
2023-05-18 13:19:21 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #64: GFLOPs: 283.2198. Time: 56044.1807 us. Best GFLOPs: 645.5695
2023-05-18 13:29:21 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 13:29:22 [INFO] [evolutionary_search.cc:715] Picked top 54 candidate(s) from database
2023-05-18 13:29:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 454 failure(s)
2023-05-18 13:29:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 911 failure(s)
2023-05-18 13:29:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1366 failure(s)
2023-05-18 13:29:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1823 failure(s)
2023-05-18 13:29:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 2273 failure(s)
2023-05-18 13:29:31 [INFO] [evolutionary_search.cc:723] Sampled 17 candidate(s)
2023-05-18 13:29:36 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 82 failure(s)
2023-05-18 13:29:42 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 84 failure(s)
2023-05-18 13:29:47 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 81 failure(s)
2023-05-18 13:29:54 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 82 failure(s)
2023-05-18 13:29:56 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0319  0.9774  0.9757  0.9666  0.9648  0.9631  0.9524  0.9507  0.9290  0.9045  0.9017  0.8959  0.8943  0.8931  0.8913  0.8905
[17 : 32]:	0.8884  0.8819  0.8793  0.8793  0.8783  0.8761  0.8748  0.8687  0.8526  0.8517  0.8485  0.8478  0.8473  0.8460  0.8443  0.8429
[33 : 48]:	0.8412  0.8405  0.8400  0.8390  0.8360  0.8333  0.8321  0.8316  0.8302  0.8285  0.8267  0.8264  0.8261  0.8244  0.8239  0.8238
[49 : 64]:	0.8194  0.8194  0.8193  0.8190  0.8182  0.8176  0.8165  0.8147  0.8143  0.8126  0.8119  0.8117  0.8096  0.8094  0.8092  0.8083
2023-05-18 13:29:56 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 13:29:56 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #65: GFLOPs: 239.4018. Time: 66302.0000 us. Best GFLOPs: 645.5695
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #66: GFLOPs: 585.8277. Time: 27094.6875 us. Best GFLOPs: 645.5695
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #67: GFLOPs: 663.7602. Time: 23913.4834 us. Best GFLOPs: 663.7602
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #68: GFLOPs: 673.7028. Time: 23560.5666 us. Best GFLOPs: 673.7028
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #69: GFLOPs: 667.6775. Time: 23773.1834 us. Best GFLOPs: 673.7028
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #70: GFLOPs: 184.3669. Time: 86093.6667 us. Best GFLOPs: 673.7028
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #71: GFLOPs: 687.3426. Time: 23093.0250 us. Best GFLOPs: 687.3426
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #72: GFLOPs: 689.7804. Time: 23011.4082 us. Best GFLOPs: 689.7804
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #73: GFLOPs: 697.1116. Time: 22769.4084 us. Best GFLOPs: 697.1116
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #74: GFLOPs: 713.9437. Time: 22232.5916 us. Best GFLOPs: 713.9437
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #75: GFLOPs: 613.3650. Time: 25878.2605 us. Best GFLOPs: 713.9437
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #76: GFLOPs: 533.1808. Time: 29770.0520 us. Best GFLOPs: 713.9437
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #77: GFLOPs: 574.1416. Time: 27646.1770 us. Best GFLOPs: 713.9437
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #78: GFLOPs: 700.2019. Time: 22668.9168 us. Best GFLOPs: 713.9437
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #79: GFLOPs: 599.3920. Time: 26481.5312 us. Best GFLOPs: 713.9437
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #80: GFLOPs: 719.8751. Time: 22049.4082 us. Best GFLOPs: 719.8751
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #81: GFLOPs: 640.5285. Time: 24780.8168 us. Best GFLOPs: 719.8751
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #82: GFLOPs: 565.4927. Time: 28069.0103 us. Best GFLOPs: 719.8751
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #83: GFLOPs: 481.3899. Time: 32972.8957 us. Best GFLOPs: 719.8751
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #84: GFLOPs: 584.1313. Time: 27173.3750 us. Best GFLOPs: 719.8751
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #85: GFLOPs: 680.5502. Time: 23323.5084 us. Best GFLOPs: 719.8751
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #86: GFLOPs: 628.5744. Time: 25252.0938 us. Best GFLOPs: 719.8751
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #87: GFLOPs: 535.0094. Time: 29668.3023 us. Best GFLOPs: 719.8751
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #88: GFLOPs: 576.0842. Time: 27552.9480 us. Best GFLOPs: 719.8751
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #89: GFLOPs: 753.7085. Time: 21059.6250 us. Best GFLOPs: 753.7085
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #90: GFLOPs: 540.1538. Time: 29385.7395 us. Best GFLOPs: 753.7085
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #91: GFLOPs: 592.9384. Time: 26769.7605 us. Best GFLOPs: 753.7085
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #92: GFLOPs: 413.5460. Time: 38382.2360 us. Best GFLOPs: 753.7085
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #93: GFLOPs: 702.9431. Time: 22580.5166 us. Best GFLOPs: 753.7085
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #94: GFLOPs: 700.2617. Time: 22666.9834 us. Best GFLOPs: 753.7085
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #95: GFLOPs: 636.1915. Time: 24949.7500 us. Best GFLOPs: 753.7085
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #96: GFLOPs: 568.5531. Time: 27917.9165 us. Best GFLOPs: 753.7085
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #97: GFLOPs: 625.9929. Time: 25356.2290 us. Best GFLOPs: 753.7085
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #98: GFLOPs: 628.2898. Time: 25263.5312 us. Best GFLOPs: 753.7085
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #99: GFLOPs: 524.8303. Time: 30243.7188 us. Best GFLOPs: 753.7085
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #100: GFLOPs: 1004.4389. Time: 15802.6726 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #101: GFLOPs: 546.8016. Time: 29028.4793 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #102: GFLOPs: 677.0034. Time: 23445.7000 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #103: GFLOPs: 487.5414. Time: 32556.8648 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #104: GFLOPs: 181.8344. Time: 87292.7083 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #105: GFLOPs: 585.6890. Time: 27101.1040 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #106: GFLOPs: 623.5080. Time: 25457.2812 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #107: GFLOPs: 452.8381. Time: 35051.8613 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #108: GFLOPs: 337.8687. Time: 46979.2500 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #109: GFLOPs: 392.6528. Time: 40424.5697 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #110: GFLOPs: 438.6946. Time: 36181.9307 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #111: GFLOPs: 541.4609. Time: 29314.8020 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #112: GFLOPs: 467.8010. Time: 33930.7083 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #113: GFLOPs: 658.4679. Time: 24105.6834 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #114: GFLOPs: 530.4817. Time: 29921.5207 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #115: GFLOPs: 488.5374. Time: 32490.4898 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #116: GFLOPs: 384.3081. Time: 41302.3333 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #117: GFLOPs: 563.5658. Time: 28164.9792 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #118: GFLOPs: 393.4988. Time: 40337.6527 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #119: GFLOPs: 575.3849. Time: 27586.4375 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #120: GFLOPs: 408.6134. Time: 38845.5693 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #121: GFLOPs: 480.9309. Time: 33004.3648 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #122: GFLOPs: 832.5087. Time: 19066.2500 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #123: GFLOPs: 359.6144. Time: 44138.4443 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #124: GFLOPs: 761.9231. Time: 20832.5750 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #125: GFLOPs: 712.5986. Time: 22274.5582 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #126: GFLOPs: 258.6888. Time: 61358.7500 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #127: GFLOPs: 95.0501. Time: 166994.3193 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #128: GFLOPs: 32.3733. Time: 490306.5557 us. Best GFLOPs: 1004.4389
2023-05-18 13:32:25 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 13:32:25 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 13:32:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 407 failure(s)
2023-05-18 13:32:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 816 failure(s)
2023-05-18 13:32:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1224 failure(s)
2023-05-18 13:32:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1632 failure(s)
2023-05-18 13:32:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 2040 failure(s)
2023-05-18 13:32:34 [INFO] [evolutionary_search.cc:723] Sampled 10 candidate(s)
2023-05-18 13:32:38 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 88 failure(s)
2023-05-18 13:32:44 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 109 failure(s)
2023-05-18 13:32:50 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 87 failure(s)
2023-05-18 13:32:56 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 81 failure(s)
2023-05-18 13:32:59 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0302  1.0210  1.0069  0.9988  0.9669  0.9649  0.9630  0.9475  0.9435  0.9412  0.9411  0.9380  0.9366  0.9327  0.9309  0.9245
[17 : 32]:	0.9235  0.9197  0.9193  0.9182  0.9151  0.9106  0.9062  0.9040  0.9023  0.9021  0.9015  0.9008  0.8997  0.8995  0.8988  0.8987
[33 : 48]:	0.8952  0.8922  0.8917  0.8909  0.8908  0.8886  0.8884  0.8881  0.8872  0.8839  0.8804  0.8801  0.8775  0.8769  0.8765  0.8758
[49 : 64]:	0.8750  0.8736  0.8736  0.8732  0.8730  0.8723  0.8699  0.8686  0.8679  0.8672  0.8663  0.8632  0.8622  0.8622  0.8621  0.8616
2023-05-18 13:32:59 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 13:32:59 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #129: GFLOPs: 271.8285. Time: 58392.7777 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #130: GFLOPs: 255.3437. Time: 62162.5693 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #131: GFLOPs: 252.7649. Time: 62796.7637 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #132: GFLOPs: 667.1756. Time: 23791.0666 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #133: GFLOPs: 634.4140. Time: 25019.6562 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #134: GFLOPs: 176.1896. Time: 90089.4443 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #135: GFLOPs: 553.6607. Time: 28668.8543 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #136: GFLOPs: 256.8841. Time: 61789.8193 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #137: GFLOPs: 653.6635. Time: 24282.8582 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #138: GFLOPs: 586.1989. Time: 27077.5312 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #139: GFLOPs: 707.2716. Time: 22442.3250 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #140: GFLOPs: 178.9456. Time: 88701.9443 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #141: GFLOPs: 257.3699. Time: 61673.1667 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #142: GFLOPs: 256.0594. Time: 61988.8193 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #143: GFLOPs: 253.1631. Time: 62698.0000 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #144: GFLOPs: 608.5739. Time: 26081.9898 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #145: GFLOPs: 88.8411. Time: 178665.3193 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #146: GFLOPs: 301.0234. Time: 52729.5140 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #147: GFLOPs: 287.2321. Time: 55261.2917 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #148: GFLOPs: 536.3536. Time: 29593.9478 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #149: GFLOPs: 531.8285. Time: 29845.7500 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #150: GFLOPs: 645.5593. Time: 24587.7000 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #151: GFLOPs: 638.1411. Time: 24873.5250 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #152: GFLOPs: 88.7330. Time: 178883.0280 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #153: GFLOPs: 79.2410. Time: 200310.7500 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #154: GFLOPs: 506.3075. Time: 31350.1563 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #155: GFLOPs: 375.9254. Time: 42223.3193 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #156: GFLOPs: 702.2261. Time: 22603.5750 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #157: GFLOPs: 604.3170. Time: 26265.7188 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #158: GFLOPs: 468.8317. Time: 33856.1110 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #159: GFLOPs: 639.4855. Time: 24821.2334 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #160: GFLOPs: 236.3055. Time: 67170.7640 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #161: GFLOPs: 567.2354. Time: 27982.7707 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #162: GFLOPs: 724.1475. Time: 21919.3166 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #163: GFLOPs: 674.0978. Time: 23546.7584 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #164: GFLOPs: 536.9203. Time: 29562.7082 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #165: GFLOPs: 558.5757. Time: 28416.5938 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #166: GFLOPs: 601.9830. Time: 26367.5523 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #167: GFLOPs: 668.7943. Time: 23733.4832 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #168: GFLOPs: 430.9004. Time: 36836.4030 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #169: GFLOPs: 683.7270. Time: 23215.1416 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #170: GFLOPs: 620.2793. Time: 25589.7918 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #171: GFLOPs: 679.4917. Time: 23359.8416 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #172: GFLOPs: 716.2730. Time: 22160.2916 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #173: GFLOPs: 537.9851. Time: 29504.1980 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #174: GFLOPs: 633.7438. Time: 25046.1148 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #175: GFLOPs: 681.6579. Time: 23285.6082 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #176: GFLOPs: 708.2794. Time: 22410.3916 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #177: GFLOPs: 539.7077. Time: 29410.0312 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #178: GFLOPs: 258.5030. Time: 61402.8333 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #179: GFLOPs: 674.5278. Time: 23531.7500 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #180: GFLOPs: 627.2902. Time: 25303.7915 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #181: GFLOPs: 539.3823. Time: 29427.7707 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #182: GFLOPs: 471.8853. Time: 33637.0280 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #183: GFLOPs: 704.3588. Time: 22535.1334 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #184: GFLOPs: 707.5858. Time: 22432.3584 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #185: GFLOPs: 669.2653. Time: 23716.7834 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #186: GFLOPs: 629.5503. Time: 25212.9480 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #187: GFLOPs: 631.8832. Time: 25119.8645 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #188: GFLOPs: 459.8869. Time: 34514.6113 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #189: GFLOPs: 713.4656. Time: 22247.4916 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #190: GFLOPs: 7.2994. Time: 2174530.0973 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #191: GFLOPs: 148.9712. Time: 106549.6110 us. Best GFLOPs: 1004.4389
2023-05-18 13:35:55 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #192: GFLOPs: 350.2616. Time: 45317.0417 us. Best GFLOPs: 1004.4389
2023-05-18 14:16:03 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 14:16:04 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 14:16:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 406 failure(s)
2023-05-18 14:16:07 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 813 failure(s)
2023-05-18 14:16:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1219 failure(s)
2023-05-18 14:16:09 [INFO] [evolutionary_search.cc:723] Sampled 11 candidate(s)
2023-05-18 14:16:13 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 84 failure(s)
2023-05-18 14:16:19 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 93 failure(s)
2023-05-18 14:16:25 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 81 failure(s)
2023-05-18 14:16:31 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 93 failure(s)
2023-05-18 14:16:33 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9789  0.8426  0.8330  0.8290  0.8263  0.8049  0.7974  0.7855  0.7843  0.7839  0.7838  0.7794  0.7788  0.7783  0.7643  0.7619
[17 : 32]:	0.7592  0.7585  0.7564  0.7563  0.7526  0.7492  0.7486  0.7474  0.7457  0.7428  0.7423  0.7417  0.7408  0.7398  0.7379  0.7356
[33 : 48]:	0.7346  0.7344  0.7329  0.7323  0.7313  0.7303  0.7281  0.7250  0.7231  0.7217  0.7217  0.7211  0.7187  0.7169  0.7167  0.7156
[49 : 64]:	0.7152  0.7144  0.7140  0.7137  0.7136  0.7112  0.7110  0.7101  0.7099  0.7089  0.7086  0.7083  0.7078  0.7034  0.7031  0.7028
2023-05-18 14:16:33 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 14:16:33 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #193: GFLOPs: 574.5776. Time: 27625.1978 us. Best GFLOPs: 1004.4389
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #194: GFLOPs: 766.6232. Time: 20704.8500 us. Best GFLOPs: 1004.4389
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #195: GFLOPs: 831.3529. Time: 19092.7568 us. Best GFLOPs: 1004.4389
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #196: GFLOPs: 960.9205. Time: 16518.3472 us. Best GFLOPs: 1004.4389
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #197: GFLOPs: 998.5843. Time: 15895.3214 us. Best GFLOPs: 1004.4389
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #198: GFLOPs: 917.8020. Time: 17294.3820 us. Best GFLOPs: 1004.4389
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #199: GFLOPs: 749.4951. Time: 21178.0168 us. Best GFLOPs: 1004.4389
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #200: GFLOPs: 1030.2597. Time: 15406.6190 us. Best GFLOPs: 1030.2597
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #201: GFLOPs: 557.3089. Time: 28481.1875 us. Best GFLOPs: 1030.2597
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #202: GFLOPs: 844.0548. Time: 18805.4375 us. Best GFLOPs: 1030.2597
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #203: GFLOPs: 1116.2300. Time: 14220.0260 us. Best GFLOPs: 1116.2300
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #204: GFLOPs: 669.1263. Time: 23721.7084 us. Best GFLOPs: 1116.2300
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #205: GFLOPs: 759.4611. Time: 20900.1084 us. Best GFLOPs: 1116.2300
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #206: GFLOPs: 826.0523. Time: 19215.2708 us. Best GFLOPs: 1116.2300
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #207: GFLOPs: 904.8477. Time: 17541.9792 us. Best GFLOPs: 1116.2300
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #208: GFLOPs: 751.7521. Time: 21114.4334 us. Best GFLOPs: 1116.2300
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #209: GFLOPs: 901.4717. Time: 17607.6735 us. Best GFLOPs: 1116.2300
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #210: GFLOPs: 559.4802. Time: 28370.6562 us. Best GFLOPs: 1116.2300
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #211: GFLOPs: 722.3389. Time: 21974.2000 us. Best GFLOPs: 1116.2300
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #212: GFLOPs: 721.7920. Time: 21990.8500 us. Best GFLOPs: 1116.2300
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #213: GFLOPs: 386.9301. Time: 41022.4443 us. Best GFLOPs: 1116.2300
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #214: GFLOPs: 635.4130. Time: 24980.3195 us. Best GFLOPs: 1116.2300
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #215: GFLOPs: 1112.6689. Time: 14265.5364 us. Best GFLOPs: 1116.2300
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #216: GFLOPs: 1145.0990. Time: 13861.5261 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #217: GFLOPs: 389.4240. Time: 40759.7360 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #218: GFLOPs: 877.0072. Time: 18098.8472 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #219: GFLOPs: 740.5713. Time: 21433.2082 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #220: GFLOPs: 1105.5649. Time: 14357.2024 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #221: GFLOPs: 705.7621. Time: 22490.3250 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #222: GFLOPs: 488.4832. Time: 32494.0937 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #223: GFLOPs: 697.6281. Time: 22752.5500 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #224: GFLOPs: 606.1036. Time: 26188.2918 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #225: GFLOPs: 889.5655. Time: 17843.3403 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #226: GFLOPs: 388.2761. Time: 40880.2360 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #227: GFLOPs: 711.8423. Time: 22298.2250 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #228: GFLOPs: 1100.7308. Time: 14420.2559 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #229: GFLOPs: 871.1616. Time: 18220.2917 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #230: GFLOPs: 799.3821. Time: 19856.3610 us. Best GFLOPs: 1145.0990
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #231: GFLOPs: 1323.2133. Time: 11995.6620 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #232: GFLOPs: 878.0890. Time: 18076.5485 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #233: GFLOPs: 608.7804. Time: 26073.1457 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #234: GFLOPs: 633.2816. Time: 25064.3916 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #235: GFLOPs: 771.9151. Time: 20562.9082 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #236: GFLOPs: 753.2182. Time: 21073.3334 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #237: GFLOPs: 942.0121. Time: 16849.9097 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #238: GFLOPs: 617.5989. Time: 25700.8540 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #239: GFLOPs: 723.1139. Time: 21950.6500 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #240: GFLOPs: 1078.2271. Time: 14721.2203 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #241: GFLOPs: 806.6308. Time: 19677.9235 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #242: GFLOPs: 736.1390. Time: 21562.2584 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #243: GFLOPs: 863.0382. Time: 18391.7917 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #244: GFLOPs: 754.7494. Time: 21030.5834 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #245: GFLOPs: 803.1511. Time: 19763.1805 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #246: GFLOPs: 611.6941. Time: 25948.9477 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #247: GFLOPs: 639.7903. Time: 24809.4084 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #248: GFLOPs: 668.6861. Time: 23737.3250 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #249: GFLOPs: 711.6479. Time: 22304.3166 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #250: GFLOPs: 213.4081. Time: 74377.7780 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #251: GFLOPs: 741.1347. Time: 21416.9166 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #252: GFLOPs: 700.4610. Time: 22660.5334 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #253: GFLOPs: 387.0950. Time: 41004.9720 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #254: GFLOPs: 160.2763. Time: 99034.0833 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #255: GFLOPs: 26.9316. Time: 589374.4583 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #256: GFLOPs: 25.7450. Time: 616540.6947 us. Best GFLOPs: 1323.2133
2023-05-18 14:18:03 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 14:18:04 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 14:18:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 405 failure(s)
2023-05-18 14:18:07 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 812 failure(s)
2023-05-18 14:18:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1217 failure(s)
2023-05-18 14:18:09 [INFO] [evolutionary_search.cc:723] Sampled 13 candidate(s)
2023-05-18 14:18:13 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 93 failure(s)
2023-05-18 14:18:19 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 84 failure(s)
2023-05-18 14:18:25 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 90 failure(s)
2023-05-18 14:18:32 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 92 failure(s)
2023-05-18 14:18:34 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9757  0.9725  0.9233  0.8630  0.8400  0.8289  0.8283  0.8258  0.8257  0.8169  0.8150  0.8136  0.8123  0.8123  0.8060  0.8033
[17 : 32]:	0.8024  0.7955  0.7908  0.7905  0.7863  0.7842  0.7799  0.7795  0.7786  0.7780  0.7772  0.7768  0.7751  0.7751  0.7749  0.7746
[33 : 48]:	0.7708  0.7704  0.7672  0.7671  0.7667  0.7660  0.7654  0.7648  0.7646  0.7643  0.7641  0.7632  0.7632  0.7597  0.7590  0.7584
[49 : 64]:	0.7576  0.7572  0.7562  0.7560  0.7550  0.7536  0.7529  0.7514  0.7491  0.7490  0.7490  0.7479  0.7443  0.7423  0.7422  0.7419
2023-05-18 14:18:34 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 14:18:34 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #257: GFLOPs: 1085.5277. Time: 14622.2143 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #258: GFLOPs: 365.5970. Time: 43416.1667 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #259: GFLOPs: 733.2386. Time: 21647.5500 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #260: GFLOPs: 984.6735. Time: 16119.8810 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #261: GFLOPs: 900.0185. Time: 17636.1042 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #262: GFLOPs: 745.1526. Time: 21301.4332 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #263: GFLOPs: 985.4449. Time: 16107.2619 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #264: GFLOPs: 463.4028. Time: 34252.7500 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #265: GFLOPs: 1102.1096. Time: 14402.2143 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #266: GFLOPs: 1116.9666. Time: 14210.6477 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #267: GFLOPs: 1116.1470. Time: 14221.0832 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #268: GFLOPs: 829.3503. Time: 19138.8610 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #269: GFLOPs: 841.3062. Time: 18866.8750 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #270: GFLOPs: 845.3240. Time: 18777.2013 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #271: GFLOPs: 824.1235. Time: 19260.2430 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #272: GFLOPs: 1148.7051. Time: 13818.0104 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #273: GFLOPs: 945.1869. Time: 16793.3125 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #274: GFLOPs: 809.4419. Time: 19609.5833 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #275: GFLOPs: 665.6542. Time: 23845.4416 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #276: GFLOPs: 459.1628. Time: 34569.0417 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #277: GFLOPs: 1167.8906. Time: 13591.0156 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #278: GFLOPs: 1167.2514. Time: 13598.4584 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #279: GFLOPs: 830.5807. Time: 19110.5070 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #280: GFLOPs: 940.8028. Time: 16871.5695 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #281: GFLOPs: 835.9676. Time: 18987.3612 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #282: GFLOPs: 816.8412. Time: 19431.9513 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #283: GFLOPs: 1176.4552. Time: 13492.0729 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #284: GFLOPs: 550.4036. Time: 28838.5102 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #285: GFLOPs: 1216.5119. Time: 13047.8125 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #286: GFLOPs: 1080.5585. Time: 14689.4584 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #287: GFLOPs: 782.5573. Time: 20283.2668 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #288: GFLOPs: 989.5291. Time: 16040.7799 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #289: GFLOPs: 823.4899. Time: 19275.0625 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #290: GFLOPs: 645.6948. Time: 24582.5416 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #291: GFLOPs: 897.1232. Time: 17693.0208 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #292: GFLOPs: 934.4255. Time: 16986.7153 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #293: GFLOPs: 640.8317. Time: 24769.0916 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #294: GFLOPs: 859.5480. Time: 18466.4723 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #295: GFLOPs: 640.6772. Time: 24775.0666 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #296: GFLOPs: 852.3549. Time: 18622.3125 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #297: GFLOPs: 729.2285. Time: 21766.5918 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #298: GFLOPs: 844.9553. Time: 18785.3958 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #299: GFLOPs: 779.3908. Time: 20365.6750 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #300: GFLOPs: 858.4636. Time: 18489.7987 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #301: GFLOPs: 749.2468. Time: 21185.0334 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #302: GFLOPs: 1132.0461. Time: 14021.3541 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #303: GFLOPs: 1204.6590. Time: 13176.1926 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #304: GFLOPs: 901.2929. Time: 17611.1667 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #305: GFLOPs: 872.8210. Time: 18185.6527 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #306: GFLOPs: 1263.9833. Time: 12557.7760 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #307: GFLOPs: 716.2623. Time: 22160.6250 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #308: GFLOPs: 871.0000. Time: 18223.6737 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #309: GFLOPs: 1017.9281. Time: 15593.2619 us. Best GFLOPs: 1323.2133
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #310: GFLOPs: 1324.3408. Time: 11985.4491 us. Best GFLOPs: 1324.3408
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #311: GFLOPs: 738.7506. Time: 21486.0334 us. Best GFLOPs: 1324.3408
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #312: GFLOPs: 584.8833. Time: 27138.4375 us. Best GFLOPs: 1324.3408
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #313: GFLOPs: 240.5294. Time: 65991.1943 us. Best GFLOPs: 1324.3408
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #314: GFLOPs: 779.8717. Time: 20353.1168 us. Best GFLOPs: 1324.3408
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #315: GFLOPs: 837.2212. Time: 18958.9307 us. Best GFLOPs: 1324.3408
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #316: GFLOPs: 836.8372. Time: 18967.6320 us. Best GFLOPs: 1324.3408
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #317: GFLOPs: 636.9502. Time: 24920.0334 us. Best GFLOPs: 1324.3408
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #318: GFLOPs: 24.0387. Time: 660303.7917 us. Best GFLOPs: 1324.3408
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #319: GFLOPs: 28.5869. Time: 555248.7083 us. Best GFLOPs: 1324.3408
2023-05-18 14:21:57 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #320: GFLOPs: 97.6188. Time: 162599.9723 us. Best GFLOPs: 1324.3408
2023-05-18 15:03:46 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 15:03:47 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 15:03:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 409 failure(s)
2023-05-18 15:03:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 818 failure(s)
2023-05-18 15:03:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1224 failure(s)
2023-05-18 15:03:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1630 failure(s)
2023-05-18 15:03:53 [INFO] [evolutionary_search.cc:723] Sampled 10 candidate(s)
2023-05-18 15:03:58 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 90 failure(s)
2023-05-18 15:04:04 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 72 failure(s)
2023-05-18 15:04:10 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 71 failure(s)
2023-05-18 15:04:16 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 82 failure(s)
2023-05-18 15:04:19 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9894  0.9860  0.9762  0.9670  0.9493  0.9307  0.9269  0.9229  0.9227  0.9219  0.9191  0.9173  0.9161  0.9154  0.9148  0.9141
[17 : 32]:	0.9109  0.9104  0.9101  0.9093  0.9040  0.8995  0.8914  0.8826  0.8816  0.8801  0.8783  0.8775  0.8744  0.8717  0.8694  0.8691
[33 : 48]:	0.8684  0.8675  0.8673  0.8656  0.8656  0.8639  0.8577  0.8574  0.8573  0.8572  0.8568  0.8543  0.8495  0.8458  0.8456  0.8424
[49 : 64]:	0.8399  0.8381  0.8374  0.8367  0.8345  0.8344  0.8328  0.8291  0.8269  0.8266  0.8250  0.8249  0.8244  0.8244  0.8241  0.8210
2023-05-18 15:04:19 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 15:04:19 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #321: GFLOPs: 1323.6501. Time: 11991.7037 us. Best GFLOPs: 1324.3408
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #322: GFLOPs: 1247.2263. Time: 12726.4947 us. Best GFLOPs: 1324.3408
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #323: GFLOPs: 1174.9779. Time: 13509.0364 us. Best GFLOPs: 1324.3408
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #324: GFLOPs: 1247.2707. Time: 12726.0418 us. Best GFLOPs: 1324.3408
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #325: GFLOPs: 1261.1744. Time: 12585.7447 us. Best GFLOPs: 1324.3408
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #326: GFLOPs: 1167.0292. Time: 13601.0469 us. Best GFLOPs: 1324.3408
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #327: GFLOPs: 1348.3287. Time: 11772.2176 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #328: GFLOPs: 249.0215. Time: 63740.7640 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #329: GFLOPs: 1295.1716. Time: 12255.3796 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #330: GFLOPs: 1184.6654. Time: 13398.5678 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #331: GFLOPs: 1186.0434. Time: 13383.0000 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #332: GFLOPs: 287.2163. Time: 55264.3333 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #333: GFLOPs: 1099.8024. Time: 14432.4286 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #334: GFLOPs: 1081.2630. Time: 14679.8869 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #335: GFLOPs: 1092.6847. Time: 14526.4406 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #336: GFLOPs: 1199.9920. Time: 13227.4375 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #337: GFLOPs: 1161.3829. Time: 13667.1719 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #338: GFLOPs: 1238.1103. Time: 12820.1979 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #339: GFLOPs: 1216.8903. Time: 13043.7553 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #340: GFLOPs: 1176.6864. Time: 13489.4219 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #341: GFLOPs: 1249.7304. Time: 12700.9947 us. Best GFLOPs: 1348.3287
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #342: GFLOPs: 1403.7046. Time: 11307.8056 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #343: GFLOPs: 1129.7895. Time: 14049.3594 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #344: GFLOPs: 1075.4485. Time: 14759.2559 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #345: GFLOPs: 1366.6169. Time: 11614.6806 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #346: GFLOPs: 1055.5274. Time: 15037.8094 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #347: GFLOPs: 1027.1188. Time: 15453.7321 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #348: GFLOPs: 1403.4122. Time: 11310.1620 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #349: GFLOPs: 1131.7472. Time: 14025.0572 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #350: GFLOPs: 1151.5672. Time: 13783.6668 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #351: GFLOPs: 1100.0029. Time: 14429.7977 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #352: GFLOPs: 1221.3394. Time: 12996.2395 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #353: GFLOPs: 1171.0306. Time: 13554.5729 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #354: GFLOPs: 1127.7677. Time: 14074.5469 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #355: GFLOPs: 776.6859. Time: 20436.6000 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #356: GFLOPs: 1170.1084. Time: 13565.2551 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #357: GFLOPs: 1164.8320. Time: 13626.7031 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #358: GFLOPs: 726.9000. Time: 21836.3166 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #359: GFLOPs: 777.0072. Time: 20428.1500 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #360: GFLOPs: 899.5711. Time: 17644.8750 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #361: GFLOPs: 1366.3207. Time: 11617.1991 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #362: GFLOPs: 1348.1442. Time: 11773.8288 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #363: GFLOPs: 1185.0463. Time: 13394.2605 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #364: GFLOPs: 1175.8501. Time: 13499.0156 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #365: GFLOPs: 1152.3027. Time: 13774.8697 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #366: GFLOPs: 1241.0128. Time: 12790.2135 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #367: GFLOPs: 1109.4954. Time: 14306.3409 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #368: GFLOPs: 1118.3288. Time: 14193.3386 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #369: GFLOPs: 1107.7211. Time: 14329.2559 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #370: GFLOPs: 1152.1384. Time: 13776.8332 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #371: GFLOPs: 1316.4442. Time: 12057.3426 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #372: GFLOPs: 1168.4790. Time: 13584.1719 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #373: GFLOPs: 1036.4895. Time: 15314.0179 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #374: GFLOPs: 1011.0839. Time: 15698.8154 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #375: GFLOPs: 1124.6953. Time: 14112.9947 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #376: GFLOPs: 1308.3072. Time: 12132.3333 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #377: GFLOPs: 1127.8695. Time: 14073.2760 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #378: GFLOPs: 1130.2924. Time: 14043.1094 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #379: GFLOPs: 1108.3998. Time: 14320.4821 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #380: GFLOPs: 1133.2327. Time: 14006.6719 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #381: GFLOPs: 1398.3699. Time: 11350.9444 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #382: GFLOPs: 39.6247. Time: 400578.7500 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #383: GFLOPs: 103.8147. Time: 152895.6947 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #384: GFLOPs: 344.6754. Time: 46051.5000 us. Best GFLOPs: 1403.7046
2023-05-18 15:07:15 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 15:07:16 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 15:07:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 409 failure(s)
2023-05-18 15:07:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 816 failure(s)
2023-05-18 15:07:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1224 failure(s)
2023-05-18 15:07:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1633 failure(s)
2023-05-18 15:07:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 2039 failure(s)
2023-05-18 15:07:24 [INFO] [evolutionary_search.cc:723] Sampled 11 candidate(s)
2023-05-18 15:07:29 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 100 failure(s)
2023-05-18 15:07:35 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 81 failure(s)
2023-05-18 15:07:41 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 77 failure(s)
2023-05-18 15:07:47 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 114 failure(s)
2023-05-18 15:07:50 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9973  0.9583  0.9536  0.9534  0.9484  0.9464  0.9316  0.9245  0.9227  0.9223  0.9221  0.9210  0.9169  0.9159  0.9134  0.9057
[17 : 32]:	0.9055  0.8995  0.8974  0.8974  0.8947  0.8945  0.8926  0.8907  0.8898  0.8893  0.8879  0.8877  0.8855  0.8839  0.8820  0.8803
[33 : 48]:	0.8797  0.8796  0.8791  0.8784  0.8780  0.8773  0.8765  0.8764  0.8735  0.8698  0.8694  0.8694  0.8688  0.8667  0.8655  0.8652
[49 : 64]:	0.8647  0.8644  0.8638  0.8637  0.8631  0.8617  0.8604  0.8600  0.8597  0.8597  0.8589  0.8556  0.8553  0.8552  0.8535  0.8533
2023-05-18 15:07:50 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 15:07:50 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #385: GFLOPs: 1340.2953. Time: 11842.7778 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #386: GFLOPs: 1169.5143. Time: 13572.1459 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #387: GFLOPs: 1273.6727. Time: 12462.2430 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #388: GFLOPs: 1319.0815. Time: 12033.2361 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #389: GFLOPs: 1116.1159. Time: 14221.4791 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #390: GFLOPs: 1252.8602. Time: 12669.2656 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #391: GFLOPs: 1240.8774. Time: 12791.6094 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #392: GFLOPs: 1391.7693. Time: 11404.7778 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #393: GFLOPs: 1094.2648. Time: 14505.4643 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #394: GFLOPs: 1177.9112. Time: 13475.3959 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #395: GFLOPs: 1100.8966. Time: 14418.0833 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #396: GFLOPs: 1127.4247. Time: 14078.8281 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #397: GFLOPs: 1218.3303. Time: 13028.3385 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #398: GFLOPs: 244.9042. Time: 64812.3613 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #399: GFLOPs: 1261.1186. Time: 12586.3020 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #400: GFLOPs: 287.2378. Time: 55260.1943 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #401: GFLOPs: 1238.2109. Time: 12819.1562 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #402: GFLOPs: 241.6433. Time: 65686.9723 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #403: GFLOPs: 1119.1370. Time: 14183.0885 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #404: GFLOPs: 904.7406. Time: 17544.0555 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #405: GFLOPs: 1161.0333. Time: 13671.2865 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #406: GFLOPs: 1402.6623. Time: 11316.2083 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #407: GFLOPs: 253.1414. Time: 62703.3610 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #408: GFLOPs: 1197.6040. Time: 13253.8125 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #409: GFLOPs: 1098.8651. Time: 14444.7381 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #410: GFLOPs: 266.8803. Time: 59475.4167 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #411: GFLOPs: 1200.2524. Time: 13224.5676 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #412: GFLOPs: 1343.1312. Time: 11817.7731 us. Best GFLOPs: 1403.7046
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #413: GFLOPs: 1421.6451. Time: 11165.1064 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #414: GFLOPs: 1409.5333. Time: 11261.0462 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #415: GFLOPs: 1161.1868. Time: 13669.4791 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #416: GFLOPs: 1160.4674. Time: 13677.9531 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #417: GFLOPs: 1246.1660. Time: 12737.3229 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #418: GFLOPs: 1299.2418. Time: 12216.9861 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #419: GFLOPs: 1253.0003. Time: 12667.8490 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #420: GFLOPs: 1151.6008. Time: 13783.2656 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #421: GFLOPs: 1099.3295. Time: 14438.6369 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #422: GFLOPs: 1160.5333. Time: 13677.1771 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #423: GFLOPs: 1096.7117. Time: 14473.1011 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #424: GFLOPs: 376.4813. Time: 42160.9720 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #425: GFLOPs: 1132.1327. Time: 14020.2812 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #426: GFLOPs: 939.3077. Time: 16898.4237 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #427: GFLOPs: 1101.0998. Time: 14415.4227 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #428: GFLOPs: 1182.2329. Time: 13426.1354 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #429: GFLOPs: 1301.8451. Time: 12192.5556 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #430: GFLOPs: 1246.5111. Time: 12733.7969 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #431: GFLOPs: 1084.8834. Time: 14630.8989 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #432: GFLOPs: 1043.1615. Time: 15216.0714 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #433: GFLOPs: 1162.0812. Time: 13658.9582 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #434: GFLOPs: 1325.1388. Time: 11978.2314 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #435: GFLOPs: 1120.5950. Time: 14164.6354 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #436: GFLOPs: 1075.2884. Time: 14761.4524 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #437: GFLOPs: 1074.3761. Time: 14773.9880 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #438: GFLOPs: 1106.3447. Time: 14347.0833 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #439: GFLOPs: 272.3590. Time: 58279.0417 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #440: GFLOPs: 1086.0101. Time: 14615.7201 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #441: GFLOPs: 1161.0492. Time: 13671.0990 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #442: GFLOPs: 1032.9700. Time: 15366.1964 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #443: GFLOPs: 1130.9333. Time: 14035.1510 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #444: GFLOPs: 1152.6535. Time: 13770.6771 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #445: GFLOPs: 1393.2318. Time: 11392.8056 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #446: GFLOPs: 82.2679. Time: 192940.6667 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #447: GFLOPs: 99.7507. Time: 159124.8470 us. Best GFLOPs: 1421.6451
2023-05-18 15:10:29 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #448: GFLOPs: 59.2616. Time: 267843.0833 us. Best GFLOPs: 1421.6451
2023-05-18 15:45:00 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 15:45:01 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 15:45:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 407 failure(s)
2023-05-18 15:45:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 812 failure(s)
2023-05-18 15:45:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1219 failure(s)
2023-05-18 15:45:06 [INFO] [evolutionary_search.cc:723] Sampled 11 candidate(s)
2023-05-18 15:45:11 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 103 failure(s)
2023-05-18 15:45:17 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 80 failure(s)
2023-05-18 15:45:23 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 92 failure(s)
2023-05-18 15:45:30 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 87 failure(s)
2023-05-18 15:45:32 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9869  0.9861  0.9767  0.9715  0.9715  0.9686  0.9631  0.9587  0.9577  0.9575  0.9562  0.9559  0.9559  0.9544  0.9536  0.9514
[17 : 32]:	0.9508  0.9490  0.9447  0.9431  0.9406  0.9379  0.9365  0.9354  0.9349  0.9337  0.9325  0.9321  0.9264  0.9261  0.9221  0.9156
[33 : 48]:	0.9155  0.9139  0.9136  0.9128  0.9114  0.9112  0.9107  0.9098  0.9039  0.9023  0.9014  0.9009  0.9003  0.8996  0.8992  0.8983
[49 : 64]:	0.8978  0.8952  0.8946  0.8927  0.8899  0.8890  0.8889  0.8869  0.8863  0.8855  0.8840  0.8826  0.8823  0.8814  0.8809  0.8796
2023-05-18 15:45:32 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 15:45:32 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #449: GFLOPs: 1418.5066. Time: 11189.8102 us. Best GFLOPs: 1421.6451
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #450: GFLOPs: 1223.9543. Time: 12968.4740 us. Best GFLOPs: 1421.6451
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #451: GFLOPs: 1129.4550. Time: 14053.5207 us. Best GFLOPs: 1421.6451
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #452: GFLOPs: 1417.6479. Time: 11196.5880 us. Best GFLOPs: 1421.6451
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #453: GFLOPs: 1417.2494. Time: 11199.7361 us. Best GFLOPs: 1421.6451
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #454: GFLOPs: 1270.9436. Time: 12489.0035 us. Best GFLOPs: 1421.6451
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #455: GFLOPs: 1336.9050. Time: 11872.8102 us. Best GFLOPs: 1421.6451
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #456: GFLOPs: 1426.8629. Time: 11124.2778 us. Best GFLOPs: 1426.8629
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #457: GFLOPs: 1326.1485. Time: 11969.1111 us. Best GFLOPs: 1426.8629
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #458: GFLOPs: 1321.0200. Time: 12015.5787 us. Best GFLOPs: 1426.8629
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #459: GFLOPs: 1414.4248. Time: 11222.1019 us. Best GFLOPs: 1426.8629
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #460: GFLOPs: 1428.2782. Time: 11113.2547 us. Best GFLOPs: 1428.2782
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #461: GFLOPs: 1438.4329. Time: 11034.8000 us. Best GFLOPs: 1438.4329
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #462: GFLOPs: 1341.5707. Time: 11831.5186 us. Best GFLOPs: 1438.4329
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #463: GFLOPs: 1458.5581. Time: 10882.5416 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #464: GFLOPs: 1378.1374. Time: 11517.5879 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #465: GFLOPs: 1414.9029. Time: 11218.3102 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #466: GFLOPs: 1429.5468. Time: 11103.3929 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #467: GFLOPs: 1362.0456. Time: 11653.6621 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #468: GFLOPs: 1360.1587. Time: 11669.8288 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #469: GFLOPs: 1448.0468. Time: 10961.5375 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #470: GFLOPs: 1423.4589. Time: 11150.8796 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #471: GFLOPs: 1390.2822. Time: 11416.9769 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #472: GFLOPs: 1263.3420. Time: 12564.1511 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #473: GFLOPs: 1328.9093. Time: 11944.2454 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #474: GFLOPs: 1436.7704. Time: 11047.5684 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #475: GFLOPs: 1402.0778. Time: 11320.9260 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #476: GFLOPs: 1384.9151. Time: 11461.2222 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #477: GFLOPs: 1419.0038. Time: 11185.8889 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #478: GFLOPs: 1372.0971. Time: 11568.2917 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #479: GFLOPs: 1341.5057. Time: 11832.0927 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #480: GFLOPs: 1383.2678. Time: 11474.8704 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #481: GFLOPs: 1202.4128. Time: 13200.8072 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #482: GFLOPs: 1035.2401. Time: 15332.5000 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #483: GFLOPs: 1354.2837. Time: 11720.4537 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #484: GFLOPs: 1365.9353. Time: 11620.4769 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #485: GFLOPs: 1238.1551. Time: 12819.7344 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #486: GFLOPs: 1251.6310. Time: 12681.7084 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #487: GFLOPs: 1246.5427. Time: 12733.4740 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #488: GFLOPs: 1185.3980. Time: 13390.2865 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #489: GFLOPs: 1415.4257. Time: 11214.1667 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #490: GFLOPs: 1278.5228. Time: 12414.9676 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #491: GFLOPs: 1281.6576. Time: 12384.6019 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #492: GFLOPs: 1228.0206. Time: 12925.5312 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #493: GFLOPs: 1411.6841. Time: 11243.8889 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #494: GFLOPs: 1301.4948. Time: 12195.8379 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #495: GFLOPs: 1197.0259. Time: 13260.2135 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #496: GFLOPs: 1282.8335. Time: 12373.2500 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #497: GFLOPs: 1225.4864. Time: 12952.2605 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #498: GFLOPs: 1447.5274. Time: 10965.4709 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #499: GFLOPs: 1174.5033. Time: 13514.4948 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #500: GFLOPs: 1308.7827. Time: 12127.9259 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #501: GFLOPs: 1171.3740. Time: 13550.5990 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #502: GFLOPs: 1252.0593. Time: 12677.3697 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #503: GFLOPs: 1374.4414. Time: 11548.5601 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #504: GFLOPs: 1233.5270. Time: 12867.8332 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #505: GFLOPs: 1186.4899. Time: 13377.9635 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #506: GFLOPs: 1239.4245. Time: 12806.6041 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #507: GFLOPs: 1166.8987. Time: 13602.5678 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #508: GFLOPs: 1250.2785. Time: 12695.4270 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #509: GFLOPs: 1202.5039. Time: 13199.8074 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #510: GFLOPs: 596.8071. Time: 26596.2290 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #511: GFLOPs: 61.4210. Time: 258426.7223 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #512: GFLOPs: 27.8514. Time: 569911.1527 us. Best GFLOPs: 1458.5581
2023-05-18 15:46:52 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 15:46:53 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 15:46:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 407 failure(s)
2023-05-18 15:46:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 814 failure(s)
2023-05-18 15:46:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1222 failure(s)
2023-05-18 15:47:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1630 failure(s)
2023-05-18 15:47:00 [INFO] [evolutionary_search.cc:723] Sampled 10 candidate(s)
2023-05-18 15:47:04 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 97 failure(s)
2023-05-18 15:47:10 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 66 failure(s)
2023-05-18 15:47:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 75 failure(s)
2023-05-18 15:47:23 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 70 failure(s)
2023-05-18 15:47:26 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9869  0.9757  0.9743  0.9743  0.9730  0.9715  0.9691  0.9667  0.9660  0.9634  0.9634  0.9632  0.9610  0.9590  0.9553  0.9537
[17 : 32]:	0.9533  0.9531  0.9523  0.9505  0.9490  0.9490  0.9449  0.9448  0.9415  0.9406  0.9379  0.9368  0.9365  0.9365  0.9358  0.9349
[33 : 48]:	0.9344  0.9313  0.9306  0.9295  0.9294  0.9290  0.9283  0.9283  0.9283  0.9280  0.9249  0.9236  0.9230  0.9225  0.9216  0.9211
[49 : 64]:	0.9209  0.9188  0.9183  0.9169  0.9169  0.9150  0.9150  0.9143  0.9131  0.9122  0.9111  0.9110  0.9109  0.9093  0.9065  0.9056
2023-05-18 15:47:26 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 15:47:26 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #513: GFLOPs: 1417.1363. Time: 11200.6297 us. Best GFLOPs: 1458.5581
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #514: GFLOPs: 1403.5811. Time: 11308.8010 us. Best GFLOPs: 1458.5581
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #515: GFLOPs: 1448.1266. Time: 10960.9334 us. Best GFLOPs: 1458.5581
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #516: GFLOPs: 1456.2481. Time: 10899.8042 us. Best GFLOPs: 1458.5581
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #517: GFLOPs: 1403.8184. Time: 11306.8889 us. Best GFLOPs: 1458.5581
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #518: GFLOPs: 1414.1582. Time: 11224.2176 us. Best GFLOPs: 1458.5581
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #519: GFLOPs: 1299.2994. Time: 12216.4444 us. Best GFLOPs: 1458.5581
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #520: GFLOPs: 1318.7583. Time: 12036.1852 us. Best GFLOPs: 1458.5581
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #521: GFLOPs: 1446.0998. Time: 10976.2959 us. Best GFLOPs: 1458.5581
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #522: GFLOPs: 1395.8410. Time: 11371.5093 us. Best GFLOPs: 1458.5581
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #523: GFLOPs: 1394.0725. Time: 11385.9351 us. Best GFLOPs: 1458.5581
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #524: GFLOPs: 1420.1759. Time: 11176.6574 us. Best GFLOPs: 1458.5581
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #525: GFLOPs: 1334.0206. Time: 11898.4814 us. Best GFLOPs: 1458.5581
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #526: GFLOPs: 1459.1106. Time: 10878.4208 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #527: GFLOPs: 1322.1397. Time: 12005.4028 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #528: GFLOPs: 1410.9155. Time: 11250.0139 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #529: GFLOPs: 1370.0733. Time: 11585.3797 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #530: GFLOPs: 1400.2065. Time: 11336.0556 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #531: GFLOPs: 684.7092. Time: 23181.8418 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #532: GFLOPs: 1338.4248. Time: 11859.3288 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #533: GFLOPs: 1440.0582. Time: 11022.3458 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #534: GFLOPs: 1285.3642. Time: 12348.8889 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #535: GFLOPs: 1444.1838. Time: 10990.8583 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #536: GFLOPs: 1424.8095. Time: 11140.3101 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #537: GFLOPs: 1408.9245. Time: 11265.9121 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #538: GFLOPs: 1354.5528. Time: 11718.1250 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #539: GFLOPs: 1323.7165. Time: 11991.1018 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #540: GFLOPs: 1339.3246. Time: 11851.3611 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #541: GFLOPs: 1440.6136. Time: 11018.0958 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #542: GFLOPs: 1426.0024. Time: 11130.9908 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #543: GFLOPs: 1319.8127. Time: 12026.5694 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #544: GFLOPs: 1251.7847. Time: 12680.1510 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #545: GFLOPs: 1203.6622. Time: 13187.1043 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #546: GFLOPs: 1374.9027. Time: 11544.6852 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #547: GFLOPs: 1399.0238. Time: 11345.6389 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #548: GFLOPs: 1317.4165. Time: 12048.4444 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #549: GFLOPs: 1221.6831. Time: 12992.5834 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #550: GFLOPs: 1353.6474. Time: 11725.9630 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #551: GFLOPs: 1436.5838. Time: 11049.0030 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #552: GFLOPs: 1429.0096. Time: 11107.5666 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #553: GFLOPs: 1215.7476. Time: 13056.0156 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #554: GFLOPs: 1348.2895. Time: 11772.5602 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #555: GFLOPs: 1449.2885. Time: 10952.1458 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #556: GFLOPs: 1320.4832. Time: 12020.4630 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #557: GFLOPs: 1295.7869. Time: 12249.5601 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #558: GFLOPs: 507.0500. Time: 31304.2500 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #559: GFLOPs: 1307.4222. Time: 12140.5462 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #560: GFLOPs: 1426.7602. Time: 11125.0787 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #561: GFLOPs: 1348.8603. Time: 11767.5787 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #562: GFLOPs: 1197.7335. Time: 13252.3801 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #563: GFLOPs: 1300.7640. Time: 12202.6898 us. Best GFLOPs: 1459.1106
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #564: GFLOPs: 1477.2702. Time: 10744.6959 us. Best GFLOPs: 1477.2702
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #565: GFLOPs: 1367.0638. Time: 11610.8842 us. Best GFLOPs: 1477.2702
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #566: GFLOPs: 1277.2130. Time: 12427.6991 us. Best GFLOPs: 1477.2702
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #567: GFLOPs: 1371.2613. Time: 11575.3426 us. Best GFLOPs: 1477.2702
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #568: GFLOPs: 1191.9700. Time: 13316.4582 us. Best GFLOPs: 1477.2702
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #569: GFLOPs: 1344.8566. Time: 11802.6111 us. Best GFLOPs: 1477.2702
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #570: GFLOPs: 1388.2915. Time: 11433.3472 us. Best GFLOPs: 1477.2702
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #571: GFLOPs: 1257.3474. Time: 12624.0521 us. Best GFLOPs: 1477.2702
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #572: GFLOPs: 1328.1444. Time: 11951.1250 us. Best GFLOPs: 1477.2702
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #573: GFLOPs: 1336.9629. Time: 11872.2962 us. Best GFLOPs: 1477.2702
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #574: GFLOPs: 12.8131. Time: 1238795.9307 us. Best GFLOPs: 1477.2702
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #575: GFLOPs: 11.5070. Time: 1379402.5557 us. Best GFLOPs: 1477.2702
2023-05-18 15:50:23 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #576: GFLOPs: 155.9129. Time: 101805.6527 us. Best GFLOPs: 1477.2702
2023-05-18 16:00:42 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 16:00:43 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 16:00:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 405 failure(s)
2023-05-18 16:00:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 814 failure(s)
2023-05-18 16:00:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1222 failure(s)
2023-05-18 16:00:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1628 failure(s)
2023-05-18 16:00:51 [INFO] [evolutionary_search.cc:723] Sampled 12 candidate(s)
2023-05-18 16:00:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 101 failure(s)
2023-05-18 16:01:02 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 107 failure(s)
2023-05-18 16:01:08 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 98 failure(s)
2023-05-18 16:01:15 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 76 failure(s)
2023-05-18 16:01:17 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0356  1.0322  1.0283  1.0258  1.0240  1.0228  1.0205  1.0198  1.0195  1.0177  1.0171  1.0168  1.0163  1.0142  1.0135  1.0109
[17 : 32]:	1.0107  1.0100  1.0086  1.0041  1.0041  1.0041  1.0041  1.0036  1.0023  1.0019  1.0015  1.0005  0.9996  0.9978  0.9978  0.9965
[33 : 48]:	0.9958  0.9937  0.9932  0.9931  0.9914  0.9907  0.9872  0.9862  0.9862  0.9862  0.9854  0.9851  0.9847  0.9842  0.9840  0.9838
[49 : 64]:	0.9837  0.9821  0.9819  0.9806  0.9800  0.9799  0.9798  0.9786  0.9783  0.9779  0.9777  0.9765  0.9756  0.9751  0.9751  0.9748
2023-05-18 16:01:17 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 16:01:17 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #577: GFLOPs: 1378.6883. Time: 11512.9861 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #578: GFLOPs: 1452.3003. Time: 10929.4334 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #579: GFLOPs: 1359.1542. Time: 11678.4537 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #580: GFLOPs: 1419.0866. Time: 11185.2361 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #581: GFLOPs: 1384.6986. Time: 11463.0139 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #582: GFLOPs: 1418.9815. Time: 11186.0648 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #583: GFLOPs: 1442.3069. Time: 11005.1607 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #584: GFLOPs: 1350.0707. Time: 11757.0278 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #585: GFLOPs: 1412.0550. Time: 11240.9352 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #586: GFLOPs: 1362.2226. Time: 11652.1482 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #587: GFLOPs: 1403.7029. Time: 11307.8194 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #588: GFLOPs: 1376.8098. Time: 11528.6944 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #589: GFLOPs: 1344.3878. Time: 11806.7269 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #590: GFLOPs: 1434.7349. Time: 11063.2416 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #591: GFLOPs: 1362.4678. Time: 11650.0509 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #592: GFLOPs: 1445.6817. Time: 10979.4702 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #593: GFLOPs: 1369.9008. Time: 11586.8380 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #594: GFLOPs: 1307.8835. Time: 12136.2639 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #595: GFLOPs: 1410.0121. Time: 11257.2222 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #596: GFLOPs: 1427.5746. Time: 11118.7316 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #597: GFLOPs: 1426.4758. Time: 11127.2963 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #598: GFLOPs: 1427.6799. Time: 11117.9120 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #599: GFLOPs: 1428.5389. Time: 11111.2268 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #600: GFLOPs: 901.0342. Time: 17616.2222 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #601: GFLOPs: 1431.0082. Time: 11092.0536 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #602: GFLOPs: 1381.9631. Time: 11485.7037 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #603: GFLOPs: 1425.3858. Time: 11135.8056 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #604: GFLOPs: 1420.8474. Time: 11171.3750 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #605: GFLOPs: 1338.4227. Time: 11859.3472 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #606: GFLOPs: 1421.3328. Time: 11167.5602 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #607: GFLOPs: 1414.2410. Time: 11223.5602 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #608: GFLOPs: 1431.7142. Time: 11086.5833 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #609: GFLOPs: 1443.1886. Time: 10998.4375 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #610: GFLOPs: 1382.4028. Time: 11482.0509 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #611: GFLOPs: 1374.9540. Time: 11544.2547 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #612: GFLOPs: 1426.7836. Time: 11124.8959 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #613: GFLOPs: 1256.9351. Time: 12628.1928 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #614: GFLOPs: 1416.4583. Time: 11205.9908 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #615: GFLOPs: 1364.5153. Time: 11632.5694 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #616: GFLOPs: 1453.6420. Time: 10919.3458 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #617: GFLOPs: 1459.8369. Time: 10873.0084 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #618: GFLOPs: 1458.9614. Time: 10879.5333 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #619: GFLOPs: 1413.7290. Time: 11227.6250 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #620: GFLOPs: 1223.8619. Time: 12969.4531 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #621: GFLOPs: 1342.1637. Time: 11826.2917 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #622: GFLOPs: 1438.2825. Time: 11035.9541 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #623: GFLOPs: 1427.7423. Time: 11117.4260 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #624: GFLOPs: 1418.8846. Time: 11186.8288 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #625: GFLOPs: 1355.3598. Time: 11711.1481 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #626: GFLOPs: 1364.3003. Time: 11634.4028 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #627: GFLOPs: 1381.3568. Time: 11490.7454 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #628: GFLOPs: 1425.7652. Time: 11132.8426 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #629: GFLOPs: 875.6022. Time: 18127.8890 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #630: GFLOPs: 825.1776. Time: 19235.6388 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #631: GFLOPs: 1341.7587. Time: 11829.8611 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #632: GFLOPs: 1433.4366. Time: 11073.2619 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #633: GFLOPs: 1374.2612. Time: 11550.0741 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #634: GFLOPs: 1377.2506. Time: 11525.0047 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #635: GFLOPs: 1430.7249. Time: 11094.2500 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #636: GFLOPs: 1164.2797. Time: 13633.1666 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #637: GFLOPs: 1378.0904. Time: 11517.9814 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:121] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #638: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv7: T.Buffer((T.int64(1), T.int64(96), T.int64(640), T.int64(448)), "float32"), self_rrdb_body_0_rdb1_conv2_weight: T.Buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), "float32"), lv9: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_body_0_rdb1_conv2_weight_shared = T.alloc_buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(140), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(8), T.int64(1), T.int64(4), T.int64(1), T.int64(2)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(8) * T.int64(4) + ff_3_init * T.int64(4) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(28) * T.int64(128) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(8) * T.int64(16) + yy_3_init + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(28) * T.int64(16) + xx_3_init * T.int64(2) + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(32), T.int64(1), T.int64(3)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(65)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(3)):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v1 = T.axis.spatial(T.int64(96), rc_0 * T.int64(3) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) // T.int64(2080))
                                        v2 = T.axis.spatial(T.int64(642), nn_0_ff_0_yy_0_xx_0_fused // T.int64(28) * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2080) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(450), rx_0 + nn_0_ff_0_yy_0_xx_0_fused % T.int64(28) * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(96) + ax0_ax1_ax2_ax3_fused_1 * T.int64(3) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(9)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("self_rrdb_body_0_rdb1_conv2.weight_shared"):
                                    v0 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(9))
                                    v1 = T.axis.spatial(T.int64(96), rc_0 * T.int64(3) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(9) // T.int64(3))
                                    v2 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(3))
                                    v3 = T.axis.spatial(T.int64(3), rx_0)
                                    T.reads(self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3])
                                    T.writes(self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3])
                                    self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3] = self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(8) * T.int64(4) + ff_3 * T.int64(4) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(28) * T.int64(128) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(8) * T.int64(16) + yy_3 + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(28) * T.int64(16) + xx_3 * T.int64(2) + xx_4)
                                v_rc = T.axis.reduce(T.int64(96), rc_0 * T.int64(3) + rc_1 * T.int64(3) + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 * T.int64(3) + ry_1 * T.int64(3) + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 + rx_1 + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(16), T.int64(16)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(32), nn_1_ff_1_yy_1_xx_1_fused * T.int64(16) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(8) * T.int64(4) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused // T.int64(28) * T.int64(128) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(8) * T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(28) * T.int64(16) + ax3)
                            T.reads(var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv9[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_compute_intermediate[v0, v1, v2, v3])
                            var_compute_intermediate[v0, v1, v2, v3] = T.Select(T.float32(0) < var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)]) * T.float32(0.20000000000000001))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="compute", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 2, 4, 1, 4])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[5, 1, 8, 16, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[28, 1, 1, 8, 2])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[32, 1, 3])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 32, 3], preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119 = sch.split(loop=l117, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b121)
l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #639: GFLOPs: 412.5556. Time: 38474.3750 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #640: GFLOPs: 13.1125. Time: 1210510.1250 us. Best GFLOPs: 1477.2702
2023-05-18 16:02:51 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 16:02:52 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 16:02:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 407 failure(s)
2023-05-18 16:02:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 811 failure(s)
2023-05-18 16:02:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1218 failure(s)
2023-05-18 16:02:57 [INFO] [evolutionary_search.cc:723] Sampled 12 candidate(s)
2023-05-18 16:03:02 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 98 failure(s)
2023-05-18 16:03:08 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 99 failure(s)
2023-05-18 16:03:15 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 91 failure(s)
2023-05-18 16:03:21 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 89 failure(s)
2023-05-18 16:03:24 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0502  1.0438  1.0374  1.0347  1.0288  1.0258  1.0257  1.0194  1.0175  1.0150  1.0137  1.0125  1.0122  1.0111  1.0096  1.0087
[17 : 32]:	1.0078  1.0073  1.0051  1.0051  1.0043  1.0041  1.0037  1.0026  1.0026  1.0021  0.9991  0.9978  0.9978  0.9978  0.9962  0.9953
[33 : 48]:	0.9941  0.9927  0.9923  0.9911  0.9905  0.9905  0.9899  0.9896  0.9889  0.9889  0.9879  0.9878  0.9877  0.9871  0.9871  0.9864
[49 : 64]:	0.9862  0.9858  0.9858  0.9857  0.9853  0.9844  0.9837  0.9833  0.9816  0.9811  0.9790  0.9785  0.9785  0.9754  0.9751  0.9747
2023-05-18 16:03:24 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 16:03:24 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #641: GFLOPs: 1425.3153. Time: 11136.3564 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #642: GFLOPs: 1424.0608. Time: 11146.1667 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #643: GFLOPs: 1414.3233. Time: 11222.9073 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #644: GFLOPs: 1348.5642. Time: 11770.1620 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #645: GFLOPs: 1414.0264. Time: 11225.2639 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #646: GFLOPs: 1426.4907. Time: 11127.1806 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #647: GFLOPs: 1420.1147. Time: 11177.1389 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #648: GFLOPs: 1421.9205. Time: 11162.9444 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #649: GFLOPs: 1415.5501. Time: 11213.1806 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #650: GFLOPs: 1414.7079. Time: 11219.8564 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #651: GFLOPs: 1426.0641. Time: 11130.5092 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #652: GFLOPs: 1445.9664. Time: 10977.3084 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #653: GFLOPs: 833.1894. Time: 19050.6735 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #654: GFLOPs: 1425.6699. Time: 11133.5863 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #655: GFLOPs: 1430.2763. Time: 11097.7291 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #656: GFLOPs: 1438.0217. Time: 11037.9554 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #657: GFLOPs: 1428.1122. Time: 11114.5463 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #658: GFLOPs: 1421.3569. Time: 11167.3704 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #659: GFLOPs: 1402.6698. Time: 11316.1481 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #660: GFLOPs: 1417.8015. Time: 11195.3750 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #661: GFLOPs: 1457.9865. Time: 10886.8083 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #662: GFLOPs: 1427.9320. Time: 11115.9491 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #663: GFLOPs: 1372.3805. Time: 11565.9028 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #664: GFLOPs: 1423.8881. Time: 11147.5186 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #665: GFLOPs: 1456.7253. Time: 10896.2333 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #666: GFLOPs: 1360.5819. Time: 11666.1991 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #667: GFLOPs: 1422.9644. Time: 11154.7547 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #668: GFLOPs: 1362.5398. Time: 11649.4351 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #669: GFLOPs: 1420.9940. Time: 11170.2222 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #670: GFLOPs: 1423.1570. Time: 11153.2453 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #671: GFLOPs: 1426.3055. Time: 11128.6250 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #672: GFLOPs: 1407.2133. Time: 11279.6111 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #673: GFLOPs: 1388.3033. Time: 11433.2500 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #674: GFLOPs: 1363.4973. Time: 11641.2547 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #675: GFLOPs: 1437.0747. Time: 11045.2291 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #676: GFLOPs: 1447.3123. Time: 10967.1000 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #677: GFLOPs: 1386.8231. Time: 11445.4537 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #678: GFLOPs: 523.7499. Time: 30306.1043 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #679: GFLOPs: 1453.7879. Time: 10918.2500 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #680: GFLOPs: 1356.9535. Time: 11697.3936 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #681: GFLOPs: 1439.3753. Time: 11027.5750 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #682: GFLOPs: 1354.9050. Time: 11715.0788 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #683: GFLOPs: 1421.6791. Time: 11164.8393 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #684: GFLOPs: 1268.8545. Time: 12509.5660 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #685: GFLOPs: 1363.5006. Time: 11641.2268 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #686: GFLOPs: 1412.6846. Time: 11235.9260 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #687: GFLOPs: 1422.5618. Time: 11157.9120 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #688: GFLOPs: 878.5741. Time: 18066.5695 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #689: GFLOPs: 1458.6821. Time: 10881.6167 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #690: GFLOPs: 899.9182. Time: 17638.0695 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #691: GFLOPs: 1399.8698. Time: 11338.7824 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #692: GFLOPs: 719.4378. Time: 22062.8084 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #693: GFLOPs: 1418.5042. Time: 11189.8287 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #694: GFLOPs: 1386.2130. Time: 11450.4907 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #695: GFLOPs: 1426.4764. Time: 11127.2917 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #696: GFLOPs: 1359.7498. Time: 11673.3380 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #697: GFLOPs: 880.7258. Time: 18022.4307 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #698: GFLOPs: 1431.5475. Time: 11087.8750 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #699: GFLOPs: 1360.2758. Time: 11668.8241 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #700: GFLOPs: 1417.8326. Time: 11195.1296 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #701: GFLOPs: 1408.6860. Time: 11267.8194 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #702: GFLOPs: 8.4392. Time: 1880839.3053 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #703: GFLOPs: 15.0675. Time: 1053444.8750 us. Best GFLOPs: 1477.2702
2023-05-18 16:06:58 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #704: GFLOPs: 547.7498. Time: 28978.2292 us. Best GFLOPs: 1477.2702
2023-05-18 16:29:56 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 16:29:56 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 16:29:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 409 failure(s)
2023-05-18 16:30:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 816 failure(s)
2023-05-18 16:30:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1224 failure(s)
2023-05-18 16:30:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1631 failure(s)
2023-05-18 16:30:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 2039 failure(s)
2023-05-18 16:30:05 [INFO] [evolutionary_search.cc:723] Sampled 11 candidate(s)
2023-05-18 16:30:10 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 123 failure(s)
2023-05-18 16:30:16 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 107 failure(s)
2023-05-18 16:30:23 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 98 failure(s)
2023-05-18 16:30:29 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 63 failure(s)
2023-05-18 16:30:32 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9784  0.9780  0.9778  0.9778  0.9778  0.9737  0.9703  0.9685  0.9652  0.9652  0.9652  0.9652  0.9652  0.9652  0.9652  0.9652
[17 : 32]:	0.9651  0.9648  0.9648  0.9648  0.9642  0.9639  0.9632  0.9632  0.9632  0.9632  0.9631  0.9619  0.9615  0.9615  0.9610  0.9609
[33 : 48]:	0.9609  0.9609  0.9609  0.9609  0.9609  0.9606  0.9603  0.9600  0.9600  0.9600  0.9596  0.9595  0.9591  0.9590  0.9590  0.9576
[49 : 64]:	0.9576  0.9576  0.9576  0.9573  0.9573  0.9564  0.9559  0.9559  0.9558  0.9540  0.9533  0.9519  0.9519  0.9516  0.9516  0.9512
2023-05-18 16:30:32 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 16:30:32 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #705: GFLOPs: 1448.7407. Time: 10956.2875 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #706: GFLOPs: 1386.8253. Time: 11445.4352 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #707: GFLOPs: 1458.6659. Time: 10881.7375 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #708: GFLOPs: 1375.4394. Time: 11540.1806 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #709: GFLOPs: 818.4913. Time: 19392.7778 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #710: GFLOPs: 1455.7195. Time: 10903.7625 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #711: GFLOPs: 1369.7520. Time: 11588.0972 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #712: GFLOPs: 1373.9798. Time: 11552.4398 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #713: GFLOPs: 1421.3988. Time: 11167.0417 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #714: GFLOPs: 1347.0076. Time: 11783.7639 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #715: GFLOPs: 1430.8665. Time: 11093.1518 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #716: GFLOPs: 1430.5314. Time: 11095.7500 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #717: GFLOPs: 1422.5966. Time: 11157.6389 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #718: GFLOPs: 1428.3805. Time: 11112.4583 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #719: GFLOPs: 1429.6602. Time: 11102.5119 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #720: GFLOPs: 1429.5563. Time: 11103.3184 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #721: GFLOPs: 1415.0348. Time: 11217.2639 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #722: GFLOPs: 1431.5475. Time: 11087.8750 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #723: GFLOPs: 1427.4801. Time: 11119.4677 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #724: GFLOPs: 1351.9271. Time: 11740.8843 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #725: GFLOPs: 883.6977. Time: 17961.8193 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #726: GFLOPs: 1416.1875. Time: 11208.1343 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #727: GFLOPs: 1422.6674. Time: 11157.0833 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #728: GFLOPs: 1422.1865. Time: 11160.8564 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #729: GFLOPs: 1417.0455. Time: 11201.3472 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #730: GFLOPs: 1422.4638. Time: 11158.6806 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #731: GFLOPs: 1406.5564. Time: 11284.8796 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #732: GFLOPs: 1420.1441. Time: 11176.9074 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #733: GFLOPs: 1421.6534. Time: 11165.0417 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #734: GFLOPs: 1420.4448. Time: 11174.5417 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #735: GFLOPs: 1428.1092. Time: 11114.5694 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #736: GFLOPs: 1353.2098. Time: 11729.7546 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #737: GFLOPs: 1409.4979. Time: 11261.3287 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #738: GFLOPs: 1415.3888. Time: 11214.4583 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #739: GFLOPs: 1414.9916. Time: 11217.6066 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #740: GFLOPs: 1413.6830. Time: 11227.9908 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #741: GFLOPs: 1343.6565. Time: 11813.1528 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #742: GFLOPs: 1324.6893. Time: 11982.2963 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #743: GFLOPs: 1427.9308. Time: 11115.9583 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #744: GFLOPs: 1437.4554. Time: 11042.3036 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #745: GFLOPs: 1437.0974. Time: 11045.0542 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #746: GFLOPs: 1436.2051. Time: 11051.9167 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #747: GFLOPs: 1425.2805. Time: 11136.6280 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #748: GFLOPs: 1435.3714. Time: 11058.3363 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #749: GFLOPs: 1425.1536. Time: 11137.6203 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #750: GFLOPs: 1414.8912. Time: 11218.4028 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #751: GFLOPs: 1379.5037. Time: 11506.1806 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #752: GFLOPs: 1441.9311. Time: 11008.0291 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #753: GFLOPs: 1443.4860. Time: 10996.1709 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #754: GFLOPs: 1448.8316. Time: 10955.6000 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #755: GFLOPs: 1442.2908. Time: 11005.2834 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #756: GFLOPs: 1356.9288. Time: 11697.6066 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #757: GFLOPs: 1407.9397. Time: 11273.7917 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #758: GFLOPs: 853.8348. Time: 18590.0347 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #759: GFLOPs: 1419.8700. Time: 11179.0648 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #760: GFLOPs: 1436.8427. Time: 11047.0125 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #761: GFLOPs: 1423.1771. Time: 11153.0880 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #762: GFLOPs: 1422.8747. Time: 11155.4583 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #763: GFLOPs: 1415.1785. Time: 11216.1250 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #764: GFLOPs: 1413.2576. Time: 11231.3703 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #765: GFLOPs: 1412.5518. Time: 11236.9821 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:121] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #766: Error in running:
RPCRunner: An exception occurred
Traceback (most recent call last):
  File "/Users/guoyaol/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 403, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/rpc_runner.py", line 515, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/Users/guoyaol/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/Users/guoyaol/tvm/python/tvm/runtime/module.py", line 403, in evaluator
    blob = feval(*args)
  File "/Users/guoyaol/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 238, in __call__
    raise get_last_ffi_error()
tvm.error.RPCError: Traceback (most recent call last):
  [bt] (8) 9   libtvm.dylib                        0x00000001223bf3e4 tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&) + 160
  [bt] (7) 8   libtvm.dylib                        0x00000001223b80a8 tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)>) + 332
  [bt] (6) 7   libtvm.dylib                        0x00000001223b6b10 tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 556
  [bt] (5) 6   libtvm.dylib                        0x00000001223b6dfc tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>) + 388
  [bt] (4) 5   libtvm.dylib                        0x00000001223ba95c tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>) + 372
  [bt] (3) 4   libtvm.dylib                        0x00000001223bc580 tvm::runtime::RPCEndpoint::EventHandler::HandleReturn(tvm::runtime::RPCCode, std::__1::function<void (tvm::runtime::TVMArgs)>) + 312
  [bt] (2) 3   libtvm.dylib                        0x0000000120003a44 __clang_call_terminate + 0
  [bt] (1) 2   libtvm.dylib                        0x0000000120005e20 tvm::runtime::detail::LogFatal::Entry::Finalize() + 0
  [bt] (0) 1   libtvm.dylib                        0x0000000120005e74 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84
  18: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  14: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  13: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  12: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  11: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  10: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  9: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  8: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  7: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  4: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  2: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  0: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87
  29: TVMFuncCall
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:477
  28: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  27: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::$_1> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  26: tvm::runtime::$_1::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:138
  25: tvm::runtime::RPCServerLoop(int)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_socket_impl.cc:119
  24: tvm::runtime::RPCEndpoint::ServerLoop()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:738
  23: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:647
  22: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:135
  21: tvm::runtime::RPCEndpoint::EventHandler::HandleProcessPacket(std::__1::function<void (tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:302
  20: tvm::runtime::RPCEndpoint::EventHandler::HandleNormalCallFunc()
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_endpoint.cc:479
  19: tvm::runtime::RPCSession::AsyncCallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::RPCCode, tvm::runtime::TVMArgs)>)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_session.cc:47
  18: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::__1::function<void (tvm::runtime::TVMArgs)> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/rpc/rpc_local_session.cc:91
  17: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  16: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  15: tvm::runtime::profiling::WrapTimeEvaluator(tvm::runtime::PackedFunc, DLDevice, int, int, int, int, int, int, tvm::runtime::PackedFunc)::$_7::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/profiling.cc:879
  14: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1221
  13: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1217
  12: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1213
  11: tvm::runtime::WrapPackedFunc(int (*)(TVMValue*, int*, int, TVMValue*, int*, void*), tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:83
  10: 0x000000011762c313
  9: 
  8: TVMBackendGetFuncFromEnv
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/c_runtime_api.cc:426
  7: tvm::runtime::ModuleNode::GetFuncFromEnv(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:114
  6: tvm::runtime::Module::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/include/tvm/runtime/packed_func.h:1946
  5: tvm::runtime::ModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/module.cc:66
  4: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:247
  3: void tvm::runtime::metal::AutoReleasePoolWrapper::operator<<<tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0>(tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0 const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_common.h:89
  2: tvm::runtime::MetalModuleNode::GetFunction(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::$_0::operator()() const
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:258
  1: tvm::runtime::MetalWrappedFunc::Init(tvm::runtime::MetalModuleNode*, tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, unsigned long, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:187
  0: tvm::runtime::MetalModuleNode::GetPipelineState(unsigned long, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)
        at /Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm:109
      int2 v__1 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((int)threadIdx) / 24) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((int)threadIdx) / 24) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  File "/Users/catalyst/Workspace/tvm-ruihang/src/runtime/metal/metal_module.mm", line 109
  File "/Users/guoyaol/tvm/src/runtime/rpc/rpc_endpoint.cc", line 376
RPCError: Error caught from RPC call:
[16:31:27] /Users/catalyst/Workspace/tvm-ruihang/src/runtime/library_module.cc:87: TVMError: Fail to compile metal source:program_source:34:241: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
program_source:34:767: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__1 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((int)threadIdx) / 24) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((int)threadIdx) / 24) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:34:1260: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__1 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((int)threadIdx) / 24) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((int)threadIdx) / 24) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:34:1737: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__1 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((int)threadIdx) / 24) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((int)threadIdx) / 24) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:34:2276: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__1 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((int)threadIdx) / 24) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((int)threadIdx) / 24) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) : ((int2(((((int)threadIdx) * 2))+(1*0), ((((int)threadIdx) * 2))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:36:269: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__2 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 128) / 48) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 128) / 48) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:36:859: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__2 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 128) / 48) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 128) / 48) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:36:1416: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__2 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 128) / 48) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 128) / 48) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:36:1957: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__2 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 128) / 48) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 128) / 48) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:36:2560: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__2 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 128) / 48) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 128) / 48) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 128))+(1*0), (((((int)threadIdx) * 2) + 128))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:38:269: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__3 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 256) / 48) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 256) / 48) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:38:859: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__3 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 256) / 48) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 256) / 48) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:38:1416: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__3 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 256) / 48) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 256) / 48) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:38:1957: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__3 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 256) / 48) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 256) / 48) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
program_source:38:2560: error: value of type 'bool __attribute__((ext_vector_type(2)))' (vector of 2 'bool' values) is not contextually convertible to 'bool'
      int2 v__3 = ((int2(((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 256) / 48) * 864)) + (rc_0 * 144)), ((((((int)blockIdx) / 896) * 6912) + ((((((int)threadIdx) * 2) + 256) / 48) * 864)) + (rc_0 * 144))) + (((((int2(16, 16) >= int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) >= int2(0, 0))) || ((int2(16, 16) < int2(0, 0)) && ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) <= int2(0, 0)))) ? (((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) : ((((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) / int2(3, 3)) - int2(1, 1))) % int2(16, 16)) + int2(16, 16))) * int2(9, 9))) + int2((ry_0 * 3), (ry_0 * 3))) + ((((int2(3, 3) >= int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) >= int2(0, 0))) || ((int2(3, 3) < int2(0, 0)) && ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) <= int2(0, 0)))) ? (int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) : ((int2((((((int)threadIdx) * 2) + 256))+(1*0), (((((int)threadIdx) * 2) + 256))+(1*1)) % int2(3, 3)) + int2(3, 3)));
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(lv7: T.Buffer((T.int64(1), T.int64(96), T.int64(640), T.int64(448)), "float32"), self_rrdb_body_0_rdb1_conv2_weight: T.Buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), "float32"), lv9: T.Buffer((T.int64(1), T.int64(32), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), "float32")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_conv2d_nchw_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(640), T.int64(448)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(642), T.int64(450)), scope="shared")
        self_rrdb_body_0_rdb1_conv2_weight_shared = T.alloc_buffer((T.int64(32), T.int64(96), T.int64(3), T.int64(3)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(3584), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(32), nn_0_ff_0_yy_0_xx_0_fused // T.int64(896) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(32) * T.int64(4) + ff_3_init * T.int64(4) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused % T.int64(896) // T.int64(56) * T.int64(40) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(20) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(32) // T.int64(8) * T.int64(5) + yy_3_init + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(56) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(8) + xx_3_init + xx_4_init)
                            T.reads()
                            T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0, ry_0, rx_0 in T.grid(T.int64(6), T.int64(3), T.int64(1)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(100)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(96), rc_0 * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(400))
                                    v2 = T.axis.spatial(T.int64(642), ry_0 + nn_0_ff_0_yy_0_xx_0_fused % T.int64(896) // T.int64(56) * T.int64(40) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(400) // T.int64(10))
                                    v3 = T.axis.spatial(T.int64(450), nn_0_ff_0_yy_0_xx_0_fused % T.int64(56) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(10))
                                    T.reads(lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(T.int64(1) <= v2 and v2 < T.int64(641) and T.int64(1) <= v3 and v3 < T.int64(449), lv7[v0, v1, v2 - T.int64(1), v3 - T.int64(1)], T.float32(0))
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("self_rrdb_body_0_rdb1_conv2.weight_shared"):
                                        v0 = T.axis.spatial(T.int64(32), nn_0_ff_0_yy_0_xx_0_fused // T.int64(896) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(48))
                                        v1 = T.axis.spatial(T.int64(96), rc_0 * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(48) // T.int64(3))
                                        v2 = T.axis.spatial(T.int64(3), ry_0)
                                        v3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                                        T.reads(self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3])
                                        T.writes(self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3])
                                        self_rrdb_body_0_rdb1_conv2_weight_shared[v0, v1, v2, v3] = self_rrdb_body_0_rdb1_conv2_weight[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(32), nn_0_ff_0_yy_0_xx_0_fused // T.int64(896) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(32) * T.int64(4) + ff_3 * T.int64(4) + ff_4)
                                v_yy = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused % T.int64(896) // T.int64(56) * T.int64(40) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(20) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(32) // T.int64(8) * T.int64(5) + yy_3 + yy_4)
                                v_xx = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(56) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(8) + xx_3 + xx_4)
                                v_rc = T.axis.reduce(T.int64(96), rc_0 * T.int64(16) + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(3), ry_0 + ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(3), rx_0 * T.int64(3) + rx_1 * T.int64(3) + rx_2)
                                T.reads(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 256, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * self_rrdb_body_0_rdb1_conv2_weight_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(5), T.int64(1)):
                        with T.block("var_conv2d_nchw_intermediate_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(32), nn_0_ff_0_yy_0_xx_0_fused // T.int64(896) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(32) * T.int64(4) + ax1)
                            v2 = T.axis.spatial(T.int64(640), nn_0_ff_0_yy_0_xx_0_fused % T.int64(896) // T.int64(56) * T.int64(40) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(20) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(32) // T.int64(8) * T.int64(5) + ax2)
                            v3 = T.axis.spatial(T.int64(448), nn_0_ff_0_yy_0_xx_0_fused % T.int64(56) * T.int64(8) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(8) + ax3)
                            T.reads(var_conv2d_nchw_intermediate_local[v0, v1, v2, v3], lv9[v0, v1, T.int64(0), T.int64(0)])
                            T.writes(var_compute_intermediate[v0, v1, v2, v3])
                            var_compute_intermediate[v0, v1, v2, v3] = T.Select(T.float32(0) < var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)], (var_conv2d_nchw_intermediate_local[v0, v1, v2, v3] + lv9[v0, v1, T.int64(0), T.int64(0)]) * T.float32(0.20000000000000001))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="compute", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[4, 1, 2, 1, 4])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[16, 2, 4, 5, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[56, 1, 8, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[6, 16, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=256)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #767: GFLOPs: 19.3323. Time: 821052.8333 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #768: GFLOPs: 144.6645. Time: 109721.6250 us. Best GFLOPs: 1477.2702
2023-05-18 16:31:33 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 16:31:34 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 16:31:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 405 failure(s)
2023-05-18 16:31:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 815 failure(s)
2023-05-18 16:31:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1225 failure(s)
2023-05-18 16:31:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1633 failure(s)
2023-05-18 16:31:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 2039 failure(s)
2023-05-18 16:31:43 [INFO] [evolutionary_search.cc:723] Sampled 11 candidate(s)
2023-05-18 16:31:47 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 104 failure(s)
2023-05-18 16:31:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 113 failure(s)
2023-05-18 16:32:00 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 100 failure(s)
2023-05-18 16:32:07 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 102 failure(s)
2023-05-18 16:32:09 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9736  0.9736  0.9736  0.9694  0.9652  0.9648  0.9648  0.9647  0.9638  0.9638  0.9632  0.9632  0.9618  0.9615  0.9609  0.9609
[17 : 32]:	0.9606  0.9600  0.9600  0.9576  0.9558  0.9558  0.9534  0.9534  0.9516  0.9516  0.9516  0.9512  0.9507  0.9507  0.9507  0.9507
[33 : 48]:	0.9507  0.9506  0.9504  0.9500  0.9500  0.9500  0.9497  0.9492  0.9491  0.9483  0.9479  0.9479  0.9479  0.9479  0.9475  0.9474
[49 : 64]:	0.9464  0.9463  0.9460  0.9460  0.9460  0.9459  0.9457  0.9454  0.9448  0.9440  0.9440  0.9434  0.9431  0.9427  0.9424  0.9421
2023-05-18 16:32:09 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 16:32:09 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #769: GFLOPs: 1376.5533. Time: 11530.8426 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #770: GFLOPs: 1460.7494. Time: 10866.2167 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #771: GFLOPs: 743.5388. Time: 21347.6668 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #772: GFLOPs: 848.1417. Time: 18714.8195 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #773: GFLOPs: 1428.1342. Time: 11114.3750 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #774: GFLOPs: 716.6430. Time: 22148.8500 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #775: GFLOPs: 1428.0176. Time: 11115.2824 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #776: GFLOPs: 1369.5867. Time: 11589.4953 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #777: GFLOPs: 1441.2551. Time: 11013.1917 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #778: GFLOPs: 463.6650. Time: 34233.3750 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #779: GFLOPs: 1356.0159. Time: 11705.4816 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #780: GFLOPs: 1422.1623. Time: 11161.0463 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #781: GFLOPs: 1429.3797. Time: 11104.6905 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #782: GFLOPs: 1419.2388. Time: 11184.0370 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #783: GFLOPs: 1416.5514. Time: 11205.2546 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #784: GFLOPs: 1415.9711. Time: 11209.8472 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #785: GFLOPs: 1425.2602. Time: 11136.7870 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #786: GFLOPs: 1435.5727. Time: 11056.7857 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #787: GFLOPs: 1437.2194. Time: 11044.1167 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #788: GFLOPs: 1448.3826. Time: 10958.9959 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #789: GFLOPs: 1418.7214. Time: 11188.1157 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #790: GFLOPs: 295.8632. Time: 53649.1803 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #791: GFLOPs: 1444.3426. Time: 10989.6500 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #792: GFLOPs: 1434.2709. Time: 11066.8208 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #793: GFLOPs: 849.4482. Time: 18686.0348 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #794: GFLOPs: 804.9049. Time: 19720.1180 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #795: GFLOPs: 1425.3905. Time: 11135.7686 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #796: GFLOPs: 1169.1402. Time: 13576.4896 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #797: GFLOPs: 1415.6302. Time: 11212.5463 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #798: GFLOPs: 488.7083. Time: 32479.1250 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #799: GFLOPs: 1349.2228. Time: 11764.4167 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #800: GFLOPs: 1432.1468. Time: 11083.2351 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #801: GFLOPs: 1417.6502. Time: 11196.5694 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #802: GFLOPs: 1441.8491. Time: 11008.6548 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #803: GFLOPs: 1384.9542. Time: 11460.8981 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #804: GFLOPs: 1416.3349. Time: 11206.9676 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #805: GFLOPs: 1411.5469. Time: 11244.9816 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #806: GFLOPs: 1417.1322. Time: 11200.6620 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #807: GFLOPs: 1452.4736. Time: 10928.1292 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #808: GFLOPs: 1419.3587. Time: 11183.0926 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #809: GFLOPs: 1423.2758. Time: 11152.3148 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #810: GFLOPs: 1445.3366. Time: 10982.0916 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #811: GFLOPs: 1410.9213. Time: 11249.9676 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #812: GFLOPs: 1163.4277. Time: 13643.1510 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #813: GFLOPs: 859.6269. Time: 18464.7777 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #814: GFLOPs: 1366.3724. Time: 11616.7593 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #815: GFLOPs: 465.4549. Time: 34101.7360 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #816: GFLOPs: 1440.1992. Time: 11021.2667 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #817: GFLOPs: 1437.5011. Time: 11041.9524 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #818: GFLOPs: 1397.2934. Time: 11359.6899 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #819: GFLOPs: 1422.2791. Time: 11160.1296 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #820: GFLOPs: 1433.0214. Time: 11076.4702 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #821: GFLOPs: 1435.6384. Time: 11056.2792 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #822: GFLOPs: 1418.5829. Time: 11189.2083 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #823: GFLOPs: 1411.1821. Time: 11247.8889 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #824: GFLOPs: 1439.1208. Time: 11029.5250 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #825: GFLOPs: 1418.7578. Time: 11187.8287 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #826: GFLOPs: 873.8989. Time: 18163.2222 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #827: GFLOPs: 1352.1862. Time: 11738.6343 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #828: GFLOPs: 1419.1871. Time: 11184.4444 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #829: GFLOPs: 1383.5402. Time: 11472.6111 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #830: GFLOPs: 391.7799. Time: 40514.6390 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #831: GFLOPs: 233.7159. Time: 67915.0140 us. Best GFLOPs: 1477.2702
2023-05-18 16:35:50 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #832: GFLOPs: 28.9340. Time: 548586.3750 us. Best GFLOPs: 1477.2702
2023-05-18 16:41:29 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 16:41:29 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 16:41:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 408 failure(s)
2023-05-18 16:41:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 817 failure(s)
2023-05-18 16:41:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1224 failure(s)
2023-05-18 16:41:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1633 failure(s)
2023-05-18 16:41:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 2040 failure(s)
2023-05-18 16:41:38 [INFO] [evolutionary_search.cc:723] Sampled 10 candidate(s)
2023-05-18 16:41:43 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 100 failure(s)
2023-05-18 16:41:49 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 106 failure(s)
2023-05-18 16:41:56 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 81 failure(s)
2023-05-18 16:42:02 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 85 failure(s)
2023-05-18 16:42:05 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9778  0.9736  0.9692  0.9654  0.9652  0.9642  0.9642  0.9632  0.9609  0.9609  0.9606  0.9600  0.9576  0.9566  0.9566  0.9558
[17 : 32]:	0.9540  0.9534  0.9512  0.9510  0.9500  0.9500  0.9500  0.9497  0.9497  0.9492  0.9483  0.9478  0.9475  0.9475  0.9473  0.9467
[33 : 48]:	0.9460  0.9460  0.9460  0.9460  0.9459  0.9458  0.9458  0.9446  0.9435  0.9434  0.9433  0.9424  0.9422  0.9421  0.9421  0.9421
[49 : 64]:	0.9418  0.9416  0.9415  0.9415  0.9415  0.9415  0.9415  0.9415  0.9411  0.9407  0.9407  0.9380  0.9379  0.9373  0.9373  0.9373
2023-05-18 16:42:05 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 16:42:05 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #833: GFLOPs: 1452.5046. Time: 10927.8958 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #834: GFLOPs: 304.6436. Time: 52102.9167 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #835: GFLOPs: 1352.0012. Time: 11740.2408 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #836: GFLOPs: 1427.0688. Time: 11122.6726 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #837: GFLOPs: 662.4241. Time: 23961.7168 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #838: GFLOPs: 1144.5932. Time: 13867.6511 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #839: GFLOPs: 1437.2397. Time: 11043.9614 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #840: GFLOPs: 1418.6545. Time: 11188.6436 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #841: GFLOPs: 616.7957. Time: 25734.3230 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #842: GFLOPs: 1411.0375. Time: 11249.0417 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #843: GFLOPs: 670.6969. Time: 23666.1584 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #844: GFLOPs: 1426.0908. Time: 11130.3009 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #845: GFLOPs: 1442.4541. Time: 11004.0375 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #846: GFLOPs: 1398.8566. Time: 11346.9953 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #847: GFLOPs: 1412.4646. Time: 11237.6759 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #848: GFLOPs: 1354.7417. Time: 11716.4908 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #849: GFLOPs: 1326.1603. Time: 11969.0046 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #850: GFLOPs: 1379.6314. Time: 11505.1158 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #851: GFLOPs: 1112.3451. Time: 14269.6894 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #852: GFLOPs: 1427.8327. Time: 11116.7222 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #853: GFLOPs: 1417.0930. Time: 11200.9722 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #854: GFLOPs: 1417.1129. Time: 11200.8148 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #855: GFLOPs: 1367.3151. Time: 11608.7500 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #856: GFLOPs: 1139.2823. Time: 13932.2969 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #857: GFLOPs: 1422.3257. Time: 11159.7639 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #858: GFLOPs: 826.9474. Time: 19194.4722 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #859: GFLOPs: 1362.7234. Time: 11647.8658 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #860: GFLOPs: 1379.6586. Time: 11504.8889 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #861: GFLOPs: 1420.3994. Time: 11174.8982 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #862: GFLOPs: 1410.5289. Time: 11253.0972 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #863: GFLOPs: 1419.2094. Time: 11184.2686 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #864: GFLOPs: 1413.4143. Time: 11230.1250 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #865: GFLOPs: 1361.4912. Time: 11658.4073 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #866: GFLOPs: 727.6920. Time: 21812.5500 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #867: GFLOPs: 455.2349. Time: 34867.3193 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #868: GFLOPs: 1435.6751. Time: 11055.9970 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #869: GFLOPs: 1377.3834. Time: 11523.8936 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #870: GFLOPs: 651.8554. Time: 24350.2168 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #871: GFLOPs: 1381.1042. Time: 11492.8472 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #872: GFLOPs: 1361.6491. Time: 11657.0556 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #873: GFLOPs: 1314.1398. Time: 12078.4861 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #874: GFLOPs: 1438.0245. Time: 11037.9334 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #875: GFLOPs: 1417.9363. Time: 11194.3102 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #876: GFLOPs: 1391.9473. Time: 11403.3194 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #877: GFLOPs: 1430.2633. Time: 11097.8304 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #878: GFLOPs: 1399.1329. Time: 11344.7547 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #879: GFLOPs: 1399.1780. Time: 11344.3889 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #880: GFLOPs: 1393.8685. Time: 11387.6019 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #881: GFLOPs: 1419.9765. Time: 11178.2269 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #882: GFLOPs: 1319.3876. Time: 12030.4444 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #883: GFLOPs: 1417.1275. Time: 11200.6991 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #884: GFLOPs: 1412.8220. Time: 11234.8333 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #885: GFLOPs: 1350.9528. Time: 11749.3518 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #886: GFLOPs: 1407.7125. Time: 11275.6111 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #887: GFLOPs: 1412.8220. Time: 11234.8333 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #888: GFLOPs: 1412.8336. Time: 11234.7407 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #889: GFLOPs: 1411.5766. Time: 11244.7453 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #890: GFLOPs: 1419.6954. Time: 11180.4398 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #891: GFLOPs: 1365.4294. Time: 11624.7824 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #892: GFLOPs: 1365.8069. Time: 11621.5694 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #893: GFLOPs: 1420.2935. Time: 11175.7314 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #894: GFLOPs: 424.6858. Time: 37375.4443 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #895: GFLOPs: 76.6547. Time: 207069.0973 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #896: GFLOPs: 97.6526. Time: 162543.6943 us. Best GFLOPs: 1477.2702
2023-05-18 16:43:18 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 16:43:19 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 16:43:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 409 failure(s)
2023-05-18 16:43:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 817 failure(s)
2023-05-18 16:43:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1227 failure(s)
2023-05-18 16:43:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1634 failure(s)
2023-05-18 16:43:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 2042 failure(s)
2023-05-18 16:43:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 2449 failure(s)
2023-05-18 16:43:29 [INFO] [evolutionary_search.cc:723] Sampled 11 candidate(s)
2023-05-18 16:43:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 109 failure(s)
2023-05-18 16:43:40 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 96 failure(s)
2023-05-18 16:43:47 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 97 failure(s)
2023-05-18 16:43:53 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 95 failure(s)
2023-05-18 16:43:56 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9648  0.9609  0.9609  0.9606  0.9600  0.9600  0.9590  0.9576  0.9571  0.9566  0.9511  0.9511  0.9511  0.9507  0.9506  0.9500
[17 : 32]:	0.9477  0.9468  0.9460  0.9459  0.9440  0.9440  0.9435  0.9435  0.9435  0.9435  0.9427  0.9421  0.9415  0.9415  0.9411  0.9365
[33 : 48]:	0.9364  0.9360  0.9358  0.9357  0.9353  0.9351  0.9348  0.9329  0.9328  0.9328  0.9324  0.9320  0.9318  0.9313  0.9311  0.9310
[49 : 64]:	0.9309  0.9305  0.9285  0.9280  0.9280  0.9279  0.9278  0.9269  0.9265  0.9263  0.9262  0.9259  0.9253  0.9247  0.9243  0.9243
2023-05-18 16:43:56 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-05-18 16:43:56 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #897: GFLOPs: 458.0258. Time: 34654.8610 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #898: GFLOPs: 1414.7330. Time: 11219.6574 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #899: GFLOPs: 1415.4584. Time: 11213.9073 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #900: GFLOPs: 1407.9652. Time: 11273.5879 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #901: GFLOPs: 1436.6845. Time: 11048.2291 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #902: GFLOPs: 1356.8547. Time: 11698.2453 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #903: GFLOPs: 1346.5177. Time: 11788.0509 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #904: GFLOPs: 1376.8811. Time: 11528.0972 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #905: GFLOPs: 1359.4042. Time: 11676.3056 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #906: GFLOPs: 1342.4217. Time: 11824.0186 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #907: GFLOPs: 1419.4638. Time: 11182.2639 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #908: GFLOPs: 1361.9493. Time: 11654.4861 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #909: GFLOPs: 1426.7614. Time: 11125.0694 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #910: GFLOPs: 720.9535. Time: 22016.4250 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #911: GFLOPs: 1403.0595. Time: 11313.0047 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #912: GFLOPs: 1418.1885. Time: 11192.3194 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #913: GFLOPs: 1447.9257. Time: 10962.4542 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #914: GFLOPs: 1416.5532. Time: 11205.2407 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #915: GFLOPs: 1431.8272. Time: 11085.7083 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #916: GFLOPs: 1418.6797. Time: 11188.4444 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #917: GFLOPs: 1400.8805. Time: 11330.6018 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #918: GFLOPs: 1172.9592. Time: 13532.2864 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #919: GFLOPs: 1440.5336. Time: 11018.7083 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #920: GFLOPs: 1432.5207. Time: 11080.3416 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #921: GFLOPs: 1363.0392. Time: 11645.1667 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #922: GFLOPs: 1408.9094. Time: 11266.0323 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #923: GFLOPs: 1400.1202. Time: 11336.7546 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #924: GFLOPs: 1385.6399. Time: 11455.2269 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #925: GFLOPs: 1413.5938. Time: 11228.6990 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #926: GFLOPs: 1408.1867. Time: 11271.8148 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #927: GFLOPs: 1377.2257. Time: 11525.2129 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #928: GFLOPs: 1397.7052. Time: 11356.3426 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #929: GFLOPs: 1409.5014. Time: 11261.3010 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #930: GFLOPs: 1413.5477. Time: 11229.0648 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #931: GFLOPs: 1421.1148. Time: 11169.2731 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #932: GFLOPs: 872.3839. Time: 18194.7638 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #933: GFLOPs: 1397.2176. Time: 11360.3056 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #934: GFLOPs: 1415.5162. Time: 11213.4490 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #935: GFLOPs: 1422.8983. Time: 11155.2731 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #936: GFLOPs: 1399.9195. Time: 11338.3797 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #937: GFLOPs: 1378.0555. Time: 11518.2731 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #938: GFLOPs: 1403.4679. Time: 11309.7129 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #939: GFLOPs: 1408.4065. Time: 11270.0556 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #940: GFLOPs: 1422.2673. Time: 11160.2222 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #941: GFLOPs: 1435.8734. Time: 11054.4702 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #942: GFLOPs: 1383.3655. Time: 11474.0602 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #943: GFLOPs: 1281.6365. Time: 12384.8056 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #944: GFLOPs: 1416.2009. Time: 11208.0278 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #945: GFLOPs: 1391.8783. Time: 11403.8842 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #946: GFLOPs: 1404.0064. Time: 11305.3750 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #947: GFLOPs: 1390.0961. Time: 11418.5047 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #948: GFLOPs: 1398.5935. Time: 11349.1296 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #949: GFLOPs: 1408.2312. Time: 11271.4583 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #950: GFLOPs: 1401.1461. Time: 11328.4537 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #951: GFLOPs: 1328.4516. Time: 11948.3611 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #952: GFLOPs: 1397.4899. Time: 11358.0926 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #953: GFLOPs: 1190.0208. Time: 13338.2709 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #954: GFLOPs: 1414.8801. Time: 11218.4908 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #955: GFLOPs: 1401.2366. Time: 11327.7222 us. Best GFLOPs: 1477.2702
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #956: GFLOPs: 1507.5173. Time: 10529.1125 us. Best GFLOPs: 1507.5173
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #957: GFLOPs: 1360.8362. Time: 11664.0186 us. Best GFLOPs: 1507.5173
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #958: GFLOPs: 49.4007. Time: 321307.5137 us. Best GFLOPs: 1507.5173
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #959: GFLOPs: 48.8534. Time: 324906.8473 us. Best GFLOPs: 1507.5173
2023-05-18 16:44:56 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #960: GFLOPs: 629.6029. Time: 25210.8438 us. Best GFLOPs: 1507.5173
2023-05-18 16:44:56 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-18 16:44:57 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-18 16:44:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 405 failure(s)
2023-05-18 16:45:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 814 failure(s)
2023-05-18 16:45:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1223 failure(s)
2023-05-18 16:45:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 1631 failure(s)
2023-05-18 16:45:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 2040 failure(s)
2023-05-18 16:45:06 [INFO] [evolutionary_search.cc:723] Sampled 10 candidate(s)
2023-05-18 16:45:11 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 101 failure(s)
2023-05-18 16:45:17 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 107 failure(s)
2023-05-18 16:45:23 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 100 failure(s)
2023-05-18 16:45:30 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x600001f605e8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x600001f63d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x600001f63008)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x600001f63ea8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x600001f61808)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x60000149d7d8)]: 96 failure(s)
2023-05-18 16:45:33 [INFO] [evolutionary_search.cc:649] Scores of the best 40 candidates:
[1 : 16]:	0.9702  0.9652  0.9638  0.9632  0.9615  0.9606  0.9565  0.9521  0.9516  0.9512  0.9510  0.9510  0.9497  0.9497  0.9487  0.9487
[17 : 32]:	0.9487  0.9468  0.9461  0.9460  0.9459  0.9458  0.9458  0.9453  0.9421  0.9418  0.9415  0.9390  0.9379  0.9373  0.9373  0.9367
[33 : 40]:	0.9360  0.9357  0.9349  0.9349  0.9347  0.9331  0.9328  0.9324
2023-05-18 16:45:33 [INFO] [evolutionary_search.cc:727] Got 40 candidate(s) with evolutionary search
2023-05-18 16:45:33 [INFO] [evolutionary_search.cc:730] Sending 40 candidates(s) for measurement
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #961: GFLOPs: 1346.2269. Time: 11790.5972 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #962: GFLOPs: 1430.1053. Time: 11099.0566 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #963: GFLOPs: 817.6866. Time: 19411.8610 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #964: GFLOPs: 1417.7522. Time: 11195.7639 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #965: GFLOPs: 1419.9759. Time: 11178.2316 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #966: GFLOPs: 1361.4939. Time: 11658.3842 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #967: GFLOPs: 1358.4299. Time: 11684.6806 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #968: GFLOPs: 1335.7034. Time: 11883.4907 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #969: GFLOPs: 1406.9979. Time: 11281.3380 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #970: GFLOPs: 1392.2287. Time: 11401.0139 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #971: GFLOPs: 1362.6898. Time: 11648.1528 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #972: GFLOPs: 1331.6341. Time: 11919.8056 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #973: GFLOPs: 1411.3482. Time: 11246.5649 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #974: GFLOPs: 1182.9892. Time: 13417.5520 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #975: GFLOPs: 474.5273. Time: 33449.7500 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #976: GFLOPs: 900.5876. Time: 17624.9583 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #977: GFLOPs: 861.0835. Time: 18433.5417 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #978: GFLOPs: 1409.3200. Time: 11262.7500 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #979: GFLOPs: 1366.4944. Time: 11615.7222 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #980: GFLOPs: 1430.7632. Time: 11093.9524 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #981: GFLOPs: 1408.4030. Time: 11270.0833 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #982: GFLOPs: 1434.0445. Time: 11068.5684 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #983: GFLOPs: 1410.1304. Time: 11256.2778 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #984: GFLOPs: 1384.1653. Time: 11467.4306 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #985: GFLOPs: 1394.5851. Time: 11381.7500 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #986: GFLOPs: 1420.6955. Time: 11172.5694 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #987: GFLOPs: 1412.9454. Time: 11233.8519 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #988: GFLOPs: 1319.1216. Time: 12032.8703 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #989: GFLOPs: 1395.8405. Time: 11371.5139 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #990: GFLOPs: 536.7015. Time: 29574.7602 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #991: GFLOPs: 1379.0366. Time: 11510.0787 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #992: GFLOPs: 1431.2224. Time: 11090.3929 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #993: GFLOPs: 1393.4045. Time: 11391.3934 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #994: GFLOPs: 474.8718. Time: 33425.4863 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #995: GFLOPs: 1309.8887. Time: 12117.6852 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #996: GFLOPs: 1411.1286. Time: 11248.3149 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #997: GFLOPs: 1430.3055. Time: 11097.5030 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #998: GFLOPs: 1368.4656. Time: 11598.9907 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #999: GFLOPs: 57.2632. Time: 277190.7360 us. Best GFLOPs: 1507.5173
2023-05-18 16:46:27 [INFO] [task_scheduler.cc:131] [Task #18: fused_conv2d2_add1_leaky_relu] Trial #1000: GFLOPs: 49.1609. Time: 322875.1667 us. Best GFLOPs: 1507.5173
